\documentclass{standalone}

\input{./content/packages}
\input{./content/desgin}
\input{./content/declarations}

\begin{document}
\begin{mindmap}
	\begin{mindmapcontent}
		\node (middle) at (current page.center) {Verification of Digital Circuits
			\resizebox{\textwidth}{!}{
				\begin{minipage}[t]{18cm}
				\end{minipage}
			}
		}
		child {
				node {Basics}
				child {
						node {Complexity classes
								\resizebox{\textwidth}{!}{
									\begin{minipage}[t]{12cm}
										\begin{itemize}
											\item \alert{P}: Problems that can be solved in Polynomial time in the size of the input
											\begin{itemize}
												\item sorting ($n\cdot log(n)$), deciding if sequence is sortedv, shortest path in graph, matrix mulitplication (naively in $n^3$)
											\end{itemize}
											\item \alert{NP}: $N$ for nondeterministic, can guess a solution (yes answer) and verify efficiently that it is a solution
											\begin{itemize}
												\item \alert{complete:} It's the hardest in it's class, if can solve SAT, one can solve all the problems in $NP$
												\begin{itemize}
													\item traveling salesman, bring in database in certain normal form, knapsack
													\item noone has ever found an algorithm that solves them efficiently without guessing, all have exponential runtime and also noone was able to proof that there's no efficient algorithm
												\end{itemize}
											\end{itemize}
											\item \alert{co-NP}: Can't guess the yes answer, one can guess the no
											\begin{itemize}
												\item noone was able to proof whether NP and co-NP are the same, so one has to disitingiush them
												\item equivalence checking for combinational circuits is \alert{co-NP complete}, can find an input that deals different outputs, therefore it's NOT equivalent
											\end{itemize}
										\end{itemize}
									\end{minipage}
								}
							}
					}
				child {
						node {Propositional Logic
								\resizebox{\textwidth}{!}{
									\begin{minipage}[t]{12cm}
										\begin{itemize}
											\item \script{128}{Syntax inductively and as context-free grammar}
											\item \script{129}{Semantics}
											\item \script{131}{Literal, Clause, Conjunctive Normal Form (CNF) (f.)}
											\begin{itemize}
												\item \script{170}{Notation: Set of literals, empty clause}, order of literals does not matter and duplicates do not matter, empty set has role like the neutral element of disjunction, thus the empty clause is \alert{unsatisfiable} by definition \script{172}{Notation: CNF formula set of clauses, empty formula}, empty formula is a set of clauses, if one adds an empty set of clauses nothing changes, the clauses are connected with AND, one has connect $1$ with AND such that nothing changes, thus a empty formula is \alert{satisfiayble} by definition
												\item \script{171}{Operations on clauses} and \script{172}{Union of two CNF formulas}
											\end{itemize}
											\item \script{144}{Equivalence}
										\end{itemize}
									\end{minipage}
								}
							}
						child {
								node {Resolution
										\resizebox{\textwidth}{!}{
											\begin{minipage}[t]{14cm}
												\begin{itemize}
													\item \script{174}{Definition, resolvent}: $L\in C_1, \neg L \in C_2, R = (C_1 - \{L\}) \cup (C_2 - \{\neg L\})$, $R = C_1 \otimes_L C_2$
													\begin{itemize}
														\item \script{175}{Examples}, can delete all tautology clauses, because they are useless, at the bottom example for empty clause
													\end{itemize}
													\item \script{176}{Resolution Lemma}: Let $F$ be a CNF formula and $R$ be the resolvent of two clauses $C_1$ and $C_2$ from $F$. Then $F$ and $F \cup \{R\}$ are \alert{(logically) equivalent}: $F \equiv F \cup \{R\}$
													\begin{itemize}
														\item \script{177}{Proof}, \underline{one direction}: trivial, if assignment satisfies all clauses including the resolvent, then all the clauses without the resolvent are satisfied, \underline{other direction}: formula f satisfiable and show that also resolvent is satisfied, A a satisficing assignment of formula f, A is a model of f, if $L$ is true then $C_1$ was satisfied becaus of that, $C_2$ is also satisfied, otherwise the formula would not be satisfied, but it's not satisfied because of $L$, because the $\neg L$ is false, so $C_2$ without the $L$ has to contain another literal that is satisfied and that Literal is also contained in the resolvent and therefore the resolvent is satisfied. The other case wors exactly the same way%, $L$ is assigne to false, then $C_2$ is satisfied because of the $\neg L$, but $C_1$ cannot be satisfied because of the $L$, so $C_1$ has to contain another satisfying literal and that other satisfying literal ends up in the resolvent and satisfies it
													\end{itemize}
													\item \script{178}{$Res(F)$ etc.}
													\begin{itemize}
														\item $Res(F) = F \cup \{R \mid R \text{ is the resolvent of two clauses in } F\}$
														\item $Res^0(F) = F$
														\item $Res^{t+1}(F ) = Res(Res^t(F)) \text{ for } t \ge 0$
														\item $Res^*(F ) = lim_{t\ge 0}\enspace Res^t(F)$
														\item do as long as fomrula changes, only finitely many clauses, so it has to terminate
													\end{itemize}
													\item \script{179}{Resolution Theorem}: A CNF formula F is \alert{unsatisfiable} \textit{iff} $\square \in Res^*(F)$
													\begin{itemize}
														\item \script{180}{Proof}, proof two things:
														\begin{itemize}
															\item \underline{if one can dervive the empty clause the formula is unsatisfied}: Only proof one half, if one can derive the empty clause, the formula is unsatisfied, resolution lemma: can add resolvents to the formula and it's logicaly equivalent, the empty clause is a resolvent, so one can add the empty clause to the formula and every formula that contains the empty clause is unsatisfied, the formula with the resolvent is unsatisfieable, therefore the original formula is unsatisfiable
															\item \underline{if formula is unsatisfied, one can derive the empty clause:} later eliminate variables using resolution you canot only add resolvents but you can if you do it right get rid of variables using resolution and the result is a equally satisfiable formula. You just apply resolution to eliminate all the variables and you know the result is equisatisfiable to original If one eliminates all the variables there are only two cases of formulas without variables the empty formula satisfiable or the formula that only contains the empty clause that's unsatisfiable so that means when you eliminate all the variables you end up either with empty formula empty clause and you know the outcome is equally satisfible to the original formula that means when the outcome is the empty Formula the original formula was satisfiable if the outcome is the empty close then the original formula was unsatisfiable whenever it's unsatisfied we have to get the empty Clause because it can't get the empty formula
														\end{itemize}
													\end{itemize}
												\end{itemize}
											\end{minipage}
										}
									}
							}
					}
				child {
						node {Important Definitions
								\resizebox{\textwidth}{!}{
									\begin{minipage}[t]{12cm}
										\begin{itemize}
											\item \underline{essential definitions:}
											\begin{itemize}
												\item \alert{verification method:} Check equivalence between specification and implementation
												\item \alert{formal verification:} Mathematical proofs of correctness
												\begin{itemize}
													\item one uses \alert{formal methods} to avoid and detect design errors
													\item because validation by simulation can never cover the complete system behavior
												\end{itemize}
												\item \alert{security:} A system should not leak information that should be kept secret
												\item \alert{safety:} System does what it should do, implementation behaves as said in the specification (in this lecture)
												\item \alert{canonical:} Exactly one representation
												\item \alert{topological sort:} A graph traversal in which each node v is visited only after all its dependencies are visited
												\begin{itemize}
													\item a topological ordering is possible \alert{iff} the graph is a directed acyclic graph (DAG)
													\item \underline{algorithm:} The algorithm loops through each node of the graph, in an arbitrary order, initiating a depth-first search that terminates when it hits any node that has already been visited since the beginning of the topological sort or the node has no outgoing edges (i.e. a leaf node)
												\end{itemize}
											\end{itemize}
										\end{itemize}
									\end{minipage}
								}
							}
					}
				child {
						node {Design of integrated circuits
								\resizebox{\textwidth}{!}{
									\begin{minipage}[t]{12cm}
										\begin{itemize}
											\item \underline{\script{22}{design of integrated circuits}:}
											\begin{itemize}
												\item start with abstract specification and make it more and more concrete
												\item implementation of the level before is the specification of the next level
												\item equivalence checking for single steps easier than between initial specification and final implementation, similiarity is much higher
												% \item more abstract SystemC Specification can be above Register-Transfer-Level
												\item \alert{Initial Specification:} Usually in natural language
												% \begin{itemize}
												%   \item would need a specification in formal language e.g. specification by properties, on high level called design properties
												% \end{itemize}
											\end{itemize}
											\begin{enumerate}[label=\color{PrimaryColor}\arabic*.]
												\item \alert{Register-Transfer-Level:} Registers, Operations, Memory, no exact implementation for e.g. multiplier, don't fix the details
												% \begin{itemize}
												%   \item[$\textcolor{SwitchColor}{\blacksquare}$] Implementation in Hardware Description Language e.g. VHDL, Verilog
												% \end{itemize}
												\item \alert{Gate-Level:} Gates (AND, OR, etc.)
												\item \alert{Layout-Level:} Placement (fix places of different components / gates) and routing (fix where connections go)
											\end{enumerate}
											\begin{itemize}
												\item \alert{Final implementation:} Design data for producing the chip
											\end{itemize}
										\end{itemize}
									\end{minipage}
								}
							}
					}
			}
		child {
				node {Basic technologies}
				child {
						node {Binary decision diagrams (BDDs)
								\resizebox{\textwidth}{!}{
									\begin{minipage}[t]{8cm}
										\begin{itemize}
											\item \script{41}{Syntax}
											\item \script{42}{Semantic}
											\item \script{45}{Example}
											\item \script{46}{Drawbacks}
											\item  The \alert{size} is given by the number of non-terminal nodes
											\item \underline{Limitations of BDDs:}
											\begin{itemize}
												\item Canonical representation has to deal with the available memory.
												\item Not directly usable with sequential circuits.
												\item Not directly usable when the specification is a set of properties.
											\end{itemize}
										\end{itemize}
									\end{minipage}
								}
							}
						child {
								node {Construction of ROBDDs}
								child {
										node {Forward construction / symbolic simulation
												\resizebox{\textwidth}{!}{
													\begin{minipage}[t]{12cm}
														\begin{itemize}
															\item \script{104}{Algorithm}
															\item \script{105}{Example}
														\end{itemize}
													\end{minipage}
												}
											}
										child {
												node {ITE-Operator
														\resizebox{\textwidth}{!}{
															\begin{minipage}[t]{14cm}
																\begin{itemize}
																	\item all the binary operation can be reduced to a call to ITE (\enquote{If-Then-Else}-Operator)
																	\item \script{90}{Definition}: $ITE(F, G, H) = (F\wedge G)\vee(\neg F\wedge H)$
																	\begin{itemize}
																		\item the expression derives from the fact that a ITE node can be interpreted as a \alert{multiplexer} with inputs $G$ and $H$ and selector $F$
																		\item $AND(F, G) = ITE(F, G, 0) = (F\wedge G)\vee(\neg F\wedge 0) = F\wedge G$
																		\item $OR(F, G) = ITE(F, 1, G) = (F\wedge 1)\vee(\neg F\wedge G) = F \vee (\neg F \wedge G) = F\vee G$
																		\item $NOT(F) = ITE(F, 0, 1) = (F\wedge 0)\vee(\neg F\wedge 1) = \neg F$
																	\end{itemize}
																	\item \script{91}{Theorem and Proof}: $ITE(F, G, H) = (\neg x_i \wedge ITE(F_{\neg x_i}, G_{\neg x_i}, H_{\neg x_i}))\vee(x_i\wedge ITE(F_{x_i}, G_{x_i}, H_{x_i}))$
																	\item \script{93}{Algorithm to Compute a new ROBDD for ITE(F, G, H) out of ROBDD's F, G and H (ff.)}
																	\begin{itemize}
																		\item \underline{Base cases:}
																		\begin{itemize}
																			\item $ITE(1, F, G) = ITE(0, G, F) = ITE(F, 1, 0) = ITE(G, F, F) = F$
																			\item $NOT(F) = ITE(F , 0, 1) = \neg F$
																		\end{itemize}
																		\item \script{99}{Runtime}
																	\end{itemize}
																\end{itemize}
															\end{minipage}
														}
													}
											}
									}
								child {
										node {Backward construction
												\resizebox{\textwidth}{!}{
													\begin{minipage}[t]{12cm}
														\begin{itemize}
															\item \script{116}{Algorithm}
															\item \script{120}{Example}
														\end{itemize}
													\end{minipage}
												}
											}
										child {
												node {Substitution operator, compose
														\resizebox{\textwidth}{!}{
															\begin{minipage}[t]{12cm}
																\begin{itemize}
																	\item \script{117}{Definition}: $compose(F, G, x_i)(x_1, \ldots , x_n) = F (x_1 , \ldots , x_{i-1}, G (x_1 , \ldots , x_n), x_{i+1}, \ldots , x_n)$
																	\item \script{118}{Theorem}: $compose(F, G, x_i) = ITE(G, F_{x_i}, F_{\neg x_i})$
																	\begin{itemize}
																		\item \script{119}{Proof}
																	\end{itemize}
																\end{itemize}
															\end{minipage}
														}
													}
											}
									}
							}
						child {
								node {Reduced Ordered Binary Decision Diagrams (ROBDDs)
										\resizebox{\textwidth}{!}{
											\begin{minipage}[t]{12cm}
												\begin{itemize}
													\item A BDD G is a Reduced Ordered Binary Decision Diagram iff it is ordered and reduced
													\begin{itemize}
														\item In this context, reduced means that none of the reduction rules (\enquote{isomorphism} and \enquote{Shannon}) can be applied (anymore).
													\end{itemize}
													\item \script{57}{Example}
													\item (\script{62}{Remark})
													\item \script{65}{Proof of the Canonicity of ROBDDs}
													\begin{itemize}
														\item \script{64}{Definition Isomorphism}
													\end{itemize}
												\end{itemize}
											\end{minipage}
										}
									}
								child {
										node {Reduction Rules
												\resizebox{\textwidth}{!}{
													\begin{minipage}[t]{12cm}
														\begin{itemize}
															\item OBDDs can be reduced to ROBDDs in layers starting from the terminal nodes
														\end{itemize}
													\end{minipage}
												}
											}
										child {
												node {\enquote{Isomorphism} reduction
														\resizebox{\textwidth}{!}{
															\begin{minipage}[t]{12cm}
																\begin{itemize}
																	\item \script{51}{Definition}
																	\item \script{52}{Example}
																\end{itemize}
															\end{minipage}
														}
													}
											}
										child {
												node {\enquote{Shannon} reduction
														\resizebox{\textwidth}{!}{
															\begin{minipage}[t]{12cm}
																\begin{itemize}
																	\item \script{53}{Definition and Example}
																\end{itemize}
															\end{minipage}
														}
													}
											}
									}
								child {
										node {Ordered BDDs (OBDDs)
												\resizebox{\textwidth}{!}{
													\begin{minipage}[t]{12cm}
														\begin{itemize}
															\item A BDD G over the set of variables $X_n = \{x_1, \ldots, x_n\}$ is ordered, iff it is \alert{free} and the \alert{variables on every path} from the root to a terminal node occur in the \alert{same order}
															\item \script{48}{information about variable order}
															\item \script{49}{example}
															\item This is still not enough, there can be redundancy in the OBDD
														\end{itemize}
													\end{minipage}
												}
											}
										child {
												node {Free BDDs
														\resizebox{\textwidth}{!}{
															\begin{minipage}[t]{12cm}
																\begin{itemize}
																	\item A BDD G is free, iff each variable along every path from the root to a terminal node occurs at most once.
																	\item \script{47}{Example}
																\end{itemize}
															\end{minipage}
														}
													}
											}
									}
							}
						child {
								node {Shannon theorem
										\resizebox{\textwidth}{!}{
											\begin{minipage}[t]{8cm}
												\begin{itemize}
													\item \script{43}{Definition}: $F = (\neg x_i\wedge F_{\neg x_i})\vee(x_i\wedge F_{x_i})$
													\item \script{44}{Proof}
													\item for BDD's Composition rule and Decomposition rule have the same structure
												\end{itemize}
											\end{minipage}
										}
									}
							}
						child {
								node {Use of ROBDDs in Verification
										\resizebox{\textwidth}{!}{
											\begin{minipage}[t]{12cm}
												\begin{itemize}
													\item the size of a ROBDD depends strongly on the variable order $\pi$ one chooses
													\begin{itemize}
														\item \script{81}{example (f.)}
													\end{itemize}
													\item every cofactor regarding the first n variables consitutes a different Boolean function
													\begin{itemize}
														\item $2n$ different cofactors
														\item \script{83}{example}
													\end{itemize}
												\end{itemize}
											\end{minipage}
										}
									}
								child {
										node {Finding optimal variable order
												\resizebox{\textwidth}{!}{
													\begin{minipage}[t]{8cm}
														\begin{itemize}
															\item \alert{Theorem (Bollig, Savicky, Wegener, 1994):} Given a ROBDD with variable order $\pi$, the problem of finding a new variable order $\pi\prime$ with minimal ROBDD-size is NP-Complete
															\begin{itemize}
																\item \underline{but there are \alert{Heuristics}:}
																\begin{itemize}
																	\item define an initial variable order based on the circuit representation
																	\item perform dynamic reordering within an existing variable order to reduce the size of the ROBDD
																\end{itemize}
															\end{itemize}
														\end{itemize}
													\end{minipage}
												}
											}
										child {
												node {Define an initial variable order
														\resizebox{\textwidth}{!}{
															\begin{minipage}[t]{12cm}
																\begin{itemize}
																	\item \script{107}{Method of Malik}
																	\item \script{108}{Example}
																\end{itemize}
															\end{minipage}
														}
													}
											}
										child {
												node {Dynamic modification of the variable ordering
														\resizebox{\textwidth}{!}{
															\begin{minipage}[t]{12cm}
																\begin{itemize}
																	\item \script{110}{General Algorithm}
																	\begin{itemize}
																		\item \script{112}{Sifting}
																		\begin{itemize}
																			\item \script{113}{Example}
																			\item \script{114}{Runtime}
																		\end{itemize}
																	\end{itemize}
																\end{itemize}
															\end{minipage}
														}
													}
											}
									}
								child {
										node {Not applicable for all pratical functions
												\resizebox{\textwidth}{!}{
													\begin{minipage}[t]{12cm}
														\begin{itemize}
															\item \alert{Theorem (Shannon):} \enquote{Almost every} Boolean function $F\colon\, \mathbb{B}^n\rightarrow\mathbb{B}$ requires more than $(2^n / n) 2$-input gates for an optimal implementation
															\begin{itemize}
																\item holds also for ROBDDs, because they can be seen as multiplexer circuits
																\item \underline{should we care?}: not really, because one does equivalence checking mostly for circuits that are not exponential (the others that are not \enquote{almost every} usually occur, because we're interested in functions with structure)
															\end{itemize}
															\item \alert{Lemma (Bryant, 1986):} Independently from the variable order, multiplication is representable with ROBDDs only with exponential complexity in the bit-width
															\begin{itemize}
																\item there exist actually polynomial mutlipliers, but there are no ROBDDs with polynomial complexity in the bit-width for them
															\end{itemize}
														\end{itemize}
													\end{minipage}
												}
											}
									}
							}
					}
				child {
						node {Satisfiability solvers (SAT / QBF)
								\resizebox{\textwidth}{!}{
									\begin{minipage}[t]{16cm}
										\begin{itemize}
											\item \script{130}{Satisfiable, Model, Unsatisfiable}
											\item \script{133}{Satisfiability-Problem (SAT-Problem)}
											\item \script{164}{Complexity of the SAT Problem}, NP-complete
											% what does NP-Complete mean summary: https://youtu.be/doDYnn9sXWg?feature=shared&t=2286
											% complexity of equivalence checking: https://youtu.be/doDYnn9sXWg?feature=shared&t=2586
											% restrictions ot SAT: https://youtu.be/doDYnn9sXWg?feature=shared&t=2715
											% horn formulas: https://youtu.be/doDYnn9sXWg?feature=shared&t=2761
											\item \script{165}{Practice and Applications}, in worst case all algorithm have exponential runtime, but worst case and pratical case are different
											\item \script{167}{Overview on SAT Algorithms (f.)}
											\begin{itemize}
												\item \script{167}{complete:} run until either they have found a solution or they can prove there's none, decide all formulas if one has enough time, always terminate and always give right answer
												\item \script{168}{incomplete methods:} typically can only find satisfying assignments, if one has a formula with many satisfying assignments, if one has a unsatisfiable formula, they will not terminate, they just look for solutions that modify assignment check again etc.
												\begin{itemize}
													\item scheduling problem, need to find good order, one knows that there's an order that works
													\item in verification they play no role at all, because verification problems either unsatifiying assignments or a few not working corner cases and then incomplete methods are not good at all, either they don't terminate or need very long time to find one of these rare satisfying assignments. Therefore in verification typically only have these complete methods that systematically search for satisfying assignments and can also prove that the formula is unsatisfiable
													\item typically verification is applied if you cannot find any wrong answers anymore by just doing simulation
												\end{itemize}
											\end{itemize}
											\item \underline{different kinds of SAT:} $k$-SAT, every clause exactly $k$-literals, $3$-SAT, $2$-SAT (efficiently solvable)
											\begin{itemize}
												\item \alert{Horn-Formulas:} arbitrary length but contain at most on positive literal (or other way round at most one negative literal), relevance in Prolog, Prolog Statements are Horn clauses, clause with only one literal (if 0 and 1 at the same time, then unsatisfiable), otherwise end up with formula where all clauses have at least length $2$, that means every clause contains a negative literal, if there are no unit clauses, the formula can be satisfied by simply setting all remaining variables negative, can be done efficiently without backtracking
											\end{itemize}
											\item bei SAT muss man eine Zuweisung von Wahrheitswertes true oder false für die Variable finden, sodass in jeder Klausel mindestens ein Literal wahr ist. Weist man einer Variable $x_i$ false zu, dann sind alle Klauseln, die $\neg x_i$ enthalten erfüllt, aber dafür könnten anderen Klauseln, die das Literal $X_i$ enthalten unerfüllbar werden, weil keines der anderen Literale wahr ist
										\end{itemize}
									\end{minipage}
								}
							}
						child {
								node {Naive method
										\resizebox{\textwidth}{!}{
											\begin{minipage}[t]{12cm}
												\begin{itemize}
													\item \script{181}{Algorithm}
													\item \script{182}{Complexity}, is limited by the number of different possible clauses (cnf formula is a \alert{set} of \alert{clauses}, not of maxterms, so there are $3$ states and not only $2$)
													\item \script{183}{Examples (ff.)}, resulting tautology $(x_2, \neg x_2)$ of first and fourth can be ignored
													\begin{itemize}
														\item we do not have to resolve two Clauses from F again because we already did that so we always take either two Clauses from the new ones orthird one Clause from F and one new Clause
													\end{itemize}
												\end{itemize}
											\end{minipage}
										}
									}
							}
						child {
								node {DP-Algorithm
										\resizebox{\textwidth}{!}{
											\begin{minipage}[t]{18cm}
												\begin{itemize}
													\item based on \alert{variable elimination} method and uses a couple of optimizations:
													\begin{itemize}
														\item \script{189}{Subsumption check}: Let $C_1$ and $C_2$ be two clauses. $C_1$ subsumes $C_2$ iff all literals occurring in $C_1$ also occur in $C_2$: $C_1 \subseteq C_2$
														\begin{itemize}
															\item \alert{Idea:} To satisfy a CNF formula $F$, all clauses need to be satisfied, in particular $C_1$. Since all literals of $C_1$ are also contained in $C_2$, every satisfying assignment of $C_1$ also satisfies $C_2$. Therefore $C_2$ does not need to be considered separately and can be deleted. One has to satify $C_1$ in any case for a satifying assigment, if on would satisify the additional literal in $C_2$, still the literals in $C_1$ have to be satisfied that would also satisfy $C_2$
															% \item the other way does not know if you satisfy C2 then you can satisfy using the additional literal and that does not help for satisfying C1 so you need to set up one more literal but that's not necessary because the one in C1 is sufficient
															\item \script{190}{Example}
														\end{itemize}
														\item \script{191}{Pure literal detection}: Let $F$ be a CNF-formula and $L$ a literal contained in $F$. $L$ is a \alert{pure literal} \textit{iff} $L$ is contained in $F$ either only positive or only negative, but not both $L$ and $\neg L$ appear in $F$. For satsifyiability one just needs one satisfying assignment, for making the literal true and removing clauses one will in every case find a satisfying assignment, but if one would make the literal false, there would be remaning clauses that have to be satisfied and could cause contradictions with the clauses not containing the literals. Es ergibt nur Sinn die Literale alle wahr zu machen und damit alle Klauseln, die dieses Literal enthalten, denn ein Literal false zu machen hat nur Nachteile, SAT ist die Entscheidung welche Variablen man wahr oder falsch macht, weil die Literale, die dadurch falsch werden vielleicht wichtig gewesen wären, um eine bestimmte Klausel wahr zu machen. In diesem Fall kommt die Variable allerdings nur in einer der beiden Ausprägungen vor, daher kann es keinen Nachteile haben alle Literale wahr zu machen, weil es keine Klausel gibt, die dadurch unerfüllbar werden könnte% The first case would only have to satisfy the clauses without this literal, while in the second clauses the clauses without this literal and the ones that contained this literal would have to be satisfied, so one in always on the better side by choosing the literal to be true
														\begin{itemize}
															\item \alert{Idea:} Delete from $F$ all clauses which contain a pure literal. They can be satisfied by an according assignment to $L$. This cannot prevent any other clause from being satisfied, because $\neg L$ does not appear in $F$
															\item \script{192}{Example}
														\end{itemize}
														\item these optimizations are not complete in the sense they are sufficient to solve the formula so we need one potentially expensive operation which does the the actual work and that is Variable Elimination
														\item \script{193}{Variable Elimination}: The DP-algorithm applies \alert{resolution} to eliminate a variable $x_i$ completely from the formula, i. e., all occurrences of $x_i$ and $\neg x_i$. The goal is to reduce the number of variables.
														\begin{itemize}
															\item \script{194}{$P$, $N$ and $W$}
															\item \script{195}{$P \otimes_{x_i} N$}
															\item \script{196}{Theorem: $F = P \cup N \cup W$ and $F' = (P \otimes_{x_i} N) \wedge W$ satisfiability equivalent}
															\begin{itemize}
																\item \script{196}{Proof} and \href{/home/areo/Documents/Studium/Summaries/Verification_of_Digital_Circuits/figures/lecture06_sat_36_05.pdf}{\inlinebox{More detailed proof}}, replace the unions with and. %we still have to apply distributivity for that we take one Clause from the P one Clause from the n and take their Union so and do that with all the combinations what do we get we pick one Clause from that set that's a the same Clause as in p but x i is set to zero so x i is removed and we take one Clause from n the original clause contained the not x i with an x i to one so that's removed because it's zero that's just a resolvent 
																%get all these ressolvants by applying distributivity to these clauses but we have to pick one element from P one element from n and take the or that's the same as the resolving that you get by picking one clause from P one Clause from n and then resolving it on x i that removes the x i from the p Clause the not x_i from the n clause the same have the W plus all resolvents 
																Here we see exactly what variable elimination with the resolution does replaces x_i once by 0 once by 1 takes the or because one of the two parts has to be satisfied bring it back to CNF and you get the same as the resolution
																\item we can reduce checking satisfiability of a formula $F$ to checking satisfiability of $F'$. $F'$ does not contain the variable $x_i$ anymore. If $F'$ is satisfiable, this also holds for $F$ and vice-versa
																\item will sooner or later terminate because you only have a finite number of variables
															\end{itemize}
															\item choose an appropriate variable $x_i$, perform resolution between all pairs of clauses which contain $x_i$ and $\neg x_i$, resp., and replace the original clauses (containing $x_i$ or $\neg x_i$) by the resolvents
															\item usually the number of resolvents is larger than the number of original clauses which are replaced, i. e., the formula grows in size during variable elimination
															\item \script{201}{Example}, tautology ignored, at the end one can eliminate X3 if one wants that gives the empty Clause so the formula was unsatisfiable
														\end{itemize}
														\item \script{202}{Davis-Putnam Algorithm}, unit Clause: we delete all the Clauses that that contain L because that s these are satisfied and from the remaining Clauses that unit resolution step is we resolve all the Clauses that contain not L with the unit Clause that removes the not L from all clauses then we call DP on the simplified formula so delete all satisfied Clauses delete all unsatisfied literals and call it recursively. If all doesn't help one elimantes a variable in the last step so you cannot get an infinite sequence of DP calls
													\end{itemize}
													\item the optimizations improve the runtime behavior in practice, but not the worst case complexity of the naı̈ve method, based on resolution plus a few optimizations%, they improve the running time in practice and the memory consumption but not in the worst case
													\begin{itemize}
														\item the main problem here is memory consumption so generating all these resolvents is costly
													\end{itemize}
												\end{itemize}
											\end{minipage}
										}
									}
							}
						child {
								node {DLL/DPLL-Algorithm
										\resizebox{\textwidth}{!}{
											\begin{minipage}[t]{12cm}
												\begin{itemize}
													\item circumvents the memory problems of resolution-based techniques through a distinction of cases, which leads to \alert{depth-first search}
													\item \alert{Idea:} If a CNF formula $F$ is satisfiable, then for a variable $x_i$ either $x_i = 1$ or $x_i = 0$ must hold $\Rightarrow$ try both cases one after the other
													\item \script{206}{DLL-Algorithm}:
													\begin{itemize}
														\item Assign $L$ to $1$. Delete all clauses containing $L$. Delete all occurrences of $\neg L$ % At the end we first set the literal to True, try to solve the formula we get by that, if it's satisfiable we are finished otherwise we flip the value to false try again and if that's also unsatisfiable the formula is unsatisfiable 
														\item \alert{Unit Clause}: A clause consisting of a single literal $L$ is called a unit clause. $L$ is the corresponding unit literal. For $P \otimes_{x_i} N$ with $N =\emptyset$ the result is $\emptyset$, because the condition in the set definition of the $P \otimes_{x_i} N$ is never satisfied, so one gets an empty formula
														\item \script{208}{Example (ff.)}
														\item \script{226}{Summary}
														\item the running time is still exponential because in the worst case we just have to to try all the assignments in N variables and there are 2^n assignments. \underline{Memory Problem:} When we have to do backtracking we need to go back to the old formula so you have to keep the old copy and you create a new formula with the modifications. With many variables the depth of the DFS Tree can be the number of variables
													\end{itemize}
												\end{itemize}
											\end{minipage}
										}
									}
							}
						child [level distance = 10cm] {
								node {Modern SAT-Algorithms
										\resizebox{\textwidth}{!}{
											\begin{minipage}[t]{14cm}
												\begin{itemize}
													\item \script{237}{Basic techniques of today’s SAT solvers}
													\begin{itemize}
														\item preprocessing
														\item alternation between ...
														\begin{itemize}
															\item choose the next decision variable, decide its value
															\item boolean Constraint Propagation / Unit Propagation
															\item if applicable, conflict analysis and backtracking
														\end{itemize}
														\item at some fixed points of the search process
														\begin{itemize}
															\item Unlearning (some conflict clauses)
															\item Restarts
														\end{itemize}
													\end{itemize}
													\item \script{238}{Algorithm}
													\begin{itemize}
														\item \underline{short:} precoessing is simplifying the formula,then after simplification if it's not yet decided we have to pick a variable to assign and the value for that variable that's the purpose of decide next branch which is called the decision heuristic after that we try to find all the implications that result from the assignment that's the purpose of BCP or Boolean constraint propagation that's also detects where the conflict occurs a conflict means in a clause all the lital are assigned to false if that happens we do a conflict analysis meaning we try to find out which assignments are responsible for the empty Clause we add a clause that prevents the solver from running into the same conflict reasons again by just negating that and adding it as a clause and we get back also a backtrack level that tells us how many decisions can be undone the solver recognize the formula as unsatisfiable if the backtrack level is zero because then there is no decision to undo and it recognize the formula satisfiable when all the variables are assigned and no conflict has has happened
														\item want to get a satisfying assignment at the end if you did pre-processing then you have to be careful the satisfying assignment you get from the solver is the satisfying assignment of the formula after pre-processing but you don't want the satisfying assignment of the formula after pre-processing but before pre-processing because you don't mind what the solver does of the formula and it can happen that the satisfying assignment you get does not work for the original formula, you might have to add a few more assignments because you're eliminated variables it might also happen that you have to modify that assignment because you deleted some clauses that you were allowed to delete but you get a wrong assignment then and you have to correct it
														% \item BCP processes all the implications and detects a conflict if we have a conflict we run conflict analysis we get back a backtrack level if the backtrack level is $0$ we know the formula is unsatisfiable if it's not zero but greater than zero then we can do backtracking and finally 
													\end{itemize}
												\end{itemize}
											\end{minipage}
										}
									}
								child {
										node {Improvements to DLL
												\resizebox{\textwidth}{!}{
													\begin{minipage}[t]{16cm}
														\begin{itemize}
															\item \script{224}{Improvements to DLL}: We do we actually modify the formula we can just say oh that clause is satisfied that's one bit of information and we can keep an assignment of the variables then you can just look it up if a variable is unsatisfied or not that's one major Improvement and of course we can carefully select which literal to assign we can learn from the conflicts so we can find out what are the reasons why the formula is unsatisfied not always all decisions are responsible for a unsatisfied formula but only a subset and we want to find out which subset
															\begin{itemize}
																\item \alert{pre-processing} before you solve the formula the goal is simplify a formula simplify means get rid of some of the clauses get rid of some of the variables shorten some clauses just simplify
																\item \alert{decision heuristics} pick a good variable and a good value for that variable when you make the decision. It's obvious that a good decision juristic helps on satisfiable formulas it also helps on unsatisfiable formulas because the sooner you run into a conflict the smaller part of the search Tree is that you have to look at if you run directly into conflict there's no reason to continue at this point you just try the other part so the sooner you run into conflict the better
																\item \alert{BCP} is just the process of finding all unit clauses in principle it's trivial run over the formula check each clause is there only one unassigned literal left, it's not easy to do it fast looking at all clauses is too expensive, BCP is how do you do it as fast as possible to find all unit clauses
																\item \alert{conflict analysis} happens when you run it a conflict conflict is you have an unsatisfied clause an empty clause then you want to find out which were the assignments that triggered this conflict which are responsible for getting an empty clause and you use that for backtracking that information there are two variants of backtracking one is called chronological backtracking and the other one non-chronological \alert{chronological} is what you have seen go back to the last decision and keep it. \alert{Non-chronological} backtracking tries to undo as many decisions as possible such as you just resolve the conflict and sometimes you can undo more assignments that's called non-chronological backtracking and the only information is that you need is which is the reason for the conflict yeah unlearning so conflict analysis also adds an additional clause to the formula that says not that bad assignment again so for instance if the if you found out in conflict analysis that assigning x 1 to true and X2 to false are the reason for the conflict so whenever you assign X1 to 1 and X2 to false you will get a conflict so you never want to do that again how can you say that oh you say either X 1 is false or X 2 is true so you have to Clause not X1 or X2 whenever you try to get that bad assignment again when you assign X1 to one then that clause becomes a unit clause and says oh X2 has to be one that's a conflict clause and you add it to the Clause database in order to prevent the solve from running into the same conflict again so the problem is you run into millions of conflicts during the solution process and you often learn more clauses than your original formula had and you have to store all of that in memory you have to process them all during bollean constraint propagation so the more you of these conflict Clauses you have the more work you have to put into BCP and there is a tradeoff between many conflict Clauses which hope hopefully trigger some implication from time to time and slowing down easy and therefore from time to time you just delete conflict clauses to reduce the memory overhead and to prevent BCP from slowing out that's \alert{unlearning conflict clauses}
																\item \alert{restarts} something strange you just start from scratch again so it can happen that the solver gets stuck into in some bad part of the search space so you have a tree you learn conflict and conflict and conflict and conflict but you make little progress so you only learn really long little useful conflict clauses and then it makes sense to say oh let's start again you keep the good conflict clause that you have learned you keep the information the decision heuristics has learned about good variables and you start from scretch and it seems to help so the hope is the information that you have learned drives you into a different part of the search space not into the bad one when you get stuck but you first look at the different part and there you learn additional conflict losses and they might be useful to handle this difficult part of the search space and therefore you make these restarts from time to time you have to be bit careful if you restart too often you can end up doing restarts in a cycle so you restart you solve a little bit you restart you solve a little bit again you restart you solve a little bit again and so on you can get stuck so typically you choose the interval between two restarts such that it diverges it gets longer longer you make few and fewer restarts
															\end{itemize}
														\end{itemize}
													\end{minipage}
												}
											}
										child [level distance = 12cm] {
												node {Preprocessing
														\resizebox{\textwidth}{!}{
															\begin{minipage}[t]{12cm}
																\begin{itemize}
																	\item \script{240}{In the algorithm}
																	\item \script{241}{Goal, practical observations, find good compromise}
																	\item \script{242}{Preprocessing techniques}
																	\item \videoseven{1929}{Preprocessing sometimes also after restart}
																\end{itemize}
															\end{minipage}
														}
													}
												child {
														node {Unit Propagation
																\resizebox{\textwidth}{!}{
																	\begin{minipage}[t]{12cm}
																		\begin{itemize}
																			\item if omitted, then immediately performed during solving process
																			\item \underline{procedure:}
																			\begin{itemize}
																				\item identify unit clauses in the CNF
																				\item assign units, simplify
																				\item if you get an empty clause formula is unsatisfiable otherwise in the end the CNF does not contain any unique clauses
																				% \item ... until the CNF is free from unit clauses
																			\end{itemize}
																		\end{itemize}
																	\end{minipage}
																}
															}
													}
												child {
														node {Unit Propagation Lookahead (UPLA)
																\resizebox{\textwidth}{!}{
																	\begin{minipage}[t]{12cm}
																		\begin{itemize}
																			\item fix a variable $x_i$ to $0$, check implications; then change its value to $x_i = 1$, check implications. Simplify the formula exploiting the \script{244}{consequences}, and also $(x_i = 0 \rightarrow x_j = 1) \wedge (x_i = 1 \rightarrow x_j = 0) \Rightarrow x_i \equiv \neg x_j$
																			\item ones pretends to have a unit clause and checks what happens, all you need for that is already implemented in the solver the only thing you need is BCP and you need BCP anyway what's the drawback Now it only works if you have clauses of length $2$ if all clauses in the formula have a length longer than two by assigning one variable you don't get any implications, it requires binary clauses and it only makes sense to apply UPLA to variables that appear in binary claes the rest can just be skipped. And because some of the variables might be missing after applying UPLA you have to do something after solving the formula namely add more variable assignments you have to keep track if variables are equivalent or so
																			\begin{itemize}
																				\item there we just pretend we have a unit Clause so we just add $x_i$ as the unit Clause propagate it and check what happens if a conflict occures then we know oh that was the wrong value for the variable so we can directly replace it by zero if $x_i$ $\ldots$
																			\end{itemize}
																			\item \script{245}{Advantages and Disadvantages}, components already in the solver, e.g. BCP, afterwards you have to extend the model because one variable is missing if you replace x i by x j or x i by not x j then you have to keep that information to extend the model afterwards because the satisfying assignment returned by the actual solver core does not contain a value for the replaced variable
																		\end{itemize}
																	\end{minipage}
																}
															}
													}
												child {
														node {Self-subsuming resolution
																\resizebox{\textwidth}{!}{
																	\begin{minipage}[t]{12cm}
																		\begin{itemize}
																			% \item apply resolution to two clauses and resolution result subsumes one of the clauses
																			\item apply resolution such that the resolvent / outcome is a subset of one of the operands. why can we replace it you can always add the resolvend to the clause then apply the subsumption checking and that deletes one of the two so it's just replace and outcome is a logically equivalent formula
																			. Saves literals. We can replace the long clause with a short clause, shorter clauses are typically better because they trigger implications earlier so you get more implications less decisions and therefore it's typically better to have shorter clauses
																			\item \script{246}{Example}
																		\end{itemize}
																	\end{minipage}
																}
															}
													}% / clause distribution ?
												child {
														node {Elimination by Resolution
																\resizebox{\textwidth}{!}{
																	\begin{minipage}[t]{12cm}
																		\begin{itemize}
																			\item \alert{variable elimination} applied to a variable of the CNF formula, seen in DP
																			\item it is applied only if it leads to a simplification of the formula
																			\item so deleting Clause is not always good of course it makes the formula shorter but later during the solution process the solver goes the hard way to derive conflict clauses they are just resolved and added so it's not always good to delete clauses also it makes the formula shorter if you could add the good conflict clause in the beginning the solver would be much faster so it's not clear what helps
																			\begin{itemize}
																				\item exactly what the DP algorithm did but in contrast to DP algorithm we only apply it when the formula size does not explode typically you only eliminate a variable if the resulting formula is not larger than the original formula but you got rid of one variable. DP always has to eliminate one to make progress here we don't have to do it
																			\end{itemize}
																			\item \script{247}{Example}
																		\end{itemize}
																	\end{minipage}
																}
															}
													}
												child {
														node {Variable elimination by substitution
																\resizebox{\textwidth}{!}{
																	\begin{minipage}[t]{12cm}
																		\begin{itemize}
																			\item if clauses represent a gate like in the Tseitin transformation, these clauses can be removed and then every occurence of the variable that corresponds to the output of the gate has to be replaced by the other side of the equation for the remaning clauses
																			\item potentially saves variables, literals and clauses, it is applied only if it leads to a simplification of the formula
																			\item \script{248}{Example}
																		\end{itemize}
																	\end{minipage}
																}
															}
													}
												child {
														node {Forward subsumption and Backward subsumption
																\resizebox{\textwidth}{!}{
																	\begin{minipage}[t]{16cm}
																		\begin{itemize}
																			\item \alert{Forward Subsumption:} Test if a clause generated during one of the other preprocessing techniques is subsumed by one clause of the initial formula. Remove all the clauses subsumed
																			\item \alert{Backward Subsumption:} Test if a clause generated during one of the other preprocessing techniques subsumes one (or more) clauses of the initial formula. Remove all the clauses subsumed
																			% \item in principle you do subsumption checking whenever you add a clause to the clause database there's function add_clause that gets a new clause and adds it to the list of all clauses whenever you do that you can check for subsumption and there are two variables as the new Clause is the short one the subsuming clause the subset is newly added and the long one is already in the clause database or the other way around you have a short clause in the clause database and you want to add a new clause which is a super set of the one you already have in the first case when you add the short clause you can replace the long with the short in the second case where you add the long one you can just ignore it
																			\item can be done whenever new Clause is added to the Clause database and we distinguish between two cases the new Clause is the short one or the new Clause is the long one, can be done whenever new Clause is added to the Clause database and we distinguish between two cases the new Clause is the short one or the new Clause is the long one if the new Clause subsumes one of the already available Clauses it can replace the old one with the new one if the new Clause is subsumed by a clause we already have then we can just skip the addition and ignore the new clause the problem is the check has different costs \alert{forward checking} or forward subsumption checking is when you have the long clause and you want to add it now we the problem you have to run over all \alert{occurrence lists} of the literals in the long clause to check is there a subsuming clause \alert{backward subsumption} is better there you have the short clause to be added so we know all the literals of the short clause have to occur in the subsume long clause so we can run over just one \alert{occurrence list} of the literals in the short clause and we just pick the shortest one that's much faster therefore backwards subsumption is always done forwards subsumption only from time to time by just running over the whole database
																			% \item forward subsumption is you add the long one backward subsumption is you add the short one now why do we distinguish it really here because the running time of the check is completely different 
																			% \item backwards subsumption now one of the data structures in the preprocessor is typically the occurrence list so for every lital you have a list of all clauses which this lital occures so you have a list of X1 list for not X1 list for X2 for not X2 and so on so when you add the short clause how can you find all candidates that could be subsumed by the new clause if you add X1 X2 
																			% \item all candidates that can be subsumed by X1 X2 contain X1 and they also contain an X2 so you can look either at the occurrence list of X1 or at the occurrence list of X2 and you just pick the shorter one you have to only run over the shortest occurrences that's quite efficient 
																			% \item forward subsumption: you have the long clause, the only thing you know is the short clause contains at least one of the literals of the long clause so you have to run over all occurrence to find all possible candidates and running over all occurrences is worse than just running off the best one shortest one and therefore forward subsumption is expensive backward subsumption is quite cheap 
																			% \item backward subsumption is done all the time forward subsumption from time to time only 
																			\item \script{249}{Example}
																		\end{itemize}
																	\end{minipage}
																}
															}
													}
												child {
														node {Blocked Clause Elimination
																\resizebox{\textwidth}{!}{
																	\begin{minipage}[t]{12cm}
																		\begin{itemize}
																			\item let $C$ be a clause and $\ell \in C$ a literal, $C$ is blocked by $\ell$ \texttt{iff} for all clauses $D$ with $\neg\ell \in D$ holds: $C \otimes_{\ell} D$ is a tautology
																			\item \alert{Blocked clauses} can be deleted without changing satisfiability
																			\item you can show that deleting block Clauses does not change satisfiability the result is not a logically equivalent formula but only an equaly satisfiable formula
																			\item \script{250}{Illustration}
																			\item \videoseven{1239}{Explanation}, if all resolvents one gets when combinding C's with D's are tautologies, then one can delete C from the formula, all the resolvents that are tautologies can be ignored they are always satisfied and now the block clause elimination says if all the resolvents that you get when you combine C with the D's if all of them are tautologies then you can delete C from the formula because if you eliminated L it would not make any contribution that's called bloc close elimination
																			\begin{itemize}
																				\item \videoseven{1351}{Problem}, changes set of satisfying assignments, by deleting the block Clause you get more satisfying assignments so it might happen that the solver after block clause elimination gives you a satisfying assignment of the formula that does not satisfy the block clause that you deleted then you have to fix the assignment and the rule is if the block clause is not satisfied flip the value of l so the pre-processor has to remember which block clauses have been deleted in which order and when you get back the satisfying assignment from the solver core you check oh is that block clause satisfied if it is it's fine otherwise you flip the value of this blocking literal and you can prove that that assignment is a satisfying assignment for all clauses plus the block clause and you do that step by step until you have a satisfying assignment for the formula before you applied block clause elimination
																			\end{itemize}
																		\end{itemize}
																	\end{minipage}
																}
															}
													}
												child {
														node {Equivalent Literals
																\resizebox{\textwidth}{!}{
																	\begin{minipage}[t]{12cm}
																		\begin{itemize}
																			\item take only the binary clauses $\{\ell, \kappa\}$
																			\item create the \alert{binary clause graph}
																			\item all literals in strongly connected components can be replaced by one representative
																			\item if there is a path from $\neg \ell$ to $\ell$ for some literal $\ell$, we can replace $\ell$ by $1$
																			\item \script{251}{Illustrations}
																			\item \videoseven{1454}{Explanation}
																			\item \videoseven{1514}{Path $a$ to $\neg a$}, thus can directly assign $a$ to $0$
																			\begin{itemize}
																				\item \script{1612}{Loop $a$ to $a$, $\neg a$ to $\neg a$}, if we have one of the bath, we have the other path as well, thus the literals in the path always have the same value ($1\rightarrow 1\rightarrow 1$, $0\rightarrow 0\rightarrow 0$), thus can replace literal by other literal ($b$ by $\neg a$ and $c$ by $a$), got rid of two values
																				\item \videoseven{1781}{Example Strongly Connected Component}, you not only check for individual Loops but you check what for what is called strongly connected component, you can partition the nodes of each directed graph into these strongly connected components so every node is in one of the classes and all the classes are disjoint the and obviously all of these nodes are connected by loops so all all of these nodes are equivalent in that case, determine all the notes that are on one loop and then you can replace them by one representative and you get rid of the remaining ones
																			\end{itemize}
																		\end{itemize}
																	\end{minipage}
																}
															}
														child {
																node {Tarjan's strongly connected components algorithm
																		\resizebox{\textwidth}{!}{
																			\begin{minipage}[t]{12cm}
																				\begin{itemize}
																					\item \videoseven{1830}{Algorithm}
																					\item a \alert{connected component} is a subset of the nodes such that you can get from each node to each other node in the subset and a \alert{strongly connected component} is maximal such subset so make it as large as possible with the property from each node in this subset you can go to each other node in the subset
																				\end{itemize}
																			\end{minipage}
																		}
																	}
															}
														child {
																node {Binary clause graph
																		\resizebox{\textwidth}{!}{
																			\begin{minipage}[t]{12cm}
																				\begin{itemize}
																					\item only binary clauses $\{\ell, \kappa\}$
																					\item $G = (V, E)$ with
																					\begin{itemize}
																						\item $V = \{x, \neg x \mid x \text{ variable}\}$
																						\item $E = \{(\neg \ell, \kappa), (\neg \kappa, \ell) \mid \{\ell, \kappa\} \in \varphi\}$
																					\end{itemize}
																				\end{itemize}
																			\end{minipage}
																		}
																	}
															}
													}
											}
										child {
												node {Decision Heuristics
														\resizebox{\textwidth}{!}{
															\begin{minipage}[t]{12cm}
																\begin{itemize}
																	\item \script{275}{In the algorithm}
																	\item role of choosing the next Decision Variable
																	\begin{itemize}
																		\item comparable with \enquote{case distinction} in the DLL algorithm
																	\end{itemize}
																	\item \videoseven{2770}{Influence on running time}, the decision juristic has a great influence on the running time not only for satisfiable formulas that's obvious if you always guess the right value you will directly run to a satisfying assignment with no backtracking at all but it also helps for unsatisfiable formulas because the sooner a conflict appears the smaller parts of the search tree have to be traversed
																\end{itemize}
															\end{minipage}
														}
													}
												child {
														node {Classical decision heuristics
																\resizebox{\textwidth}{!}{
																	\begin{minipage}[t]{12cm}
																		\begin{itemize}
																			\item among the unassigned variables, choose the one that occurs more frequently in the currently unsatisfied clause
																			\begin{itemize}
																				\item in most cases also weighted with the length of those clauses
																				\item \videoseven{2851}{In other words}
																			\end{itemize}
																			\item \videoseven{2901}{Drawback}, run over all clauses, test if unsatisfied and count number of literals or with counter, but have to be update counters again when backtracking, because number of unsatisfied clauses changed, not worth it, too costly
																			\item \underline{Complexity:} These heuristics are quite time consuming, because both the status of each clause and the distribution of the variables in the (learned) clauses have to be computed and kept up to date
																			\begin{itemize}
																				\item computation complexity determined by \#Clauses
																			\end{itemize}
																			\item \script{277}{Summary}
																		\end{itemize}
																	\end{minipage}
																}
															}
													}
												child {
														node {Variable State Independent Decaying Sum (VSIDS)
																\resizebox{\textwidth}{!}{
																	\begin{minipage}[t]{12cm}
																		\begin{itemize}
																			\item today’s standard method used by every SAT solver
																			\item every literal gets counted ($x_i$ and $\neg x_i$ are two different literals)
																			\item $P_{x_i} = P_{x_i} + 1 \text{ if } L = x_i$, $N_{x_i} = N_{x_i} + 1 \text{ if } L = \neg x_i$
																			\begin{itemize}
																				\item initially, $P_{x_i}$ ($N_{x_i}$) equals the number of occurrences of $x_i$ ($\neg x_i$ ) in the original CNF (number of clauses that contain $x_i$)
																				\item unassigned variable $x_i$ with the highest activity (counter value) ($P_{x_i}$ or $N_{x_i}$) is chosen as decision variable, valuation depends on whether $P_{x_i} > N_{x_i}$ holds or not, take Heap where can get maximum cheaply
																				\item only increase counter values of literals in the conflict clauses
																			\end{itemize}
																			\item \underline{Complexity:} No update is needed for assignments and backtracks, since values do not depend on variable state
																			\begin{itemize}
																				\item \alert{variable state independent} $\hat =$ it does not matter in which state the clauses are, don't look at state of the clauses
																				\item \videoseven{3033}{Advantage}, if conflict clause only $10$ variables then only have to increase $10$ values
																				\item computation complexity determined by \#Variables
																			\end{itemize}
																			\item periodically, the activities are \enquote{normalized}, i. e., divided by a constant factor
																			\begin{enumerate}[label=$\Rightarrow$]
																				\item that's the \alert{decaying sum part}
																				\item after the normalization, the recently learned clauses have a higher weight in comparison with the clauses learned before that last normalization
																				\item takes into account the \enquote{history} of the search process
																				\item \videoseven{3157}{Intuition}, want to run into conflicts early don't go deep into serach tree, make variables more relevant if they contribute to a conflict often, make old conflicts contribute less, because probably they are already in a different part of the search space where they are not relevant
																			\end{enumerate}
																			\item \script{279}{Several optimizations possible}
																			\item \script{278}{Summary (f.)}
																		\end{itemize}
																	\end{minipage}
																}
															}
													}
											}
										child {
												node {Boolean Constraint Propagation (BCP)
														\resizebox{\textwidth}{!}{
															\begin{minipage}[t]{12cm}
																\begin{itemize}
																	\item \script{281}{In the algorithm}
																	\item \underline{Tasks}
																	\begin{itemize}
																		\item detecting all the implications from the assignment of a variable (i.e. find all unit clauses until there are no unit clauses)
																		\item detecting conflicts
																	\end{itemize}
																	\item comparable to the repeated application of the unit rule in the DLL algorithm
																	% \item efficient implementation mandatory, because roughly 80\% of the runtime of a SAT algorithm is spent in the BCP routine
																	\item \script{283}{General procedure}
																	\begin{itemize}
																		\item in principle easy task, two cases, either all clauses false except one that is unassigned, then one has an implication, or all clauses false then one has a conflict, but checking that would be too slow
																		\item \videoseven{3377}{do better:} when you assign X1 to one then the clause that does not contain X1 or not X1 is not affected all clauses that contain X1 are satisfied so they are irrelevant for the moment all claueses that contain not X1 they could have become unit clause or unsatisfied clause so the first optimization is do not run over all clauses but only run over the clauses in the occurrence list of not x1 okay
																		\item but you can do even better
																	\end{itemize}
																	\item \script{284}{Example (ff.)} with \videoseven{3478}{Explanation}
																	\item largest part of the solution time is spend for BCP ($\approx 70 / 80\%$)
																	\item \script{282}{Summary (ff.)}
																\end{itemize}
															\end{minipage}
														}
													}
												child {
														node {Counter-Based Schemes
																\resizebox{\textwidth}{!}{
																	\begin{minipage}[t]{12cm}
																		\begin{itemize}
																			\item \underline{2-Counter Scheme:}
																			\begin{itemize}
																				\item two counters for each clause
																				\begin{itemize}
																					\item one counter for the literals which satisfy the clause
																					\item one counter for the unassigned literals (aka “open” literals)
																					\item[$\Rightarrow$] a clauses is unit if the first counter is $0$ and the second one is $1$
																					\item[$\Rightarrow$] a clause is a conflict clause if the first one is $0$ and the second is also $0$
																				\end{itemize}
																			\end{itemize}
																			\item \underline{1-Counter Scheme:}
																			\begin{itemize}
																				\item one counter for each clause to count the number of not falsified literals
																			\end{itemize}
																			\item \underline{Disadvantages:}
																			\begin{itemize}
																				\item \enquote{unnecessary} counter updates
																				% \item all counter based schemes have the drawback that one has to do work when one does backtracking, because the number of anassigned literals changes all the time
																				\item adjustment of the counter values during the backtracks
																				\item need a list for each variable and polarity to store all the clause where the \enquote{related literal} (variable having that polarity) occurs (called \alert{occurrences list})
																				% \item the problem is you have to update the counters all the time, make a variable assignment you have to update them when you do backtracking you have to update them it's quite costly therefore people have invented other techniques but don't have that update work all the time and they are called a watch LS
																			\end{itemize}
																		\end{itemize}
																	\end{minipage}
																}
															}
													}
												child {
														node {Watched Literals / 2-Literal Watching Scheme
																\resizebox{\textwidth}{!}{
																	\begin{minipage}[t]{12cm}
																		\begin{itemize}
																			\item \underline{Idea:} As long as a clause contains two unassigned (or one satisfied) literal, it can not be a unit clause and the exact number of unassigned literals is not important
																			\begin{itemize}
																				\item we do watch two because two is the smallest number of literals you need to be unassigned such that none of these base cases appears
																			\end{itemize}
																			\item for each clause mark two different literals
																			\item \underline{Invariant:} The watched literals of a clause are either unassigned or satisfy the clause
																			\begin{itemize}
																				\item if that invariant becomes violated you try to reestablish it by finding another citeral in the clause chich still satisficonflict the invariant if that's not possible there are two cases clause is unit or clause is conflict
																			\end{itemize}
																			\item \underline{Advantages:}
																			\begin{itemize}
																				\item update operations only when necessary, i.e., when an assignment \enquote{breaks} the invariant
																				\begin{itemize}
																					\item another advantage with backtracking all the watches that point to an unassigned literal still point to an unassigned literal after backtracking because they only remove assignments and for the unit clause or for the conflict clause you just undo the assignment flip the decision and put it one level down such that this clause become satisfied so nothing bad happens when you do backtracking you don't have to move the watch pointers doing nothing is always fast just to backtrack and ignore the watch points they will still be valid after backtracking
																				\end{itemize}
																				\item one list for each variable and polarity (like above) containing only the clauses currently watching that literal
																				\begin{itemize}
																					\item very often one does not look (if it's not a unit clause), when you just use the occurrence list and you assign X1 to one you look at all the clauses that contain a not X1 with the watch literals you only look at those Clauses in which not X1 is watched and if you have long clauses it's quite unlikely that exactly the not X1 is watched you only look at a small subset of all clauses that contain the not X1
																				\end{itemize}
																			\end{itemize}
																			\item \underline{Disadvantages:} The literals of a clause are checked several times
																			\item \script{297}{Example}
																			\begin{itemize}
																				\item \videoseven{3924}{Explanation}, don't have unit clauses because Pre-Processor already deleted them, if know there are two unassigned literals don't have to look at the clause which is faster
																			\end{itemize}
																			\item \underline{Possible optimizations:}
																			\begin{itemize}
																				\item store the watched literals in the first two positions (memory \enquote{cells}) of a clause
																				\begin{itemize}
																					\item makes it possible to access to the \enquote{second} watched literal of a clause fast, as well as its status
																					\item if the second watched literal satisfies the clause, it is not necessary to find a replacement for the first one, if this is in turn falsified
																				\end{itemize}
																				\item \videoseven{4285}{Explanation}, they always swap the literals such that the watch literals appear at the first two positions in the clause and if one of the watches points to a satisfied literal it's always moved to the first position so checking if the clause is satisfied just looking at the first position in the clause finding the watches is always looking at the first two positions of the clause you don't have to search for the watch point
																			\end{itemize}
																			% \item watched Literal schemes have been used in all the modern SAT solvers in the last years
																		\end{itemize}
																	\end{minipage}
																}
															}
													}
											}
										child {
												node {Conflict Analysis and Backtracking
														\resizebox{\textwidth}{!}{
															\begin{minipage}[t]{12cm}
																\begin{itemize}
																	\item \script{300}{In the algorithm}
																	\item comparison of \script{301}{DLL algorithm} and \script{303}{Modern SAT Algorithms}
																\end{itemize}
															\end{minipage}
														}
													}
												child {
														node {Backtracking
																\resizebox{\textwidth}{!}{
																	\begin{minipage}[t]{12cm}
																		\begin{itemize}
																			\item in today’s SAT algorithms the backtrack level is only determined by the resulting conflict clause
																			\item the backtrack level matches the maximum decision level among all the literals in the conflict clause except the UIP literal, that means with the exception of the literal assigned at the current decision level, which is conflicting by definition
																		\end{itemize}
																	\end{minipage}
																}
															}
														child {
																node {Chronological Backtracking
																		\resizebox{\textwidth}{!}{
																			\begin{minipage}[t]{12cm}
																				\begin{itemize}
																					\item is what one has seen, go back to the last decision and keep it
																					\begin{itemize}
																						\item DLL Chronological Backtracking undo always the last decision and if there's no last decision the formula is unsatisfiable
																						\item only remove topmost level
																					\end{itemize}
																					\item \script{302}{Example}
																					\begin{itemize}
																						\item \videoseven{4489}{Explanation}
																					\end{itemize}
																				\end{itemize}
																			\end{minipage}
																		}
																	}
															}
														child {
																node {Non-Chronological Backtracking
																		\resizebox{\textwidth}{!}{
																			\begin{minipage}[t]{12cm}
																				\begin{itemize}
																					\item \underline{Idea:} \enquote{What would have happened if the conflict clause had already been contained in the original CNF formula?}
																					\begin{itemize}
																						\item backtrack as far as possible such that a conflict clause stays a unit clause
																						\begin{itemize}
																							\item \videoeight{2331}{Exmaple: How far can backtrack}
																						\end{itemize}
																						\item \videoeight{2417}{What non-chronological backtracking does}, it takes the second highest level of the literals in the conflict clause and that's the one that remains everything above is removed
																					\end{itemize}
																					\item \script{318}{Procedure}
																					\begin{itemize}
																						\item if a conflict appears at decision level $0$, the CNF formula is unsatisfiable
																					\end{itemize}
																					\item \videoseven{4518}{Explanation: Conflict analysis}
																				\end{itemize}
																			\end{minipage}
																		}
																	}
															}
													}
												child {
														node {Conflict Analysis
																\resizebox{\textwidth}{!}{
																	\begin{minipage}[t]{12cm}
																		\begin{itemize}
																			% \item whenever we get a contradicting assignment conflict analysis starts and analyzes this one
																			\item during the conflict analysis the \alert{implication graph} is traversed backwards (in reverse order of the assignments in the decision stack) starting from the conflicting point, to allow to compute the series of resolution steps which finally lead to the \alert{conflict clause}
																			\item different termination criteria for interrupting the resolution steps lead to different conflict clauses
																			\item \script{306}{Implementations}
																			\item \script{307}{Example for Conflict Analysis (ff.)}
																			\begin{itemize}
																				\item \videoseven{4956}{Explanation: Conflict Analysis}, anavoidable for literals of resolution of two clauses, that resolvent clause is called \alert{conflict clause}, one of the assignments has to be different and the condition for that is exactly the resolvent of the two clauses that contain the two literals causing the conflict (clauses are OR), so the resolvent just tells us change one of the assignments that lead to the conflict and that's what is called a conflict clause the first observation is the conflict Clause is a resolvent and that means we can add it to the formula and get a logically equivalent formula
																				\item \videoeight{1034}{Explanation: Further options}, so we take the old conflict Clause from the previous step and we solve it with the unit clause that generated this node in the graph, we just go backwards on the topmost level of the decision stack, when ever you have an implication on the topmost level it comes from unit clause, all the literals except the first one have an associated unit clause so the reason why it was put on the decision stack, can always add resolvents to the formula according to resolution lemma, negate assignment that lead to box and get exactly that clause, in principle you can continue until get decision, only it on decision stack left, because a decision has no corresponding unit clause and one cannot do resolution
																			\end{itemize}
																		\end{itemize}
																	\end{minipage}
																}
															}
														child {
																node {(1st) Unique Implication Point (UIP and 1UIP)
																		\resizebox{\textwidth}{!}{
																			\begin{minipage}[t]{18cm}
																				\begin{itemize}
																					\item \underline{Observation:} Many partitions of the implication graph into \enquote{conflict side} and \enquote{reason side} are possible
																					\item a node in the implication graph is called a \alert{Unique Implication Point} (UIP) \textit{iff} all paths from the decision variables of the current decision level to the conflict variable go through this node
																					\begin{itemize}
																						\item \alert{unique implication point}: it's a node in the graph through which all the paths have to go when you go from the decision on the top level to the conflict, you have a node in graph which is the decision on the topmost level and you have the two conflict notes and you look at all the paths that go from the decision to the conflict and if all paths go to the same node that's called a unique implication point
																						\item the set of UIPs is not empty. The node with the decision variable of the current decision level is a Unique Implication Point
																						\item \videoeight{1785}{Explanation: Example}, decision itself is always a unique implicationo point, only look at blue nodes reachable from decision at top level
																						\item the \alert{1st Unique Implication Point} (1UIP) is the UIP that is closest to the conflict variable
																						\begin{itemize}
																							\item \underline{the rule is:} Stop whenever the next literal you would resolve on is unique implication point
																							\item \videoeight{2010}{How used and why always works}, now you do resolution going back on the topmost level of the decision stack until you would as the next step resolve on the unique implication point and then you stop, that always works because you always have a unique implication point, in doubt the decision is always a unique implication point
																						\end{itemize}
																					\end{itemize}
																					\item \videoeight{2172}{How they work}, what happens to the conflict clause when ones remove the assignment on the top level level it becomes a unit the decision variable is unassigned the remaining are still false so if you add it to the clause database you have added the unit clause, you don't have to make a decision afterwards you just add the conflict clause and call TCP and the conflict clause will take care that you run away from this conflict because it forces you to assign the decision variable fo this level differently than before
																					\begin{itemize}
																						\item \videoeight{2228}{Why are good}, that's why unique implication points are good because they lead to conflict clauses with exactly one literal from the highest level if you don't have an unique implication point you have at least two literals from the highest level and when you do backtracking both get unassigned and that leads you in a state where you don't know what to do you cannot just call BCP because you have two options of for satisfying the conflict clause but when you have a unique implication point the conflict clause becomes a unit clause by backtracking and you can just call BCP and it tells you what to do
																					\end{itemize}
																					\item an \alert{asserting clause} is a clause with exactly one literal from the current decision level
																					\item \underline{Observation:} A partition with a UIP on the reason side and all successors of the UIP on the conflict side leads to an \alert{asserting clause} as a \alert{conflict clause}
																					\item \alert{1UIP scheme}: Use the 1UIP for constructing an (asserting) conflict clause
																					\begin{itemize}
																						\item conflict analysis according to the \alert{1UIP scheme} terminates as soon as the currently computed resolvent contains exactly one literal which was assigned at the decision level being analyzed at that moment (the highest), whereas all other literals were assigned at lower decision levels
																						\item \alert{conflict clauses} represent combinations of variables that will inevitably lead to a conflict
																						\item \alert{Resolution Lemma} allows to insert the conflict clauses into the CNF formula, and consequently to \enquote{prune} the whole search tree (they prevent the algorithm from running into identical conflicts)
																						\begin{itemize}
																							\item \videonine{5022}{Meaning of Resolution}, you don't want to get that assignment again
																						\end{itemize}
																						\item compared to others, the \alert{1UIP scheme} turned out to be the most powerful (shorter conflicts clauses, more effective pruning, faster runtime)
																					\end{itemize}
																				\end{itemize}
																			\end{minipage}
																		}
																	}
															}
														child {
																node {Implication Graph
																		\resizebox{\textwidth}{!}{
																			\begin{minipage}[t]{12cm}
																				\begin{itemize}
																					% \item data structure for performing the conflict analysis in today’s SAT algorithms 
																					\item Directed, acyclic graph
																					\begin{itemize}
																						\item Nodes represent assignments to variables
																						\begin{itemize}
																							\item decision nodes have no incoming edge, they have only outgoing edges
																						\end{itemize}
																						\item Edges reflect which set of assignments have caused an implication (correspond the precondition of getting an unit clause)
																					\end{itemize}
																					\item the implication graph is updated at every variable assignment and every backtrack operation of the search process
																					\item \script{304}{Example for Edges Implication} and \script{305}{Example for Implication graph}
																					\begin{itemize}
																						\item \videoseven{4605}{Explanation for Edges} and \videoseven{4665}{Explanation for Implication graph}
																					\end{itemize}
																				\end{itemize}
																			\end{minipage}
																		}
																	}
															}
													}
											}
										child {
												node {Unlearning
														\resizebox{\textwidth}{!}{
															\begin{minipage}[t]{12cm}
																\begin{itemize}
																	\item \script{320}{In the algorithm}
																	\item Modern SAT algorithms produce a conflict clause for each conflict and add it to the set of clauses
																	\item \underline{Problems:}
																	\begin{itemize}
																		\item Risk of memory overflow
																		\item Significant slowdown of the BCP routine
																	\end{itemize}
																	\item \underline{Solution:} Periodic deletion of conflict clauses
																	\item the following clauses are excluded from deletion:
																	\begin{itemize}
																		\item those of the original CNF formula
																		\item those which are used in the current implication graph
																	\end{itemize}
																	\item it is important to find a good compromise between $\ldots$
																	\begin{itemize}
																		\item the deletion of information, and
																		\item the avoidance of the above stated problems
																	\end{itemize}
																	\item \underline{possible criteria for conflict clause deletion:}
																	\begin{itemize}
																		\item delete clauses whose length exceeds a predefined value
																		\item delete “old” and/or “inactive” conflict clauses
																		\begin{itemize}
																			\item the age of a clause results from the order of learning
																			\item the activity of a clause is increased every time this clause is involved in a resolution step of some following conflict analyses
																			$\Rightarrow$ active clauses are often used to derive conflicts
																		\end{itemize}
																	\end{itemize}
																\end{itemize}
															\end{minipage}
														}
													}
											}
										child {
												node {Restarts
														\resizebox{\textwidth}{!}{
															\begin{minipage}[t]{12cm}
																\begin{itemize}
																	\item \script{324}{In the algorithm}
																	% \item possibility that SAT algorithms perform search in less promising areas of the search tree
																	\item \underline{basic idea}:
																	\begin{itemize}
																		\item the longer a SAT algorithm searches for a model with no result, the higher the probability that $\ldots$
																		\begin{itemize}
																			\item the solver is looking in an unsatisfiable part of the search space
																			\item at previous branches, it made \enquote{wrong} decisions
																		\end{itemize}
																	\end{itemize}
																	\item \underline{procedure:} from time to time
																	\begin{enumerate}
																		\item stop the search routine
																		\item undo all assignments except from those at decision level 0
																		\item restart the search with decision level 1
																	\end{enumerate}
																	\item keep the clauses already learned
																	\item variable activities remain unchanged
																	\item \underline{compared to the previous search, good chance that:}
																	\begin{itemize}
																		\item other variables are chosen at lower decision levels
																		\item the search process goes into another direction
																	\end{itemize}
																	\item infinite loops are generally avoided by continuously increasing the interval between two restarts
																	% \item \underline{several optimizations possible:}
																	%   \begin{itemize}
																	%     \item when should the first restart take place?
																	%     \item by how much should the interval between two restarts be increased?
																	%   \end{itemize}
																	\item restarts are not only useful to accelerate the process in case of satisfiable CNF formula, but also in case of unsatisfiable ones
																\end{itemize}
															\end{minipage}
														}
													}
											}
									}
								child {
										node {Differences to DLL
												\resizebox{\textwidth}{!}{
													\begin{minipage}[t]{14cm}
														\begin{itemize}
															\item \underline{Differences:}
															\begin{itemize}
																\item \script{228}{Difference $1$: Recursion and modification of formula (f.)}
																\begin{itemize}
																	\item \underline{DLL}:
																	\begin{itemize}
																		\item recursive procedure
																		\item for the transition from the recursion level $r$ to the level $r + 1$ the given formula is modified (clauses being satisfied are removed and \enquote{unsatisfied literals} are erased)
																		\item for backtracking from level $r + 1$ to $r$ the original (sub)formula at level $r$ must be restored
																	\end{itemize}
																	\item \underline{Modern SAT}:
																	\begin{itemize}
																		\item non-recursive procedure
																		\item apart from special cases, during the search process neither satisfied clauses nor resolved literals are removed from the CNF formula no removal from CNF formula
																		\item usually the \alert{pure literal} rule is not applied, overhead for detecting pure literals is larger than what it helps. Pure literals can occur after preprocessing when you assign variables and you can ignore the satisfied clauses and in the remaining not yet satisfied sources there can be pure literals. \alert{Subsumption check} is applied by modern SAT-algorithms only during preprocessing. \alert{Variable elimination} is applied by modern SAT during preprocessing. Here elimination of a variable is only done if it reduces the formula size (or only slightly increases it)
																		\item we never modify clauses except in pre-processing
																	\end{itemize}
																\end{itemize}
																\item \script{230}{Difference $2$: Unit clause definition (f.)}
																\begin{itemize}
																	\item In DLL a clause is made of exactly one literal. In modern procedures also the clauses where all the literals but one are assigned with negated polarity are denoted with the term unit clause. \script{231}{Example of implication}
																	\item \script{232}{Boolean Constraint Propagation (BCP) or Unit Propagation and example}: Determining all the implications forced by the assignment of a variable
																\end{itemize}
																\item \script{233}{Difference $3$: Contradiction / conflict (f.)}
																\begin{itemize}
																	\item empty clause for DLL, Unsatisfied clause for modern SAT algorithms in which all literals are assigned to false. \script{233}{Example}
																\end{itemize}
																\item \script{234}{Difference $4$: Conflict analysis and backtracking: (f.)}
																\begin{itemize}
																	\item \underline{DLL:} The combination of the previously done decisions will always be considered as the origin of a conflict. Backtracking (recursive back tracing) to the recursion level of the last \enquote{branching} in which one case for a variable assignment has not been explored yet. If none exists the given CNF formula is unsatisfiable. Backtracking always goes back one decision level
																	\item \underline{Modern SAT:} Complex and deep analysis of the conflict setting, because not all the previously made \enquote{branchings} must be involved in the current conflict Derivation via resolution and learning of a \alert{conflict clause} for the given formula. The conflict clause avoids to run into the identical conflict again by including all the literals that are responsible (because of their assignment) for the current contradiction. Backtrack with the help of the conflict clause or output UNSATISFIABLE. What are the actual assignments that led to the conflict and rule out the ones that are not involved in the conflict
																\end{itemize}
															\end{itemize}
														\end{itemize}
													\end{minipage}
												}
											}
									}
								child {
										node {Decision Stack
												\resizebox{\textwidth}{!}{
													\begin{minipage}[t]{12cm}
														\begin{itemize}
															% \item Central data structure of modern SAT algorithms
															\item stores the order of the executed assignments
															\item if a model for a CNF formula could be found, the decision stack stores the satisfying assignment
															\item each variable assignment has an associated decision level
															\begin{itemize}
																\item decision level is initialized with $0$; before a decision is made, it is incremented by one; backtracking decrements the decision level appropriately
																\item decision level $0$ plays a special role: it stores only implications from unit clauses in the original formula, but no decisions
																\item a conflict on decision level $0$ means that the CNF is unsatisfiable
															\end{itemize}
															\item \script{253}{Illustration}
															\item \script{255}{Example 1: Satisfiable (ff.)}, if we had unit clauses they would first put on letter zero and then we start with the first decision that ends up on level one, all literals in clause red means conflict, because all false, \videoseven{2335}{Explanation}, for $x_3$ decision heuristiry is the reason for value $1$, as soon as all the Clauses are satisfied you cannot run into a conflict anymore then you can just take the value the decision heuristic returns, \videoseven{2596}{Case if $x_2=1$}, if you have a unit Clause BCP is telling us what to do if you don't have a unit clause the decision us just guesses and sometimes it guesses badly like in our first try in the first attempt it's sign X1 to 1 which was obviously wrong but it didn't know better
															\item \script{265}{Example 2: Unsatisfiable (ff.)}
															\item \videoseven{2014}{Explanation}, every level except level zero starts with a decision typically you call the decision heuristic that tells you here in this example assign X6 to zero every decision opens a new decision level so and the first decision ends up always of level one level zero can be empty then you call BCP BCP detects all the implications resulting from the decision every time you make a decision you open a new decision level and the lital that was made true by decision heuristic is the first entry, calling BCP adds further literals to the same decision level, \alert{chronological backtracking} takes the topmost level clears it and puts the decision I variable negated one level down, \videoseven{2141}{Example (Chronological) Backtracking}
															\item \videoseven{2256}{Get Entries on Level $0$}, unit clauses before make decision, but preprocessing eliminates unit clauses, if you have a conflict on level, on level 0 conflict formula is unsatisfiable because there's no decision you can flip, all the entries on level 0 exist because one has no other choice
														\end{itemize}
													\end{minipage}
												}
											}
									}
								child {
										node {Termination
												\resizebox{\textwidth}{!}{
													\begin{minipage}[t]{12cm}
														\begin{itemize}
															\item Modern SAT algorithms do not test whether the CNF formula is already satisfied during the search, rather it is indirectly guaranteed from assigning all the variables without running into a conflict
															\begin{itemize}
																\item \script{276}{Example}
																\item if the decision juristic has nothing to do anymore, meaning all the variables are assigned then the formula is satisfiable so that also means we do not check if the formula is already satisfied that might happen before all the variables are assigned but a solver does not detect that it just runs until all variables are assigned and if no conflict has happened the formula satisfied why is that the case because it's cheaper to just run until all variables are assigned then detecting if the formula satisfied so nobody checks if the formula satisfied because that requires running overall clauses and in between you sometimes do just unlearning and restarts and so on
															\end{itemize}
															\item \underline{Observation:} Due to conflict analysis, learning, and non-chronological backtracking, it seems that modern SAT solvers roam \enquote{wildly} in the search space
															\item \script{329}{Argumentation why termination is given (f.)}
														\end{itemize}
													\end{minipage}
												}
											}
									}
								child {
										node {Aspects without more details
												\resizebox{\textwidth}{!}{
													\begin{minipage}[t]{12cm}
														\begin{itemize}
															\item \script{332}{Overview}
														\end{itemize}
													\end{minipage}
												}
											}
									}
							}
					}
				child {
						node {And-inverter graphs (AIGs)
								\resizebox{\textwidth}{!}{
									\begin{minipage}[t]{12cm}
										\begin{itemize}
											\item AIGs are a class of circuits which consist only of AND gates and inverters:
											\begin{itemize}
												\item Nodes represent AND gates
												\item Negated edges represent inverters
											\end{itemize}
											\item Efficient data structure, since there is only one type of nodes (inverters are stored as last bit of pointers)
											\item Apart from exor/exnor all binary operations can be represented using only one AIG node
											\item AIGs do not provide a canonical representation
											\begin{itemize}
												\item \script{340}{Example (ff.)}, thus, combinational equivalence checking cannot be reduced to an isomorphism check on AIGs
											\end{itemize}
											\item \script{344}{Combinational Equivalence Checking with AIGs}
											\begin{itemize}
												\item \script{345}{Example (f.)}
											\end{itemize}
											\item \script{348}{Normalization rules (f.)}
											\begin{itemize}
												\item \script{350}{Limits of Normalization Rules (ff.)}
											\end{itemize}
										\end{itemize}
									\end{minipage}
								}
							}
						child {
								node {Functionally Reduced AIGs (FRAIGs)
										\resizebox{\textwidth}{!}{
											\begin{minipage}[t]{12cm}
												\begin{itemize}
													\item not canonical, but \enquote{\alert{semi-canonical}}, can be used to normalize and compress circuits representations
													\item \underline{maintain the invariant:} There is no pair of two nodes in a FRAIG which represent the same Boolean function (or a function and its negation)
													\begin{itemize}
														\item by this invariants, FRAIGs are sufficient for combinational equivalence checking.
													\end{itemize}
													\item \script{362}{Building Option 1}
													\begin{itemize}
														\item \script{365}{Example (ff.)}
													\end{itemize}
													\item \script{374}{Building Option 2}
													\begin{itemize}
														\item \script{376}{Example (ff.)}
													\end{itemize}
												\end{itemize}
											\end{minipage}
										}
									}
							}
					}
			}
		child {
				node (test) {Property checking
						\resizebox{\textwidth}{!}{
							\begin{minipage}[t]{12cm}
								\begin{itemize}
									\item Prove that a system specifies a set of properties
								\end{itemize}
							\end{minipage}
						}
					}
				child {
						node {Specification of properties with temporal logics}
					}
				child {
						node {Algorithms for checking properties of circuits}
					}
				child {
						node {Bounded model checking using SAT solvers}
					}
				child {
						node {Unbounded model checking}
						child {
								node {K-Induktion}
							}
						child {
								node {Craig interpolation}
							}
						child {
								node {Property directed reachability (PDR)}
							}
					}
			}
		child {
				node {Equivalence checking
						\resizebox{\textwidth}{!}{
							\begin{minipage}[t]{12cm}
								\begin{itemize}
									\item Prove that two designs have the same (functional) behavior
									\item Given two combinational circuits (i.e., without memory), do they compute the same boolean function?
									\item So one can't do better in all cases, doesn't work for all practical cases, but for many:
									\begin{itemize}
										\item Combinational Equivalence Checking is NP-hard, if there would be polynomial data in a canonical datastructure one would just have to translate both circuits into this datastructure and comparison is easy, can't assume there's a datastructure with polynomial size which is canonical
										\item some function tables are so random, it's not possible to compress them
										\item canonical disjunctive normal form, then one has as many terms as elements in the ON-Set
									\end{itemize}
								\end{itemize}
							\end{minipage}
						}
					}
				child {
						node {Combinational circuits}
						child {
								node {Application of BDDs and SAT for equivalence checking
										\resizebox{\textwidth}{!}{
											\begin{minipage}[t]{12cm}
												\begin{itemize}
													\item \alert{Equivalence Checking Method:} Convert each circuit into a datastructure that has exactly one representation of each Boolean function. Then compare these representations
													\item in \alert{BDD-based} equivalence checking the limiting resource is the \alert{available memory}, whereas in the \alert{SAT-based} approach this is the \alert{runtime} (exponential in the size of the formula) of the solving algorithm
													\begin{itemize}
														\item size of the formula will be linear in the size of the circuit, so if one can get the circuit into memory, one can also get the formula into memory
													\end{itemize}
												\end{itemize}
											\end{minipage}
										}
									}
								child {
										node {SAT-based Equivalence Checking
												\resizebox{\textwidth}{!}{
													\begin{minipage}[t]{12cm}
														\begin{itemize}
															\item \script{135}{Approach}
															\item \script{139}{Miter Circuit with multiple outputs (f.)}, convert Miter Circuit into propositional logic formula with the property of being satisfied if the miter circuit outputs a $1$ and the Miter circuit has the property that it's output is $1$ for a certain input assignment if the circuits behave differently
															\item usually SAT-algorithms take as input only CNF formulas; that means the Boolean function of the miter circuit must be translated into a CNF representation
															\item \script{162}{Example}
														\end{itemize}
													\end{minipage}
												}
											}
										child {
												node {Conversion of a Propositional Logic Formula into CNF
														\resizebox{\textwidth}{!}{
															\begin{minipage}[t]{12cm}
																\begin{itemize}
																	\item every propositional logic formula $F$ can be translated into an equivalent CNF formula $F'$
																	\begin{itemize}
																		\item \script{144}{Proof}
																	\end{itemize}
																\end{itemize}
															\end{minipage}
														}
													}
												child {
														node {Satisfiability equivalent CNF (Tseitin Transformation)
																\resizebox{\textwidth}{!}{
																	\begin{minipage}[t]{16cm}
																		\begin{itemize}
																			\item it doesn't work good to turn formula into equivalent CNF formula, instead turn miter circuit into formula that is satisfiable \textit{iff} the original two circuits are not equivalent. Don't need the same output for all possible assignments, only need satisfiable \textit{iff} not equivalent. Not logically equivalent to normal CNF,
																			\item one gives up \alert{logical equivalence} and only requires \alert{equisatisfiability} because because in the formula $X\oplus Y$ you cannot assign the output variable $Z$ in the wrong way, but in the formula $Z \equiv X \oplus Y$ you can, because of the additional variables that would not be assigned in the original formula
																			\item define for $F$ an \alert{equisatisfiable} CNF $F'$ that is satisfiable \textit{iff} $F$ is satisfiable. Every line in the circuit has variable, not only the outputs % ist satisfiable gdw. andere seite....
																			\item \script{152}{Algorithm for conversion into \alert{satisfiability equivalent} CNF}
																			\item \script{153}{Gates}
																			\item \script{155}{Example (ff.)}, satisfying assignments of the formula are exactly the consistents assignments of the circuit, all the output has to be derived using the gate function from the gate, that does not mean one gets a $1$ at the output \script{157}{Example for reason for unit clause in the last line}, all clauses satisfied but output is $0$, can only satisfy this clause if assign output of the circuit to $1$, first 3 lines say that we need a consistent assignment, the output of each gate has to match the gate function applied to the inputs and last line says output must be $1$, this formula is satisfiable \textit{iff} there's a input assignment that makes the output $1$
																			\item as long as for the CNF representation of each single gate only a constant number of clauses is required, the number of clauses in the final CNF will be linear in the number of gates in the circuit (the same holds for the size of the formula)
																			\item \script{159}{Size comparison to equivalent CNF}, linear in the size of the circuit
																		\end{itemize}
																	\end{minipage}
																}
															}
													}
												child {
														node (convcnf) {Equivalent CNF
																\resizebox{\textwidth}{!}{
																	\begin{minipage}[t]{14cm}
																		\begin{itemize}
																			\item \script{145}{Algorithm for conversion into \alert{equivalent} CNF}, move nots inside the formula until they only appear directly in front of variables, elimnate double negation, move ands outside with distributivity
																			\begin{itemize}
																				\item \script{148}{Examples (ff.)}, already shortest CNF for the formulas
																			\end{itemize}
																			\item \script{146}{Size of a formula}, in wost case formula increases exponentialy in size
																			\begin{itemize}
																				\item \script{147}{Proof}
																			\end{itemize}
																		\end{itemize}
																	\end{minipage}
																}
															}
													}
											}
									}
							}
						child {
								node {Exploitation of structural information}
							}
					}
				child {
						node {Sequential circuits
								\resizebox{\textwidth}{!}{
									\begin{minipage}[t]{12cm}
										\begin{itemize}
											\item \script{456}{Definition and difference to Combinational}
											\item \script{458}{State}
											\item \script{462}{Notations}
										\end{itemize}
									\end{minipage}
								}
							}
						child {
								node {Deterministic Finite Automata (DFA)
										\resizebox{\textwidth}{!}{
											\begin{minipage}[t]{12cm}
												\begin{itemize}
													\item \script{459}{Definition}, also called \alert{transducer}
													\begin{itemize}
														\item \script{464}{Semantics of Transducers}
													\end{itemize}
													\item \script{460}{Illustration}
												\end{itemize}
											\end{minipage}
										}
									}
								child {
										node {Equivalence
												\resizebox{\textwidth}{!}{
													\begin{minipage}[t]{12cm}
														\begin{itemize}
															\item \script{468}{Equivalence of Finite Automata}
															\item \script{471}{Combinational equivalence checking}, Identical State Encoding
															\item \script{473}{Behavioral Equivalence w.r.t. a State Correspondence}
															\item \script{477}{Equivalent States}
															\begin{itemize}
																\item \script{477}{Theorem: Implication for equivalent states}
																\item \script{480}{Theorem: Equivalence for DFA's}
															\end{itemize}
														\end{itemize}
													\end{minipage}
												}
											}
									}
								child {
										node {Product Automaton
												\resizebox{\textwidth}{!}{
													\begin{minipage}[t]{12cm}
														\begin{itemize}
															\item \script{481}{Definition}
															\item \script{482}{Equivalence}
															\begin{itemize}
																\item \script{487}{Equivalence check with reachability analysis}
															\end{itemize}
															\item \script{483}{Example}
															\item \script{485}{Properties (ff.)}
															\item \script{492}{Method}
															\begin{itemize}
																\item \script{493}{Illustration}
																\item \script{494}{Complexity}
															\end{itemize}
														\end{itemize}
													\end{minipage}
												}
											}
									}
								child {
										node {Reduced Finite Automata
												\resizebox{\textwidth}{!}{
													\begin{minipage}[t]{12cm}
														\begin{itemize}
															\item alternative without Product Automata
															\item \script{497}{Definition}
															\begin{itemize}
																\item \underline{Theorem:} The reduced deterministic finite automaton for a deterministic finite automaton is \alert{unique up to isomorphism}, i.e, up to renaming of the states.
															\end{itemize}
															\item \script{499}{Analysis}
														\end{itemize}
													\end{minipage}
												}
											}
									}
							}
						child {
								node {Characteristic functions
										\resizebox{\textwidth}{!}{
											\begin{minipage}[t]{12cm}
												\begin{itemize}
													\item \script{501}{Definition and characteristic boolean functions}
													\item \script{502}{Set Operations}
													\item \script{504}{Boolean Functions and Relations}
													\begin{itemize}
														\item \script{505}{Example (f.)}
														\item \script{507}{Characteristic function of the corresponding boolean relation}
													\end{itemize}
												\end{itemize}
											\end{minipage}
										}
									}
							}
						child {
								node {Image and Preimage and Range
										\resizebox{\textwidth}{!}{
											\begin{minipage}[t]{12cm}
												\begin{itemize}
													\item \script{508}{Definition}
													\begin{itemize}
														\item \script{509}{Example (ff.)}
													\end{itemize}
													\item \script{512}{Problem: Efficient with ROBDD}
												\end{itemize}
											\end{minipage}
										}
									}
								child {
										node (efficient image computation) {Efficient Image Computation
												\resizebox{\textwidth}{!}{
													\begin{minipage}[t]{12cm}
														\begin{itemize}
															\item \script{524}{Formula}
														\end{itemize}
													\end{minipage}
												}
											}
									}
								child {
										node (efficient preimage computation) {Efficient Preimage Computation
												\resizebox{\textwidth}{!}{
													\begin{minipage}[t]{12cm}
														\begin{itemize}
															\item \script{527}{Formula}
														\end{itemize}
													\end{minipage}
												}
											}
									}
								child {
										node (efficient range computation) {Efficient Range Computation
												\resizebox{\textwidth}{!}{
													\begin{minipage}[t]{12cm}
														\begin{itemize}
															\item \script{521}{Formula}
														\end{itemize}
													\end{minipage}
												}
											}
										child {
												node (existential quantification) {Existential Quantification
														\resizebox{\textwidth}{!}{
															\begin{minipage}[t]{12cm}
																\begin{itemize}
																	\item \script{514}{Definition}
																	\item \script{516}{Notation and Lemma}
																	\item \script{518}{Exercise}
																\end{itemize}
															\end{minipage}
														}
													}
											}
									}
							}
						child {
								node {BDD-based methods for proving equivalence of two sequential circuits}
							}
						child {
								node {Generation of counterexamples}
							}
					}
			}
	\end{mindmapcontent}
	\begin{edges}
		\edge{test}{middle}
	\end{edges}
	\annotation{test}{annotation}
\end{mindmap}
\end{document}
