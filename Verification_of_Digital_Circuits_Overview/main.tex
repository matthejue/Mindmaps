\documentclass{standalone}

\input{./content/packages}
\input{./content/desgin}
\input{./content/declarations}

\begin{document}
\begin{mindmap}
	\begin{mindmapcontent}
		\node (middle) at (current page.center) {Verification of Digital Circuits
			% \resizebox{\textwidth}{!}{
			% 	\begin{minipage}[t]{20cm}
			% 		\begin{itemize}
			% 			\item digital systems in electronics everywhere increasing
			% 			\item make circuits correct, find design errors, the later detect problem the harder to fix because of transformations (back to intial specification do all steps again)
			% 			\item just doing simulation, cannot systematically cover the whole input space with simulation and tests (64 bit input, 1 input in 1ns, 584 years), need formal methods
			% 			\item cause costs (Pentium FDIV-bug nowadays easilty to detect), all chips produced effected in case of design error
			% 			\item safety critical (Therac-25)
			% 			\item security (Spectre and Meltdown)
			% 		\end{itemize}
			% 	\end{minipage}
			% }
		}
		child {
				node {Basic Technologies}
				child {
						node (shannonbooleanfunction) {Theorem Shannon almost every boolean function
								% \resizebox{\textwidth}{!}{
								% 	\begin{minipage}[t]{16cm}
								% 		\begin{itemize}
								% 			\item no representation that works for all boolean functions such that it doesn't explode
								% 			\item almost every boolean function requires exponential size
								% 			\item bdd not representation for all practical functions
								% 			\item 2-input gates not to be taken to literally, can also put in any datastructure with n bits of memory or a constant number of memory
								% 			\item almost every boolean function means, if have collection of all n input function and randomly pick one then probability will converge to 1 that one needs at least $2^n/n$ bits for representation
								% 			\item the larger n is the more unlikely it gets that one gets a good function that can be represented compactly
								% 			\item \underline{idea why that's the case:} justification for this "no data structure" can represent all boolean functions efficiently
								% 			\begin{itemize}
								% 				\item how see so many boolean functions. boolean function uniquely represented by a function table, for every input combination has a row, and in output column have 0 or 1 for every row, $2^n$ rows, $2^n$ different input combinations
								% 				\item with m bits can represent $2^m$ different things
								% 				\item how large has M to be such that one can represent $2^(2^n)$ different functions
								% 				\item on average m has to be equal to $2^n$
								% 				\item on average means need $2^n$ bits to represent n bit functions on average
								% 				\item only thing can do is how some functions represented with fewer bits and other functions with more bits but the average has to be the same
								% 			\end{itemize}
								% 			\item \underline{$2^n/n$ if take 2 input gates is a minor issue:}
								% 			\begin{itemize}
								% 				\item have 2 input gates, they already do something, they have associated function that have to store in memory as well and then get this divided by n
								% 			\end{itemize}
								% 			\item also holds for bdds, because a bdd is just a multiplexer circuit
								% 			\begin{itemize}
								% 				\item implement in hardware by replacing every non-terminal node by a multiplexer
								% 				\item select signal just a variable, that's the label of the node
								% 				\item 0 and 1 is just the logic 0 and 1
								% 				\item no datastructure that works in all cases
								% 			\end{itemize}
								% 		\end{itemize}
								% 	\end{minipage}
								% }
							}
					}
				child {
						node {Scalability}
					}
				child {
						node (bdds) {Binary Decision Diagrams (BDDs)
								% \resizebox{\textwidth}{!}{
								% 	\begin{minipage}[t]{12cm}
								% 		\begin{itemize}
								% 			\item datastructure for representing boolean functions (can't compare gate level circuits not canonical, function tables canonical but comparison easy but don't scale n inputs $2^n$ lines (64 inputs have $2^64$ lines 1ns need 584 years for whole table), canonical disjunctive normal canonical but often explode)
								% 			\item easy to compare (ROBDD)
								% 			\item compact
								% 			\item construct efficiently from circuit
								% 			\item can explode which one can't avoid, but work for many practical cases if not choose random function
								% 			\begin{itemize}
								% 				\item don't work in all cases, not all functions relevant in practise have small representation multiplication, division, square root, can prove that no matter how choose variable order in bdd the representation will always be exponential in the number of bits of the multiplier, same for dividers, square root and a few other things
								% 			\end{itemize}
								% 		\end{itemize}
								% 	\end{minipage}
								% }
							}
						child {
								node {Variable Order
										% \resizebox{\textwidth}{!}{
										% 	\begin{minipage}[t]{12cm}
										% 		\begin{itemize}
										% 			\item variable order crucial for the size
										% 			\item some functions only good orders, some good and bad, some only bad
										% 		\end{itemize}
										% 	\end{minipage}
										% }
									}
								child {
										node {Static heuristic, define an initial variable order (Method of Malik)
												% \resizebox{\textwidth}{!}{
												% 	\begin{minipage}[t]{12cm}
												% 		\begin{itemize}
												% 			\item look at circuit and guess a good order
												% 			\item if have more than one output, continue with 2nd output and do the same and append the missing variables
												% 			\item can be arbitrarily bad, but on average it returns an acceptable order and it's fast
												% 		\end{itemize}
												% 	\end{minipage}
												% }
											}
									}
								child {
										node {Dynamic heuristic
												% \resizebox{\textwidth}{!}{
												% 	\begin{minipage}[t]{12cm}
												% 		\begin{itemize}
												% 			\item pick initial order based on first heuristic and start constructing the bdd and if it becomes too large modify variable order
												% 			\item when look size bdds during creation bdd for some circuit see peak middle. Typically last bdd not always the largest one. not always, no guarantee
												% 			\item initial often good for whole circuit (not always) but in the middle it can be bad.
												% 			\item therefore modify variable order during construction of the bdds
												% 		\end{itemize}
												% 	\end{minipage}
												% }
											}
										child {
												node {Sifting
														% \resizebox{\textwidth}{!}{
														% 	\begin{minipage}[t]{12cm}
														% 		\begin{itemize}
														% 			\item allows swapping 2 adjacent variables in the order and if do that systematically to find better variable order, do that during construction of the bdd
														% 			\item most popular heuristic
														% 			\item if xi has value and xj has value and arrive at some sub-bdd that has to be the same after swapping
														% 			\item only affects 2 levels that we swap
														% 			\item local operation that can be done quite efficiently
														% 			\item implementations bdd packages that point along the levels, don't have to traverse whole bdd
														% 			\item why case, because by swapping you enable further reductions, you see symmetries in the functions better
														% 			\item example, no matter what value of xi is, if xj is 1, one ends up at k
														% 			\item if swap don't have to ask anymore for the xi value, if xj is 1 the value of xi does not matter
														% 			\item can apply shannon reduction to xi node, on other side can't, because low successors of the xj nodes are different and therefore these are 2 distinct nodes and you can't remove the xi
														% 			\item but if you swap the order then you don't have to ask for xi if xj is one, you only have if xj is 0
														% 			\item also reason for isomorphism reduction on other side
														% 			\item swapping can also increase size, because if start with right bdd and swap get other one
														% 			\item apply swapping of 2 adjacent levels such that in the end have a better bdd and sifting just does that systematically
														% 			\item start with widest level of the bdd, start with level with the most nodes
														% 			\item move x4 close end of the bdd, if upper half move it first to the root, if it's in the lower half you move it first to the leaf level
														% 			\item keep track size bdd after the swap
														% 			\item then move to opposite end
														% 			\item then had x4 on every level of the bdd and kept track how large bdd is and determined position in which bdd was the smallest
														% 			\item and then move x4 back to that position
														% 			\item here level 3 bdd was the smallest
														% 			\item necessary to do immediate steps. Couldn't one save this bdd, then it would cost more memory. If can efford keeping a copy can do that. Then don't need to shift it to most positions twice
														% 			\item when finished one variable mark as finished and then continue next variable that is on the largest level that has not been processed yet and do that for all variables
														% 			\item in the end bdd at least hasn't become larger
														% 			\item problem if bdd size explodes during the sifting operation. there's no guarantee that it stays small for the intermediate steps. if growths to much just abord
														% 			\item no reason to do every variable in every position
														% 			\item might miss some good position, but at least doesn't explode in between
														% 			\item therefore have threshold, so just allow growth by factor of 2 or sth
														% 			\item if bdds size exceeds this threshold then stop, then get runtime n2 times size of input bdd
														% 			\item other techniques, window optimization
														% 		\end{itemize}
														% 	\end{minipage}
														% }
													}
											}
									}
								child {
										node {Theorem Finding good order NP-Complete (Bollig, Savicky, Wegener)
												% \resizebox{\textwidth}{!}{
												% 	\begin{minipage}[t]{12cm}
												% 		\begin{itemize}
												% 			\item can guess variable order and try to construct bdd and if becomes too large abord
												% 			\item can verify in polynomial time in the size of the input bdd whether new variable order better than old, but \alert{finding} that order can only be done in exponential time
												% 			\item not worth risking exponential running time, just for finding a better variable order, therefore do thing that are fast but without guarantee, heuristic, do best to find good order, but might be unlucky and not find one
												% 			\item deciding if better variable order np-complete
												% 			\item and finding optimal as well, can just do binary search and check can find variable order halve size of bdd
												% 			\item optimization problem just as hard as decision problem
												% 		\end{itemize}
												% 	\end{minipage}
												% }
											}
									}
								child {
										node {Theorem multplication no good variable order
												% \resizebox{\textwidth}{!}{
												% 	\begin{minipage}[t]{12cm}
												% 		\begin{itemize}
												% 			\item independent of variable order multiplication has exponential size bdd
												% 			\item same idea as for proof method exponential size
												% 			\item but have to prove that holds for all the variable orders
												% 			\item many arithmetic functions have only bdd representation with exponential size
												% 			\item still works for many cases, not always, when look at modern verification tools, they do not rely on one technique
												% 			\item invented extensions of bdds that work for multipliers
												% 		\end{itemize}
												% 	\end{minipage}
												% }
											}
										child {
												node {Proof method bdd exponential
														% \resizebox{\textwidth}{!}{
														% 	\begin{minipage}[t]{12cm}
														% 		\begin{itemize}
														% 			\item on top have n variables, so have $2^n$ different assignments of these variables
														% 			\item look at cofactors with respect to these variables
														% 			\item take our function and replace the variables above the line by its assignment and then we get this table (count how many different functions get by replacing the first 3 variables by a constant)
														% 			\item rightmost column have function we get after replacing the variable values (right column function obtained by replacing in this polynomial the first 3 variables by a constant)
														% 			\item all of them are different
														% 			\item if we follow path from root node, given by one of these assignments, the edge we traverse last has to end the bdd node that represents this function (edges crossing red line all point to different bdd nodes)
														% 			\item and because $2^n$ different functions, $2^n$ different nodes to represent this cofactors, they are all reached by an edges from the top
														% 			\item therefore below the cut have at least $2^n$ nodes, because these $2^n$ edges all have to point to a different node + in principle as few more (because have as many functions as variable evaluations, have as many nodes below the cut as have different combinations here), in this case don't have more, but in principle could have + nodes above
														% 			\item way to prove is count different cofactors
														% 			\item why other linear, either this monomial is 1 or have to look at remaining part
														% 		\end{itemize}
														% 	\end{minipage}
														% }
													}
											}
									}
							}
						child {
								node {Actions on BDD}
								child {
										node {Number satisfying assignments}
									}
								child {
										node {Size of Bdds}
									}
								child {
										node {Derive function reprsented by BDD
												% \resizebox{\textwidth}{!}{
												% 	\begin{minipage}[t]{12cm}
												% 		\begin{itemize}
												% 			\item start bottom and insert into shannon theorem
												% 		\end{itemize}
												% 	\end{minipage}
												% }
											}
									}
								child {
										node {Evaluate function value
												% \resizebox{\textwidth}{!}{
												% 	\begin{minipage}[t]{12cm}
												% 		\begin{itemize}
												% 			\item start at root node and follow dashed and solid edges
												% 			\item if have bdd can evaluate the function value in time that is given by the length of the longest path
												% 		\end{itemize}
												% 	\end{minipage}
												% }
											}
									}
								child {
										node {Check Isomorphism
												% \resizebox{\textwidth}{!}{
												% 	\begin{minipage}[t]{12cm}
												% 		\begin{itemize}
												% 			\item injective means need at least as many outputs as inputs, surjective needs at least as many inputs as outputs, bijective mapping exists iff size input and output set are the same, case for finite and infinite sets, integer and even numbers have same size, rational and natural numbers have same size, but integer and real numbers don't have same size, because no bijective mapping
												% 			\item starting and end point of low edge correspond to each other for all edges, bbds have the same structure, bdds identical iff isomorphic
												% 			\item if not isomorphic, then 2 circuits compute different functions
												% 			\item checking for isomorphism is not difficult for bdds but still don't do it, all implementations construct shared bdds, share nodes, roots 1st and 2nd function overlap, check isomorphism by comparing the 2 pointers, isomorphic if point to same node, compare in constant time
												% 		\end{itemize}
												% 	\end{minipage}
												% }
											}
									}
								child {
										node {Construction / Building
												% \resizebox{\textwidth}{!}{
												% 	\begin{minipage}[t]{12cm}
												% 		\begin{itemize}
												% 			\item pick variable rood node
												% 			\item compute negative and positive cofactor
												% 			\item compute recursively a bdd for them
												% 			\item attach to low and high edge
												% 		\end{itemize}
												% 	\end{minipage}
												% }
											}
										child {
												node {ITE-Algorithm
														% \resizebox{\textwidth}{!}{
														% 	\begin{minipage}[t]{12cm}
														% 		\begin{itemize}
														% 			\item have long list of base cases that can answer without computation
														% 			\item sooner or later get base case, because if you did recursion on all the variables one ends up with three constant parameters
														% 			\item fgh are bdds with same variable order
														% 			\item x, topmost variable that occurs in fgh, look at three root nodes and pick variable of rootnode and check which is the first one in the variable order
														% 			\item call ITE recursively on cofactors
														% 			\item negative cofactor of x, two cases, check if rootnode equal to x, if not the case just take f, because f is independent of x and therefore nothing changes
														% 			\begin{itemize}
														% 				\item efficient, doable in constant time
														% 			\end{itemize}
														% 		\end{itemize}
														% 	\end{minipage}
														% }
													}
												child {
														node {Forward construction / Symbolic simulation
																% \resizebox{\textwidth}{!}{
																% 	\begin{minipage}[t]{12cm}
																% 		\begin{itemize}
																% 			\item forward, start inputs call ITE,
																% 			\item start inputs and run though circuit in topological order
																% 			\item one bdd for every output bit of a circuit
																% 			\item for every primary input labeled xi construct such a bdd
																% 			\item arrive at gate, apply e.g. and function for bdds at input of gate, algorithm takes 2 bdds and outpus bdd for e.g. and of functions represented by bdds
																% 			\item create one non-terminal node bdds for inputs, traverse circuit topological order from inputs to outputs
																% 			\item whenever arrive at gate apply corresponding function to input bdds and get bdd for output of the gate
																% 			\item at primary outputs bdds are the representation of the functions computed by the circuit
																% 			\item do for all input assignments in one step
																% 			\item \enquote{ands} and \enquote{or} calls to ITE
																% 			\item \enquote{not} just changing complementation mark of incoming edge
																% 		\end{itemize}
																% 	\end{minipage}
																% }
															}
													}
												child {
														node {Backward construction
																% \resizebox{\textwidth}{!}{
																% 	\begin{minipage}[t]{12cm}
																% 		\begin{itemize}
																% 			\item backward, start output and call compose
																% 			\item for forward cosntruction may happen intermediate results much larger than final result, cannot continue if bdd size too large. alternative that might not always work, but maybe works in cases where the first method doesn't work
																% 			\item not the solution, if one methods fails, take another one
																% 			\item start bdd for output f, bdd labeled f low to 0, high to 1
																% 			\item replace f with definition of the or-gate
																% 			\item replace one edge with that next bdd
																% 			\item continue until arrive primary inputs
																% 			\item result is bdd that only depends on primary inputs and describes the circuit
																% 			\item need algorithm that replaces a variable by a bdd called compose
																% 			\item want to replace xi in F with the result of G
																% 			\item result same as for forward. result the same, because bdds are canonical. bdds get in between are different for both methods. sometimes intermediate bdds for forward traversal are smaller, sometimes for backward traversal
																% 			\item having choice good, because no method is guaranteed to work, if one doesn't work take another
																% 		\end{itemize}
																% 	\end{minipage}
																% }
															}
														child {
																node {Substitution operator, compose
																		% \resizebox{\textwidth}{!}{
																		% 	\begin{minipage}[t]{12cm}
																		% 		\begin{itemize}
																		% 			\item want to replace xi in F with the result of G
																		% 			\item formulate in terms of ITE
																		% 			\item make a case distinction on g
																		% 			\item know that function is a negative co-factor of f with respect to xi
																		% 			\item if g 1, have to replace x with 1, that's the positive cofactor
																		% 			\item in ITE did something similar
																		% 			\item but was different because variable was topmost variable of the bdd, and then just follow low edge to get negative cofactor
																		% 			\item this time xi not necessarily label of the rootnote
																		% 			\item start traversing bdd, when arrive at xi node just follow the low edge
																		% 			\item don't create xi node, but skip it by following the low edge
																		% 			\item when go back it works like an ITE, go down recursively, when skip when arrive at xi just return low successor
																		% 			\item and when go up create new nodes with computed / unique table etc.
																		% 			\item goes in linear time in size of the bdd
																		% 			\item call algorithm recursively both successors
																		% 			\item return pointer to that x3
																		% 			\item back original call, two different outputs from recursive calls
																		% 			\item create x1 node, attach result from the call to the left x2 node the low edge and other one to the high edge
																		% 			\item use computed table avoid doing things twice (for speeding up keep computed table)
																		% 			\item summary: do recursive traversal until hit base case (hit x2 node or a node below the x2 node). If have x2 node skip it an follow the low edge. then if return from recursive calls do the same as ITE. if the two results are the same, apply shannon reduction otherwise apply isomorphism reduction using unique table
																		% 		\end{itemize}
																		% 	\end{minipage}
																		% }
																	}
																child {
																		node {Lemma compose equal to ITE
																				% \resizebox{\textwidth}{!}{
																				% 	\begin{minipage}[t]{12cm}
																				% 		\begin{itemize}
																				% 			\item if G is 0 then have to return f with xi replaced by 0 and then that's just the negative cofactor and the same holds for if G is 1
																				% 		\end{itemize}
																				% 	\end{minipage}
																				% }
																			}
																	}
															}
													}
												child {
														node {Unique Table
																% \resizebox{\textwidth}{!}{
																% 	\begin{minipage}[t]{12cm}
																% 		\begin{itemize}
																% 			\item isomorphism reduction hash table, remembers all nodes already have, key is just triple variable low and high successor and output is pointer to corresponding node
																% 			\item whenever create new node check if already have this combination, unique table
																% 		\end{itemize}
																% 	\end{minipage}
																% }
															}
													}
												child {
														node (iteop) {ITE-Operator
																% \resizebox{\textwidth}{!}{
																% 	\begin{minipage}[t]{12cm}
																% 		\begin{itemize}
																% 			\item don't want implement one algorithm per gate type, reduce all of them to one boolean function -> ITE
																% 			\item all binary functions can be reduced to this ITE operator
																% 			\item f, g, h 3 boolean function represented as bdds with the same variable order
																% 			\item directly want to get a robdd without going via function tables etc.
																% 			\item use shannons decomposition theorem
																% 			\item doesn't matter compute fg or not fh and replace all xi by 1 or vice versa
																% 			\item look inside braces, it's ITE applied to negative and positive cofactor
																% 			\item ITE(F, G, H) is same as not xi and ITE applied to negative cofactors or ... positive cofactors ...
																% 			\item gives us recursive formulation, if want to compute ITE of fgh pick first variable in variable order and compute this expression and calling ITE recursively
																% 			\item get 2 results for negative and positive cofactor, create new bdd node labeled with xi, attach negative and positive cofactor result to low and high edge
																% 			\item \underline{\alert{advantage} using ITE instead of nor, xor, equivalence etc.:}
																% 			\begin{itemize}
																% 				\item share same computed table for all ite calls
																% 				\item if have seperate implement for and, or etc. each one needs it's own computed table and then the hitrate is much lower
																% 			\end{itemize}
																% 			\item typical bdd algorithm, like ITE operator, bdds as parameters, compute result for cofactors of root node, then assemble the real result, running time depends on what have to do to ensemble final result
																% 		\end{itemize}
																% 	\end{minipage}
																% }
															}
														child {
																node {Theorem Decomposition of ITE-Opterator}
															}
													}
												child {
														node {Optimizations and Runtime
																% \resizebox{\textwidth}{!}{
																% 	\begin{minipage}[t]{12cm}
																% 		\begin{itemize}
																% 			\item recursive calls with n variables, 2 calls, after 2 variables have 4 calls, after 3 have 8 calls (for every variable level double number of recursive calls, n levels, $2^n$ recursive calls)
																% 			\item num recursive calls exponential in worst case
																% 			\item everything else constant time if have decent hash tables
																% 			\item how many different recursive calls, have distinct arguments, num different combinations, much more calls $2^n$, don't compute same result again (cannot have arbitrary number of different calls, are all nodes of the original inputs)
																% 			\item everything else constant time, good hash table lookups, computing cofactors, computing top variable, comparing 2 pointers for shannon reduction, checking unique tables, creating new node
																% 			\item running time: constant * num recursive call, num recursive calls are number of node triples one can get
																% 			\item but only improve average running time, worst case may be as bad as without the table, if have 3 bdds that have exponential nodes in the number of variables, if have exponential size bdd lost anyway
																% 			\item and, third parameter bdd 0 with 1 node
																% 		\end{itemize}
																% 	\end{minipage}
																% }
															}
														child {
																node {Theorem Runtime}
																child {
																		node {Lemma Runtime AND}
																	}
																child {
																		node {Lemma Runtime OR}
																	}
																child {
																		node {Lemma Runtime Negation}
																	}
															}
														child {
																node {Computed Table
																		% \resizebox{\textwidth}{!}{
																		% 	\begin{minipage}[t]{12cm}
																		% 		\begin{itemize}
																		% 			\item dynamic programming
																		% 			\item new hash table, key triple of bdd nodes, value result of ITE call
																		% 			\item before computation, check already have result, computed table
																		% 			\item in practise helps drastically
																		% 		\end{itemize}
																		% 	\end{minipage}
																		% }
																	}
															}
														child {
																node {Complemtnary Edges
																		% \resizebox{\textwidth}{!}{
																		% 	\begin{minipage}[t]{12cm}
																		% 		\begin{itemize}
																		% 			\item negation mark on edges of a bdd
																		% 			\item if edge is negated, just negative everything below
																		% 			\item careful, bdds should be canonical, if allow arbitrary negation mark they aren't
																		% 			\item make restrictions where negation mark can appear, forbid terminal node 1
																		% 			\item can normalize bdd such that no high edge is negated
																		% 			\item get rid of negation mark high edge with, de-morgan rule
																		% 			\item \underline{advantage complement edges:}
																		% 			\begin{itemize}
																		% 				\item don't loose canonicity
																		% 				\item save up to halve of the nodes, recuce bdd size / memory consumption up to 50\%, if represent function f and not f, they are without complement edges two different bdd nodes
																		% 				\item does not cost memory, boolean on edge costs memory
																		% 				\begin{itemize}
																		% 					\item exploit memory alignment of processor, 64 bit processor, all pointers aligned to adresses divisible by 8
																		% 					\item pointer dividable by 8 last three bits are 0, 32 2 bits
																		% 					\item 3 bits left, abuse them to store negation mark,
																		% 					\item just have to be careful if dereference pointer, have to clear last bit
																		% 				\end{itemize}
																		% 				\item don't slow down algorithm, just have to keep track, have seen even or odd number of negations
																		% 				\item node representing function f and not f, in normal bdds can't merge them
																		% 				\item can negate bdd in constant time
																		% 				\item complement marks only advantages, no additional memory, reduce size of bdd, algorithms work as before, be careful bdds stay canonical
																		% 				\item only have leave 0 or 1, agree on one version. could also do dual, never complement low edge
																		% 			\end{itemize}
																		% 		\end{itemize}
																		% 	\end{minipage}
																		% }
																	}
															}
													}
											}
									}
							}
						child {
								node (shannon) {Shannon Theorem / Shannon's Decomposition Theorem
										% \resizebox{\textwidth}{!}{
										% 	\begin{minipage}[t]{12cm}
										% 		\begin{itemize}
										% 			\item reminds of formula BDD and tells how to construct a BDD
										% 			\item proof case distinction, when xi is 0, then result is f not xi and that's exactly what you get if you replace xi with 0
										% 		\end{itemize}
										% 	\end{minipage}
										% }
									}
							}
						child {
								node {Reduced Ordered Binary Decision Diagram (ROBBD)
										% \resizebox{\textwidth}{!}{
										% 	\begin{minipage}[t]{12cm}
										% 		\begin{itemize}
										% 			\item every node in bdd represents a different function
										% 			\item cannot apply any reduction rule
										% 		\end{itemize}
										% 	\end{minipage}
										% }
									}
								child {
										node {Canonicity theorem
												% \resizebox{\textwidth}{!}{
												% 	\begin{minipage}[t]{12cm}
												% 		\begin{itemize}
												% 			\item induction over number of variables on which F depends
												% 			\item n=0, function does not depend on any variable
												% 			\item replace all 0's by 1's
												% 			\item have to prove there's no other bdd for the same function which is reduced and ordered and so on
												% 			\item assume have bdd that represents the 0 function and it's different from the terminal node 0
												% 			\item that means it has at least one non-terminal node
												% 			\item because it's a 0 function all paths from that node to a terminal node have to end up in the terminal node that is labeled 0, otherwise would get function value of 1
												% 			\item it's a free bdd so you know all the path can be triggered
												% 			\item it's a finite acyclic graph, so sooner or later you will reach a node whose both successors a terminal node
												% 			\item only one 0 terminal node, shannon reduction
												% 			\item contradiction that it's a reduced obdd
												% 			\item assume have shown for n-1 variables and have bdd that depends on n variables
												% 			\item assume have 2 different bdds for the same variable order and both represent the same function
												% 			\item have to show root node labeled with the same variable
												% 			\item have to show they are really isomorphic
												% 			\item assume different nodes in the root
												% 			\item assume that because have fixed variable order, one has to appear before the other
												% 			\item other way round proof works exactly same way
												% 			\item if starts with xj, nothing further up, then have no xi in this bdd, there's no i xi here
												% 			\item if it contained an xi node it should have appeared before the xj
												% 			\item that bdd independent of xi
												% 			\item two functions that don't depend on xi are the same (xi 0 and xi 1 has no influence)
												% 			\item cofactors depend on n-1 variables, 2 cofactors depend on n-1 variables (that cofactor depends on 1 variable less, doesn't depend on xi, therefore can apply induction hypothesis, only one representation of these 2 cofactors)
												% 			\item property holds for n-1 variables so we know these to 2 sub-bdds have to be isomorphic
												% 			\item merge isomorphic sub-bdds, because it's a reduced bdd
												% 			\item can apply shannon reduction, but one can't it's a reduced bdd -> contradiction
												% 			\item wrong assumption that xi xj are different, not possible that root nodes have different labels
												% 			\item use isomorphism get by induction assumption, functions that depend on n-1 variables, plus root nodes
												% 			\item bdds typically overlap
												% 			\item for nodes in overlap have 2 isomorphism defined, mapping low to low, high to high
												% 			\item show that they're the same, because of structural properties they have to be the same
												% 			\item compute cofactor respect to xi, replace with 0 or 1 get same cofactor
												% 		\end{itemize}
												% 	\end{minipage}
												% }
											}
										child {
												node {Isomorphism}
											}
									}
								child {
										node {Ordered BDD (OBDD)}
										child {
												node {Free BDD
														% \resizebox{\textwidth}{!}{
														% 	\begin{minipage}[t]{12cm}
														% 		\begin{itemize}
														% 			\item non-free have dead edges, free bdd walk along all edges, evaluation of variables that triggers every path
														% 		\end{itemize}
														% 	\end{minipage}
														% }
													}
											}
									}
							}
						child {
								node {Reduction Rules
										% \resizebox{\textwidth}{!}{
										% 	\begin{minipage}[t]{12cm}
										% 		\begin{itemize}
										% 			\item starting at the bottom, upwards level by level
										% 			\item in practise never do reduction, never create a redundant node, just costs memory, reduction afterwards costs time
										% 			\item they all do reduction on the fly, apply reduction rules immediately
										% 		\end{itemize}
										% 	\end{minipage}
										% }
									}
								child {
										node {\enquote{Isomorphism} reduction
												% \resizebox{\textwidth}{!}{
												% 	\begin{minipage}[t]{12cm}
												% 		\begin{itemize}
												% 			\item 2 nodes both with \alert{same label}, both have the same low successor and high successor, means they do the same thing, if compute function represented by these 2 nodes see they are the same
												% 		\end{itemize}
												% 	\end{minipage}
												% }
											}
									}
								child {
										node {\enquote{Shannon} reduction
												% \resizebox{\textwidth}{!}{
												% 	\begin{minipage}[t]{12cm}
												% 		\begin{itemize}
												% 			\item distributivity, always true
												% 			\item remove upper one, xi depends on xj, but xj is independent of xi, both nodes define the same function, because upper node xi defines it's function in terms of the lower node xj, can't delete the lower node xj, because that would destroy the upper one
												% 		\end{itemize}
												% 	\end{minipage}
												% }
											}
									}
							}
					}
				child {
						node {AND-Inverter Graphs}
						child {
								node {Normalization Rules}
								child {
										node {Redundant AND Elimination}
									}
								child {
										node {Constant Zero Elimination}
									}
								child {
										node {Constant Zero Propagation}
									}
								child {
										node {Constant One Propagation}
									}
								child {
										node {Strutural Hashing}
									}
							}
						child {
								node {Functionally Reduced AIGs (FRAIGs)}
								child {
										node {Semi-canonical, Invariant}
									}
								child {
										node {Equivalence classes, Random Vectors, SAT, CE's refine simulation}
									}
								child {
										node {Functional Reduction \enquote{on the fly}}
									}
							}
						child {
								node {Usecases}
								child {
										node {Replace ROBDDs where canonicity is not necessarily needed}
										child {
												node {Represent set of states in model checking}
											}
										child {
												node {Sufficient for combinational equivalence checking}
											}
									}
							}
					}
				child {
						node (satsolver) {SAT Solvers
								% \resizebox{\textwidth}{!}{
								% 	\begin{minipage}[t]{12cm}
								% 		\begin{itemize}
								% 			\item first problem proven NP-Complete
								% 			\item if satisfiable want satisfying assignment, because that's a CE for equivalence
								% 			\item if not how can be sure sat-solver works
								% 		\end{itemize}
								% 	\end{minipage}
								% }
							}
						child {
								node {Complete methods}
								child {
										node {Proprositional logic
												% \resizebox{\textwidth}{!}{
												% 	\begin{minipage}[t]{12cm}
												% 		\begin{itemize}
												% 			\item if xi is formula, then truth value formula is just assignment of xi
												% 			\item algorithms expect formulas in certain shape
												% 			\item not x1 also a clause of length 1
												% 		\end{itemize}
												% 	\end{minipage}
												% }
											}
										child {
												node {Syntax and Semantics}
											}
										child {
												node {SAT-Problem and Satisfiability}
											}
										child {
												node {Notation for clause}
												child {
														node {Empty clause}
													}
												child {
														node {Empty formula}
													}
												child {
														node {Union}
													}
												child {
														node {Difference}
													}
											}
										child {
												node {Clause and Literal}
											}
										child {
												node {CNF}
											}
									}
								child {
										node {Resolution }
										child {
												node {Resolution Lemma}
											}
										child {
												node {Resolution Theorem}
											}
									}
								child {
										node {Naive method}
										child {
												node {Complexity}
											}
									}
								child {
										node {Davis Putman (DP)-Algorithm}
										child {
												node {Variable elimination}
												child {
														node {Theorem satisfiability equivalent}
														child {
																node {Existential quantification}
															}
													}
												child {
														node {Resoluton of all pairs}
													}
											}
										child {
												node {Optimizations}
												child {
														node {Subsumption check}
													}
												child {
														node {Pure literal elimination}
													}
											}
									}
								child {
										node {DLL-Algorithm
												% \resizebox{\textwidth}{!}{
												% 	\begin{minipage}[t]{12cm}
												% 		\begin{itemize}
												% 			\item dfs in space of assignments
												% 		\end{itemize}
												% 	\end{minipage}
												% }
											}
										child {
												node {Unit Clause}
											}
									}
								child {
										node {Modern SAT algorithms
												% \resizebox{\textwidth}{!}{
												% 	\begin{minipage}[t]{12cm}
												% 		\begin{itemize}
												% 			\item nowadays algorithms also work on resolution
												% 			\item dfs not recursively but as a while loop and add ingredients like preprocessing simplifying the formula, picking good variable assignments, like if run into assignment that does not satisfy formula find out reason why that's the case and take care never have the same reasons again (conflict analysis)
												% 		\end{itemize}
												% 	\end{minipage}
												% }
											}
										child {
												node {Comparison to DLL}
												child {
														node {Algorithm}
													}
												child {
														node {Different meaning for Unit Clause}
													}
												child {
														node {Different meaning for Contradiction / Conflict}
													}
												child {
														node {Different meaning for Conflict Analysis and Backtracking}
													}
											}
										child {
												node {Preprocessing }
												child {
														node {Unit Propagation}
													}
												child {
														node {Unit Propagation Lookahead (UPLA)}
													}
												child {
														node {Self-Subsuming Resolution }
													}
												child {
														node {Variable Elimination by Resolution (Elimination by clause distribution)}
													}
												child {
														node {Variable Elimination by Substitution}
													}
												child {
														node {Forward Subsumption}
													}
												child {
														node {Backward Subsumption}
													}
												child {
														node {Blocked Clause Elimination}
													}
												child {
														node {Equivalent Literals (Equivalent Literal Detection)}
													}
											}
										child {
												node {Decision Stack}
											}
										child {
												node {Decision Heuristics}
												child {
														node {Classical Decision Heuristics}
													}
												child {
														node {Variable State Independent Decaying Sum (VSIDS)}
													}
											}
										child {
												node {Boolean Constraint Propagation}
												child {
														node {Implication queue}
													}
												child {
														node {Counter-Based Schemes}
														child {
																node {2-Counter Scheme}
															}
														child {
																node {1-Counter Scheme}
															}
														child {
																node {Disadvantages}
															}
													}
												child {
														node {Watched Literals}
													}
											}
										child {
												node {Conflict Analysis and (Non-)Chronological Backtracking}
												child {
														node {Chronological Backtracking}
													}
												child {
														node {Non-Chronological Backtracking}
														child {
																node {Conflict Clause}
															}
														child {
																node {Implication Graph}
																child {
																		node {1UIP Scheme}
																		child {
																				node {Unique Implication Point}
																				child {
																						node {Asserting Clause}
																					}
																			}
																	}
															}
													}
											}
										child {
												node {Unlearning (conflict clauses)}
											}
										child {
												node {Restarts}
											}
										child {
												node {Termination}
												child {
														node {Ranking Function}
													}
											}
										child {
												node {Certificates of (un)satisfiability of a CNF formula}
											}
										child {
												node (incrementalsat) {Incremental SAT solving}
												child {
														node {Knowledge learnt so far re-used}
														child {
																node {Conflict clauses}
																child {
																		node {Problem, if remove clauses ($CNF_B \not\Rightarrow CNF_B \cdot a \Rightarrow c$)}
																		child {
																				node {Adding clauses no problem ($CNF_A \cdot b \Rightarrow CNF_A \Rightarrow c$)}
																			}
																		child {
																				node {De-activation variables}
																				child {
																						node {Assumptions}
																						child {
																								node {Before SAT solving (decision level -1)}
																							}
																						child {
																								node {Can't be changed during SAT solving}
																							}
																					}
																				child {
																						node {Only apppar positively}
																						child {
																								node {All resolved conflicting conflict clauses contain it}
																							}
																					}
																			}
																		child {
																				node {Conflict Clause c not allowed to be added to $CNF_B$}
																			}
																	}
																child {
																		node {Problem, if pre-processing used for instances}
																		child {
																				node {New clauses added later on which contain eliminated variables}
																			}
																		child {
																				node {Preprocessor may remove}
																				child {
																						node {Clauses (Subsumption)}
																					}
																				child {
																						node {Literals (Self Subsumption)}
																					}
																				child {
																						node {Variables (Variable Elimination)}
																					}
																			}
																	}
															}
														child {
																node {Variable activity}
															}
													}
											}
									}
							}
						child {
								node {Incomplete methods}
							}
						child {
								node (satcomplexity) {Complexity}
								child {
										node {3-SAT}
									}
								child {
										node {2-SAT}
									}
								child {
										node {Horn formulas}
									}
							}
					}
			}
		child {
				node (equivalencechecking) {Equivalence Checking
						% \resizebox{\textwidth}{!}{
						% 	\begin{minipage}[t]{12cm}
						% 		\begin{itemize}
						% 			\item compare design before and after transformation (vhdl/vetilog, rtl descirption, net level gate list), bug in software tool
						% 			\item design for testability, ensure not introduce errors
						% 			\item timing analysis, part chip to slow, replace by more efficient
						% 			\item compute bdds for 1st and 2nd circuit and check are they isomorphic thanks to cannonicity theorem for ROBDD's
						% 			\item co-np complete
						% 			\begin{itemize}
						% 				\item no answer, can guess circuits not equivalent, guess counterexample, guess input that leads to different outputs
						% 				\item can verify difference outputs in linear size in the circuit
						% 				\item apply to both circuits, propagate through all the gates and check outputs different
						% 				\item for yes have to verify for all inputs the outputs are the same
						% 				\item analogy formula, verify that it's not satisfiable, check for all inputs the output is 0 or false and that's hard to guess
						% 			\end{itemize}
						% 		\end{itemize}
						% 	\end{minipage}
						% }
					}
				child {
						node {Combinational Circuits
								% \resizebox{\textwidth}{!}{
								% 	\begin{minipage}[t]{12cm}
								% 		\begin{itemize}
								% 			\item no states because no memory
								% 		\end{itemize}
								% 	\end{minipage}
								% }
							}
						child {
								node {BDD's}
								child {
										node {Limitations}
									}
								child {
										node {Boolean function specification and implementation as ROBDDs}
										child {
												node {Testing whether both ROBDDs equivalent up to isomorphism}
											}
									}
							}
						child {
								node {SAT}
								child {
										node {Limitations}
									}
								child {
										node {Miter Circuit}
										child {
												node {CNF}
												child {
														node {Theorem size of formula}
														child {
																node {Size of formula}
															}
													}
												child {
														node {Theorem equivalent CNF}
														child {
																node {Equivalence}
															}
													}
												child {
														node {Tseitin Transformation}
														child {
																node {Satisfiability equivalent / Equisatisfiable}
															}
														child {
																node {Linear number clauses in final CNF}
															}
													}
											}
									}
							}
						child {
								node (structuralmethods) {Structural Methods (Exploiting structural information)}
								child {
										node {Khlmann, IBM, 80\% equivalent nodes}
									}
								child {
										node {Find such equivalences efficiently}
										child {
												node {Equivalence classes}
											}
										child {
												node {ROBDD's or SAT}
											}
									}
								child {
										node {Basic Approach}
									}
								child {
										node {Cut points (internal equivalences simpler by locality)}
										child {
												node {False negative problem}
												child {
														node {Solution 0: Do not Use Cut Points, Disadvantage}
													}
												child {
														node {Solution 1: Simulation based on \enquote{Xor ROBDD}, Disadvantages}
													}
												child {
														node {Solution 2: SAT based on \enquote{Xor (/ Difference) ROBDD}}
													}
												child {
														node {Solution 3: Backward Traversal based on \enquote{Xor ROBDD}}
													}
												child {
														node {Solution 4: \enquote{Cuts and Heaps}, \enquote{BDD Sweeping}}
													}
												child {
														node {Solution 5: SAT Solving with Cuts, \enquote{SAT Sweeping}}
													}
											}
									}
								child {
										node {Observation from real-world instances (local in most cases)}
										child {
												node {Only small changes in later design phases}
											}
										child {
												node {In many cases logic optimizations respect hierarchy boundaries}
											}
									}
							}
					}
				child {
						node {Sequential Circuits}
						% [grow=30]
						% [every child/.style={sibling angle=60}]
						% [level 1/.style={sibling angle=60}]
						child {
								node {Transducer}
								child  {
										node (productautomaton) {Product automata
												% \resizebox{\textwidth}{!}{
												% 	\begin{minipage}[t]{12cm}
												% 		\begin{itemize}
												% 			\item automatons of 2 circuts, traverse simultaneously with dfs
												% 			\item doesn't scale (2 circuits 64 bit of state, product automaton 128 bit of state), cannot efford to visit every state
												% 		\end{itemize}
												% 	\end{minipage}
												% }
											}
										child {
												node {Theorem states equivalent}
											}
										child {
												node {Theorem (Equivalence check with reachability analysis)}
												child {
														node {Properties of Product Automata}
													}
											}
									}
								child {
										node {Bit vector and Sequence notations}
									}
								child {
										node {Deterministic Finite Automata (DFA)}
										child {
												node {State of a Sequential Circuit}
											}
										child {
												node {(Behaviorial) Equivalence}
											}
										child {
												node {Equivalence with Identical State Encoding}
											}
										child {
												node {General Case}
												child {
														node (equivalentdfa) {Theorem Equivalent DFA's}
														child {
																node {Equivalent States}
																child {
																		node {Theorem If states are equivalent}
																	}
															}
													}
											}
									}
							}
						child {
								node {Reduced Finite Automata method}
								child {
										node {Theorem Reduced DFS unique up to isomorphism (Hotz/Walter)}
									}
								child {
										node {Complexity}
									}
							}
						child {
								node {Product automaton method, BDD based method}
								child {
										node {Generation of Counter Examples Steps}
									}
								child {
										node {Efficient implementation, Image and Preimage using BDDs
												% \resizebox{\textwidth}{!}{
												% 	\begin{minipage}[t]{12cm}
												% 		\begin{itemize}
												% 			\item turn dfs into bfs, compute all successor states in one step
												% 			\item characteristic functions
												% 			\item image and pre-image computation
												% 		\end{itemize}
												% 	\end{minipage}
												% }
											}
										child {
												node {Symbolic Traversal of Automata steps}
												child {
														node {Optimizations}
														child {
																node {Backward traversal}
																child {
																		node {Algorithm Exact Backward Traversal}
																	}
															}
														child {
																node {Simplified transition relation}
															}
														child {
																node {Early quantification}
																child {
																		node {Algorithm}
																	}
															}
														child {
																node {Image computation with generalized cofactor}
																child {
																		node {Generalized cofactor}
																		child {
																				node {Care function}
																			}
																		child {
																				node {Theorem Composition with Mapping function}
																			}
																		child {
																				node {Algorithm Computing the Generalized Cofactor}
																			}
																		child {
																				node {Properties}
																				child {
																						node {Theoreom Composition}
																					}
																				child {
																						node {Theorem Or and Negation}
																					}
																			}
																		child {
																				node {Efficient formula}
																			}
																	}
																child {
																		node {Theorem Range Generalized Cofactor same as Image Computation}
																	}
															}
														child {
																node {Funtional Image Computation}
																child {
																		node {Algorithm Range}
																	}
																child {
																		node {Functional Preimage Computation with Compose Operator}
																	}
																child {
																		node {Optimization of State Sets}
																	}
															}
													}
												child {
														node {Algorithm Exact Forward Traversal}
														child {
																node {Number Iterations in the Worst Case}
																child {
																		node {Sequential Depth}
																	}
															}
														child {
																node {Improved Algorithm (Image Computation only new states)}
																child {
																		node {Differences to unimproved Algorithm}
																	}
															}
													}
											}
										child {
												node {Fixpoint Theory}
												child {
														node {Partial Order}
														child {
																node {Lattice}
																child {
																		node {Supremum}
																	}
																child {
																		node {Infimum}
																	}
																child {
																		node {Complete Lattice}
																		child {
																				node {Lemma each finite Lattice Complete}
																			}
																		child {
																				node {Lattice of Subsets, Union and Intersection}
																			}
																	}
															}
														child {
																node {Monotone Increasing (/ Decreasing)}
																child {
																		node {Upward (/ downward) continuous}
																	}
																child {
																		node {Lemma Upward or Downward Continuous then Monotone Increasing}
																	}
															}
														child {
																node {Fixed Point}
																child {
																		node {Theorem Unique least Fixed Point}
																		child {
																				node {Knaster-Tarski Fixed point Theorem (replace by monotone increasing)}
																			}
																	}
																child {
																		node {Theorem Automaton Traversal as Fixed Point Iteration}
																	}
															}
													}
											}
										child {
												node {Special form of Product automaton}
												child {
														node {Theorem Automata equivalent no Bad States reachable}
														child {
																node {Set of Bad States}
															}
													}
											}
										child {
												node {Existential Quantification and Existential Quantifier}
											}
										child {
												node {Image, Preimage, Range}
												child {
														node {Efficient Range Computation}
														node {Efficient Image Computation}
														node {Efficient Preimage Computation}
													}
											}
										child {
												node {Characteristic Function of Set}
												child {
														node {Set operations}
													}
												child {
														node {Characteristic Function of Boolean Relation}
													}
											}
									}
								child {
										node {Inefficient implementation Complexity}
									}
							}
					}
			}
		child {
				node {Property Checking
						% \resizebox{\textwidth}{!}{
						% 	\begin{minipage}[t]{12cm}
						% 		\begin{itemize}
						% 			\item beginning only one circuit
						% 		\end{itemize}
						% 	\end{minipage}
						% }
					}
				child {
						node {Symbolic Model Checking (BDD based algorithms)
								% \resizebox{\textwidth}{!}{
								% 	\begin{minipage}[t]{12cm}
								% 		\begin{itemize}
								% 			\item take algorithm from equivalence checking and turn into algorithms for property checking
								% 		\end{itemize}
								% 	\end{minipage}
								% }
							}
						child {
								node {Characteristic functions for subformulas}
							}
						child {
								node {CTL Model Checking}
								child {
										node {Advantages and Disadvantages}
									}
								child {
										node {Temporal Propositional Logic}
										child {
												node {Linear Temporal Operator}
											}
										child {
												node {Path Quantifiers}
											}
									}
								child {
										node {Computation Tree Logic (CTL)}
										child {
												node {Syntax and Semantics}
											}
										child {
												node {Abbreviations}
											}
										child {
												node {Proof method for CTL}
												child {
														node {Problem Definition}
														child {
																node {Property holds for Temporal Structure iff Initial States subset SAT}
															}
													}
												child {
														node {SAT of differenet Procedures}
														child {
																node {Easy procedures}
															}
														child {
																node {Computation EU formula}
																child {
																		node {Smallest Fixpoint}
																	}
															}
														child {
																node {Computation EG formula}
																child {
																		node {Largest Fixpoint}
																	}
															}
														child {
																node {Other fixed point characterizations for efficiency reasons}
															}
													}
												child {
														node {Algorithm}
														child {
																node {Complexity}
																child {
																		node {Theorem with K size of Releation R}
																	}
																child {
																		node {Theorem PSPACE-complete if M given as sequential circuit}
																	}
															}
													}
											}
									}
							}
						child {
								node {Kripke Structure}
								child {
										node {Atomic Proposition}
									}
								child {
										node {Transform Sequential Circuit into Kripke Structure}
									}
								child {
										node {Computational Runs}
									}
								child {
										node {Path}
									}
							}
					}
				child {
						node {Bounded Model Checking (using SAT sovlers)
								% \resizebox{\textwidth}{!}{
								% 	\begin{minipage}[t]{12cm}
								% 		\begin{itemize}
								% 			\item can prove design not correct, but bounded model checking itself not able to prove that the design is correct (\alert{incomplete}, if there's no counter example it will not terminate), boolean formula which is satisfiable iff there's CE to equivalence that leads to different outputs of two circuits within k steps
								% 			\item simplify properties to just safety and liveness
								% 		\end{itemize}
								% 	\end{minipage}
								% }
							}
						child {
								node {Properties}
								child {
										node {Restriction to finite path lengths (bounded)}
										child {
												node {$M\models_k\varphi$ instead of $M \models \varphi$}
											}
									}
								child {
										node {Form of Invariants}
										child {
												node {CE's for AG safe}
											}
										child {
												node {Certificates for EF unsafe (negated invariants)}
											}
									}
							}
						child {
								node {Procedure}
								child {
										node {for $AG\varphi$ negate $\varphi' = \neg \varphi$, for $EF\varphi$ just take $\varphi' = \varphi$}
									}
								child {
										node {Propositional logic formula satisfiable iff $M\models_k \varphi'$, Tseitin Transform}
										child {
												node {Characteristic Function}
												child {
														node {Characteristic f. of the initial states}
													}
												child {
														node {Characteristic f. of the transition relation, 0 to $k-1$}
													}
												child {
														node {Checks $\varphi$ up to depth k}
														child {
																node {Simplified under assumption that check for increasing k}
															}
														child {
																node {Invariant Checking (Safety: $AG safe$)}
															}
														child {
																node {Liveness ($AF good$) Checking}
															}
													}
												child {
														node {Optional $\displaystyle\bigwedge_{i=1}^{k} P^{i-1}$ to help SAT-Solver}
													}
											}
									}
								child {
										node {CNF satisfiable, with $M\models_k \varphi'$ have Certificate / CE}
									}
								child {
										node {CNF unsatisfiable, with $M\not\models_k \varphi'$ note statement about $M\models \varphi$, next iteration step}
									}
								child {
										node {Repeat with increasing k until CE/certificate found or stopping criterion met}
									}
							}
						child {
								node {Optimizations}
								child {
										node (bmcincrementalsat) {Incremental SAT solving}
										child {
												node {Problem with $\neg P^i$ clauses getting removed}
												child {
														node {Add de-activation literal $d_i$ for each clause representing $\neg P^i$}
													}
											}
										child {
												node {Problem with Pre-Processing}
												child {
														node {Solution}
														child {
																node {Just preprocess the transition relation}
															}
														child {
																node {Preprocessor is not allowed to eliminate state variables}
															}
														child {
																node {Use simplified transition relation for BMC}
															}
														child {
																node {Turn off preprocessing during incremental SAT for BMC}
															}
													}
											}
									}
								child {
										node {Preprocessing the transition relation}
									}
							}
					}
				child {
						node {Unbounded Model Checking
								% \resizebox{\textwidth}{!}{
								% 	\begin{minipage}[t]{12cm}
								% 		\begin{itemize}
								% 			\item complete, solves problem of bounded model checking
								% 		\end{itemize}
								% 	\end{minipage}
								% }
							}
						child {
								node {BMC with Completeness Threshold}
								child {
										node (radius) {Radius (max)}
										child {
												node {Formula do termine radius is QBF (PSPACE complete)}
												child {
														node {Recurrence Radius}
														child {
																node {Computed using SAT}
															}
														child {
																node {May considerably larger than radius (example)}
															}
													}
											}
										child {
												node {Theorem No other path length less than radius}
											}
										child {
												node {Distance from initial states (min of min)}
												child {
														node {Distance of two states (min path)}
													}
											}
									}
							}
						child {
								node {k-Induktion
										% \resizebox{\textwidth}{!}{
										% 	\begin{minipage}[t]{12cm}
										% 		\begin{itemize}
										% 			\item induction proof but encoded in a sat formula
										% 		\end{itemize}
										% 	\end{minipage}
										% }
									}
								child {
										node {Algorithm}
										child {
												node {Induction Base}
												child {
														node {Sat means unsafe (CE found)}
													}
												child {
														node {Unsat can transform into implication, continue}
													}
											}
										child {
												node {Induction Step}
												child {
														node {for $k=0$ tautology check}
													}
												child {
														node {Sat continue}
													}
												child {
														node {Unsat after Base Unsat means safe, can transform into implication}
													}
											}
										child {
												node {Both have $P^0$ to $P^{k-1}$}
											}
									}
								child {
										node {Soundness}
										child {
												node {Theorem: Return Safe, then there's no error path}
												child {
														node {Base 0 to j correspond to BMC 0 to j}
														child {
																node {Bad State cannot be reached in j step}
															}
													}
												child {
														node {j steps correspond arbitrary BMC > j where step suffix always remains unsat}
													}
											}
										child {
												node {Theorem: Return Unsafe, then error path}
											}
									}
								child {
										node {Completeness}
										child {
												node {Need to add suffix for no state repetition (example)}
												child {
														node {Else algorithm won't terminate}
													}
											}
									}
							}
						child {
								node {Craig Interpolation
										% \resizebox{\textwidth}{!}{
										% 	\begin{minipage}[t]{12cm}
										% 		\begin{itemize}
										% 			\item makes us of existence of certain kinds of formulas, where you can do a fixpoint iteration using a sat solver
										% 		\end{itemize}
										% 	\end{minipage}
										% }
									}
								child {
										node {Interpolation theorem by Craig}
										child {
												node {Construction of a Craig Interpolant}
												child {
														node {Convention $c_1$ positive litral, $c_2$ negative literal}
													}
											}
									}
								child {
										node {Algorithm}
										child {
												node {Base case $I(s_0) \land \neg P(s_0)$ handlet first}
												child {
														node {If sat return unsafe / true}
														child {
																node {Error path of length 0}
															}
													}
												child {
														node {If unsat continue}
													}
											}
										child {
												node {Formula similar BMC but checking all $P(s^i)$ from 1 to $k+1$}
												child {
														node (craigformulasatoriginal) {If sat return unsafe / true}
														child {
																node {Error path from I to $\neg P$ in $\ge 1$ and $\le k + 1$ steps}
															}
													}
												child {
														node {If unsat use Craig Interpolant $C(s^1)$ of $(A, B)$}
														child {
																node {Over-approximates the states reachable in one step}
																child {
																		node {Since $C(s^1)$ is implied by $I(s^0) \land T(s^0, s^1)$, $C$ holds for all states $s^1$ reachable from $I$ in one step}
																	}
															}
														child {
																node {Restricted by the requirement $C \land B$ unsat}
																child {
																		node {No state $s^1$ satisfying $C(s^1)$ can reach $\neg P$ in up to $k$ steps}
																	}
															}
														child {
																node {Add $C$ to the initial states (forming a collection $R$)}
																child {
																		node {Apply Craig interpolation again with $R$}
																	}
															}
													}
												child {
														node {Apply until}
														child {
																node {Fixed point reached (check with $C(s^0)\rightarrow R(s^0)$)}
																child {
																		node {Return safe / false}
																		child {
																				node {Property P holds in all reachable states}
																			}
																	}
															}
														child {
																node (craigformulasat) {Formula becomes sat}
															}
													}
											}
									}
								child {
										node {Termination}
										child {
												node {If $\ge rd(T, \neg P)$, then the algorithm will (at the latest) terminate}
												child {
														node {Reverse depth (max)}
														child {
																node {Distance to bad states (like Distance from initial states but $\displaystyle \min_{t\in \neg P}$)}
															}
													}
											}
									}
							}
						child {
								node {Property Directed Reachability (PDR)
										% \resizebox{\textwidth}{!}{
										% 	\begin{minipage}[t]{12cm}
										% 		\begin{itemize}
										% 			\item gets rid of unrolling (problem with unrolling is that the formula grows)
										% 		\end{itemize}
										% 	\end{minipage}
										% }
									}
								child {
										node {Idea}
										child {
												node {Replace huge SAT problems of BMC by smaller ones}
											}
										child {
												node {Avoid proving facts which are not necessarily needed}
											}
									}
								child {
										node {Algorithm}
										child {
												node {$R_1 \subseteq R_2 \Rightarrow S_2 \subseteq S_1$}
												child {
														node {Always have $R_0 = I$}
													}
												child {
														node {$R_i$ represents $\chi(S_i)$ of state set $S_i$}
													}
												child {
														node {For $1 \le i \le N$, $R_i$ are initialized by $\emptyset$, i.e., $\chi_{S_i}$ by $1$}
													}
											}
										child {
												node {Adding a negated cube to R = removing states from S}
												child {
														node {Cube / Monomial (conjunction) negated yields a Clause (disjunction)}
													}
											}
										child {
												node {Invariants maintained}
												child {
														node {$R_i \supseteq R_{i+1}$ for $1 \le i \le N$, $S_i \subseteq S_{i+1}$}
													}
												child {
														node {For $0 \le i \le N$, the set $S_i$ overapproximates the set of states reachable from $I$ in $\le i$ steps}
													}
											}
										child {
												node {Main Loop}
												child {
														node {Start with $N=1$}
													}
												child {
														node {Do as long as $R_N \land \neg P$ sat}
														child {
																node {Extract bad state from the SAT model and generalise it to cube s}
															}
														child {
																node {Check $s \land I$}
																child {
																		node {If unsat insert $(s, N, 0)$ into proof-obligation queue, process proof obligations}
																		child {
																				node {Proof Obligation (cube, frame, depth)}
																				child {
																						node {If $R_{k-1} \land T \land s'$ is unsat}
																						child {
																								node {discharged}
																								child {
																										node {If discharged at frame k, then automatically discharged in all frames $1 \le i < k$}
																									}
																							}
																					}
																				child {
																						node {If $R_{k-1} \land T \land s'$ is sat}
																						child {
																								node {New proof obligation generated at frame $k-1$}
																								child {
																										node {If $\hat s \land I$ unsat}
																										child {
																												node {Insert proof obligation $(\hat s, k-1, d+1)$ into proof-obligation queue}
																											}
																									}
																								child {
																										node {If $\hat s \land I$ sat}
																										child {
																												node {Path of length $d + 1$ from $I$ to $\neg P$, invariant not hold}
																											}
																									}
																							}
																					}
																			}
																	}
																child {
																		node {If sat property does not hold}
																	}
															}
													}
												child {
														node {Before opening new frame, check whether $S_{i-1} \supseteq S_i$ and thus $S_{i-1} = S_i$ for some $2 \le i \le N$}
														child {
																node {If $R_i \land \neg R_{i-1}$ unsat, then the invariant property holds}
															}
													}
												child {
														node {If no new ones can be generated at frame N, a new frame $N + 1$ is opened, $R_{N+1} = \emptyset$}
													}
											}
									}
								child {
										node {Optimizations}
										child {
												node (pdrincrementalsat) {Incremental SAT}
												child {
														node {Assumptions enforce assignment to variables occurring in s'}
													}
											}
										child {
												node {Generalizing proof obligations}
												child {
														node {0,1,X Logic}
													}
											}
										child {
												node {Generalizing lemmas}
												child {
														node {Lemma}
													}
											}
										child {
												node {Pushing proof obligations to higher frames}
											}
										child {
												node {Propagation phase and syntactical termination check}
											}
										child {
												node {Strengthening SAT checks: $\neg s \land R_{k-1} \land T \land s'$}
											}
									}
								child {
										node {Termination}
                    child {
                      node {If $N > 2^{\lvert\vec{s}\rvert}$ then for sure $S_{i-1} = S_i$ for some $2 \le i \le N$}
                    }
									}
							}
					}
			}
		child {
				node {Prerequisites}
				child {
						node {Complexity Theory
								% \resizebox{\textwidth}{!}{
								% 	\begin{minipage}[t]{12cm}
								% 		\begin{itemize}
								% 			\item measure how difficult problem is
								% 			\item difference polynomial and exponential, exponential computer 1000 times faster can only process 10 additional inputs, faster computers almost don't help to scale input
								% 		\end{itemize}
								% 	\end{minipage}
								% }
							}
						child {
								node {NP-Hard
										% \resizebox{\textwidth}{!}{
										% 	\begin{minipage}[t]{12cm}
										% 		\begin{itemize}
										% 			\item class problems hardest in NP, if can solve that problem fast can solve all problems in NP fast (reduction)
										% 		\end{itemize}
										% 	\end{minipage}
										% }
									}
								child {
										node (npcomplete) {NP-Complete
												% \resizebox{\textwidth}{!}{
												% 	\begin{minipage}[t]{12cm}
												% 		\begin{itemize}
												% 			\item NP complete means it's part of NP, can guess and verify efficiently and it's at least as hard as all problems in NP
												% 			\item Problems proven by Steven Cook in 1970 that all problems in NP can be formulated as sat problem, all problems can be reduced to "is this formula satisfiable". SAT first NP complete problem. If can solve SAT fast can solve everything in NP fast
												% 			\item in practise no algorithm which runs in polynomial time in the worst case
												% 			\item there are formulas can solve quickly, with every algorithm always be input for which this algorithm needs exponential time
												% 			\item many people tried to find efficient algorithms or to prove that noone exists, no proof that exponential complexity is unavoidable
												% 		\end{itemize}
												% 	\end{minipage}
												% }
											}
									}
							}
						child {
								node {NP
										% \resizebox{\textwidth}{!}{
										% 	\begin{minipage}[t]{12cm}
										% 		\begin{itemize}
										% 			\item NP problem, problem where can guess and verify that the solution is a solution in polynomial time
										% 			\item N means non-deterministic, problem computers can't guess
										% 			\item probably more NP problem than P problems, no prove yet, P=NP problem
										% 			\item some practically relevant problems in NP, nobody found polynomial algorithm for them
										% 			\item in practise algorithms running in exponential time in worst case
										% 		\end{itemize}
										% 	\end{minipage}
										% }
									}
								child {
										node (conp) {CO-NP
												% \resizebox{\textwidth}{!}{
												% 	\begin{minipage}[t]{12cm}
												% 		\begin{itemize}
												% 			\item co means can guess a no answer and verify it
												% 			\item open problem if np and co-np the same
												% 			\item noone found way to certify the no answer of np-complete problems efficiently or to verify yes answer of co-np complete problems efficiently or prove that they are different
												% 			\item practical implications, tool says circuits equivalent
												% 			\item can beiebe tool if it says equivalent, how make sure implementer of tool did not make any bugs
												% 			\item no has CE easy to check
												% 			\item nobody has found a way to check this result in polynomial time, how can convince that yes answer in case of equivalence checking is correct
												% 			\item also sat solving if unsatisfiable, how make sure not implementation wrong
												% 			\item if classes the same then can also verify the opposite answer in polynomial time, if not the same one can't
												% 		\end{itemize}
												% 	\end{minipage}
												% }
											}
									}
								child {
										node {P
												% \resizebox{\textwidth}{!}{
												% 	\begin{minipage}[t]{12cm}
												% 		\begin{itemize}
												% 			\item P is the class of all problems where you have a solution algorithm in polynomial time without guessing
												% 			\item all P problems subset of NP problems, if don't need guessing and fast, then also fast with guessing
												% 		\end{itemize}
												% 	\end{minipage}
												% }
											}
									}
							}
					}
				child {
						node {Steps during the design of integrated circuits}
					}
			}
	\end{mindmapcontent}
	\begin{edges}
		\edge{shannon}{iteop}
		\edge{shannonbooleanfunction}{bdds}
		\edge{satcomplexity}{npcomplete}
		\edge{structuralmethods}{satsolver}
		\edge{structuralmethods}{bdds}
		\edge{equivalentdfa}{productautomaton}
		\edge{equivalencechecking}{conp}
		\edge{bmcincrementalsat}{incrementalsat}
		\edge{pdrincrementalsat}{incrementalsat}
		\edge{craigformulasatoriginal}{craigformulasat}
	\end{edges}
	% \annotation{test}{annotation}
\end{mindmap}
\end{document}
