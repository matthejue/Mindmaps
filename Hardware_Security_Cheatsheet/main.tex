\documentclass[landscape, a4paper]{article}

\input{./content/packages}
\input{./content/desgin}
\input{./content/declarations}

\begin{document}
\fontsize{3pt}{3pt}\selectfont

\begin{minipage}[t]{0.2\linewidth}
	\fbox{General}
	\begin{betterlist}
		\item \alert{Hardware Security} goes beyond classical cryptography. It protects the implementations of cryptographic algorithms against physical attacks, side-channel attacks etc. Avoids tampering with devices
		\item \alert{Security} entails that the system fulfills certain security properties which an intelligent attacker seeks to undermine. No static and complete definition or classification. \alert{Important security properties (\enquote{CIAAN}) are:} \alert{Confidentiality:} Protecting confidential information from being disclosed to unauthorized parties (no unauthorized reads), \alert{Integrity:} Ensuring that information is only modified by authorized parties (no unauthorized writes), \alert{Availability:} Making sure that information and systems are accessible to authorized parties when they need them (e.g. resistance to denial-of-service attacks), \alert{Authenticity:} Ensuring that information and communication come from the source they are supposed to come from, \alert{Non-repudiation:} Ensuring that nobody can deny having performed certain actions (like sending / receiving messages, changing data etc.)
		\item \alert{Vulnerability:} Weakness in the secure system. \alert{Threat:} set of circumstances that has the potential to cause loss or harm. \alert{Attack:} The act of a human exploiting the vulnerability in the system
		\item \alert{Safety:} System is designed without any error leading to unintended behavior. (\alert{design time})
		\item \alert{Reliability:} A correctly designed system continues to work correctly during its \alert{life-time}
		\begin{betterlist}
			\item \underline{relationship between security and safety / reliability:} Port for monitoring the system good for safety / reliability, but bad for confidentiality of the processed data. Safety problems (erroneous implementations) may also lead to security problems
		\end{betterlist}
		\item \underline{Possible Actions of Adversaries, Attacks:} Pirating Intellectual Property (IP) – illegal use of IPs (e.g. system integrators, fabrication facilities), Implementing and inserting Trojan horses, Reverse engineering of ICs, Spying by exploiting IC vulnerabilities (\enquote{backdoors}), Physical attacks, side-channel attacks, fault injection, Counterfeiting ICs by Recycling ICs and Cloning, overproducing ICs (e.g. fabrication facilities)
		\item \underline{Examples for Countermeasures to Attacks:} Encrypting secret data (Encryption has to do with scrambling to hide), Design locks or physical locks limiting the access, Devices to verify the user identities, Hiding signatures in the design files, Intrusion detection, Security policies
	\end{betterlist}
	\fbox{Supply Chain Vulnerabilities}
	\begin{betterlist}
		\item \underline{Problem 1:} Cost of Manufacturing
		\begin{betterlist}
			\item An \alert{untrusted foundry} may overproduce ICs and sell overproduced chips on its own account
			\item An \alert{untrusted assembly} may sell defective ICs, sell out-of-spec ICs (possibly noticed only by early aging, e.g.), mark correct ICs as defective and sell them on its own account
		\end{betterlist}
		\item \underline{Problem 2:} Design Complexity
		\begin{betterlist}
			\item buy design data as \alert{intellectual property} ($=$ \alert{IP}) from other companies
			\item \alert{IP Vendors} are located across the world. No control on the design process. Safety and security problem
		\end{betterlist}
		\item \underline{Several parties may be untrusted:} IP vendors (untrusted IP), System integrator (untrusted system, IP piracy), Fab (untrusted IC, IC Piracy (Counterfeiting)), Assembly (IC Piracy (Counterfeiting))
		\item  \alert{Counterfeit} chips are not restricted to Overproduced chips (foundry) and Defective / out-of-spec chips (assembly + test). The whole IC life cycle and supply chain is affected: \alert{Recycled ICs} and \alert{Cloned ICs}
		\item \alert{Soft IP:} High Level Synthesis (RTL HDL code from other vendor). \alert{Firm IP:} Logic Synthesis. \alert{Hard IP:} Physical Synthesis (Place \& Route)
	\end{betterlist}
	\includegraphics[width=0.8\linewidth]{./figures/supply_chain_vulnerabilities.png}
	\fbox{\enquote{Classical} Cryptography}
	\begin{betterlist}
		\item \alert{Cryptology:} cryptography + cryptanalysis. \alert{Cryptography:} art/science of keeping message secure. Is about algorithms protecting secret information. \alert{Cryptanalysis:} art/science of breaking ciphertext. \alert{Basic Cryptographic Scheme:} \alert{injective} and both sets have \alert{same cardinality}, so \alert{one-to-one}, \alert{bijective}, so it is \alert{reversable}, $D$ is the \alert{inverse function} of $E$ and by this also bijective
	\end{betterlist}
	\fbox{Classification by type of encryption operations}
	\begin{betterlist}
		\item \alert{Substitution ciphers:} letters of $P$ replaced with other letters by $E()$
		\begin{betterlist}
			% \item \underline{Sidenote:} One can say $key = 3$ or $key = \enquote{D}$, because $no(D) = 3$
			\item \underline{Effects:} $C$ hides chars of $P$ (plaintext), If $> 1$ key alphabet (polyalphabetic), $C$ dissipates high frequency chars
		\end{betterlist}
		\begin{betterlist}
			\item \alert{General Monoalphabetic substitution ciphers:} Each letter in $P$ is substituted by a fixed letter using a \alert{substitution table}, The \alert{key} is the substitution table, $26!=2^{88}$ substitution tables (= keys)
			\begin{betterlist}
				\item \underline{Attacks:} \sout{Exhaustive search:} Search through $2^{88}$ keys (substitution tables) is completely infeasible with today‘s computers!, \alert{Letter Frequency Attack:} In practice, not only frequencies of individual letters (\alert{1-gram} (unigram) model of a language) can be used for an attack, but also the frequency of letter pairs, letter triples, etc, The longer the ciphertext $C$, the more effective statistical analysis would be
				\item need better concealing of statistical frequencies and probably also longer keys to avoid exhaustive search
			\end{betterlist}
			\begin{betterlist}
				\item \alert{Caesar Cipher:} each letter in $P$ is substituted by a fixed letter. In this special case the \alert{key} is of length $1$, it is the shift amount
				\begin{betterlist}
					\item \underline{Attacks:}
					\begin{betterlist}
						\item \alert{Exhaustive search:} Try all possible keys until you find the right one. \enquote{Finding the right one} means \enquote{receiving a meaningful plain text}.
						\begin{betterlist}
							\item has $26$ possible keys
						\end{betterlist}
					\end{betterlist}
				\end{betterlist}
			\end{betterlist}
		\end{betterlist}
		\begin{betterlist}
			\item \alert{Polyalphabetic substitution ciphers:} several key alphabets, flatten (diffuse) somewhat the frequency distribution of letters by combining high and low distributions
			\begin{betterlist}
				\item \underline{Attack:} Frequency of pairs is somewhat hidden. Works if the attacker doesn't know that polyalphabetic substitution with $n$ keys is used, If one knows the $n$, then one can break the whole text into $n$ parts and for these a \alert{statistical analysis} works as for the monialphabetic substitution cipher with the unigram model
			\end{betterlist}
			\begin{betterlist}
				\item \alert{Vigenère Tableaux Method:} special case of polyalphabetic substitution with $n$ key alphabets. For each key alphabet the special case of Caesar cipher is chosen, i.e., each key alphabet can be represented by one letter%. One can describe a row either by the shift or by saying which letter $c_i$ it mapped to which letter $c_j$ and takes $b_j$ as name of the row, choosing the last choice one can describe $n$ keys by a word of length $n$
				\begin{betterlist}
					\item $26^n$ different keys, one has to choose $n$ large enough
					\item \underline{Attack:} same problem as for polyalphabetic substitution ciphers
				\end{betterlist}
			\end{betterlist}
		\end{betterlist}
	\end{betterlist}
	\begin{betterlist}
		\item \alert{Transposition (permutation) ciphers:} order of letters in $P$ rearranged by $E()$
		\begin{betterlist}
			% \begin{betterlist}
			% 	\item rearrange letters in plaintext to produce ciphertext
			% \end{betterlist}
			\item \underline{Effects:} $C$ scrambles text, hides \alert{$n$-grams} for $n > 1$ (combinations of $n$ letters, e.g. th)
		\end{betterlist}
		\begin{betterlist}
			\item \alert{Rail-Fence Cipher}, columnar transposition, \alert{key} = number of columns
			\begin{betterlist}
				\item \underline{Attack:} Number of columns, the key space is restricted if the text is short
			\end{betterlist}
		\end{betterlist}
	\end{betterlist}
	\begin{betterlist}
		\item \alert{Product ciphers:} Idea to combine two or more ciphers to enhance the security of the cryptosystem. Built of multiple blocks, either \alert{Substitution} or \alert{Transposition}. Might not be stronger than individual components used separatly (two times ceasar is like one time ceaser with key being sum of keys) or as strong as individual components (two times ceasar with keys $3$ and $23$)
		\begin{betterlist}
			\item \underline{Effects:} Can do all what Substitution and Transposition ciphers can, so more secure if used well
			\item \alert{Two-block product cipher:} $E2(E1(P, KE1), KE2)$, may be repeated to form several encryption rounds
			\item \alert{AES}
		\end{betterlist}
	\end{betterlist}
	\fbox{Classification by key}
	\begin{betterlist}
		\item \alert{Crypto System with Keys:} $P = D(K_D, E(K_E, P))$, $P = D(K_D, C)$. $C = E(K_E, P)$, $D/E =$ set of d/encryption algorithms, $K_D/K_E$ selects $D_j/E_i \in D/E$
		\begin{betterlist}
			\item \underline{advantage of crypto systems with keys:}, Keeping the encryption / decryption algorithm secret is not needed, Keys can regulary be changed, to increase security
		\end{betterlist}
	\end{betterlist}
	\begin{betterlist}
		\item \alert{Symmetric cryptosystems} $K_E = K_D$ (secret key encryption)
		\begin{betterlist}
			\item Encipher and decipher using the same key or one key is easily derived from the other. Only sender $S$ and receiver $R$ know the \alert{secret key}. As long as the key remains secret it also provides \alert{authentication} ($=$ proof of sender’s identity)
			\item \underline{disadvantage:} one needs a \alert{key exchange}, the sender and the receiver have to agree on the same key and they key should be secret, one needs a way to transport the secret key via a secure channel from the sender to the receiver
			\item \alert{AES}
		\end{betterlist}
	\end{betterlist}
	\begin{betterlist}
		\item \alert{Asymmetric cryptosystems} $K_E \ne K_D$ (public key encryption)
		\begin{betterlist}
			\item Encipher and decipher using different keys, computationally infeasible to derive one from other. Also other applications like \alert{authentication} (authenticity, able to sign message, so it can be sure it can only come from oneself). Only owner of \alert{private key} $K_D$ can decode msgs that could be encoded by anybody with \alert{public key} $K_E$. Asymmetric schemes based on a \alert{one-way function} (based on mathematically hard problems) $f()$: Computing $y = f(x)$ easy, but $x = f^{-1}(y)$ is computationally infeasible
			\item \underline{advantage:} distribution of public key for encryption can be done over an insecure channel
			% \item allows to share \alert{public key}, secure key exchange not needed (for \alert{confidentiality}, message should be kept secret)
			\item \underline{disadvantage:} usually assymetric crypto systems are much slower than symmetric ones
			\item \alert{RSA}
		\end{betterlist}
		\item \alert{Hybrid Asymmetric-symm. Systems:}
		\begin{betterlist}
			\item Key exchange (for symmetric schemes) and digital signatures performed with (slow) asymmetric algorithms. Encryption of data is done using (fast) symmetric ciphers
		\end{betterlist}
		\includegraphics[width=0.6\linewidth]{./figures/hybrid_assymetric-symmetric_systems.png}
	\end{betterlist}
	\fbox{Classification by way to process plaintext}
	\begin{betterlist}
		\item \alert{Stream Ciphers:} Bitwise Encryption and Decryption. Encrypt bits individually. Encryption and decryption are simple additions modulo 2 (aka XOR). Encryption and decryption are the same functions
	\end{betterlist}
\end{minipage}
\begin{minipage}[t]{0.2\linewidth}
	\begin{betterlist}
		\item \alert{Stream Ciphers continue}
		\begin{betterlist}
			\item \alert{Encryption:} $y_i = e_{si}(x_i) = s_i \oplus x_i$, where $x_i, y_i, s_i \in \{0, 1\}$. \alert{Decryption:} $x_i = e_{si}(y_i) = s_i \oplus y_i$
			\begin{betterlist}
				\item \underline{Attack:}

				\includegraphics[width=0.7\linewidth]{./figures/stream_cipher_attack.png}
				\includegraphics[width=0.3\linewidth]{./figures/stream_ciphers.png}
				\begin{betterlist}
					\item if a prefix of plaintext is known, then $S_0, S_1, \ldots, S_k$ are known, then paramters of the random function are known and thus all $S_i$ are known
				\end{betterlist}
			\end{betterlist}
			% \item need a method to generate key stream efficiently, starting from some \enquote{seed}
			% \item usually small and fast common in embedded device
		\end{betterlist}
	\end{betterlist}
	\begin{betterlist}
		\item \alert{Block Ciphers:} always encrypt a full block (several bits). Block Cipher Primitives
		\begin{betterlist}
			% \item are common for Internet applications
			\item \alert{Claude Shannon:} There are two primitive operations with which strong encryption algorithms can be built:
			\begin{enumerate}
				\item \alert{Confusion:} An encryption operation where the \alert{relationship between key and ciphertext is obscured}, Today, a common element for achieving confusion is substitution, which is found in AES and other ciphers
				\item \alert{Diffusion:} An encryption operation where the \alert{influence of one plaintext symbol is spread over many ciphertext symbols} with the goal of hiding statistical properties of the plaintext, A simple diffusion element is the \alert{bit permutation} (in other context known as Tranposition)
			\end{enumerate}
			\begin{betterlist}
				\item Both operations by themselves are suboptimal in providing security. A cipher must include confusion and diffusion elements
			\end{betterlist}
			\item \alert{polyalphabetic cipher} is a block cipher with (small) $8$-bit-blocks as char is encoded by $8$ bits
			\item \alert{AES}
		\end{betterlist}
	\end{betterlist}
	\fbox{Advanced Encryption Standard (AES)}
	\begin{betterlist}
		\item \underline{requirements for all AES candidate submissions were:}
		\begin{betterlist}
			\item Block cipher with 128-bit block size
			\item Three supported key lengths: $128$, $192$ and $256$ bit
			\begin{betterlist}
				\item the number of AES rounds depends on the chosen key length ($10$, $12$, $14$)
			\end{betterlist}
			\item Security relative to other submitted algorithms
			\item Efficiency in software and hardware
			\begin{betterlist}
				\item \alert{Implementation in Software:} straightforward implementation is well suited for $8$-bit processors (e.g., smart cards) with small amount of memory, because operations are on bytes, but inefficient on $32$-bit or $64$-bit processors.
				% \item \alert{T-Tables:} When executing MixColumn for one column of the state matrix one can speed up the calculation of the resulting vector which is made of $4$ \alert{columns} with one entry of the column of the state matrix multiplied with the values of one column of the $4\times 4$ matrix with $3$ exor operations between the columns. There are $2^8$ possible values for this one value from the column of the state matrix, thus one needs a lookup table with $2^8$ values of $32$-bit values concatenating the resulting values of one column of the calculation. One needs $4$ such lookup tables, because the $4\times 4$ matrix has $4$ columns. One can then calculate the resulting vector by $4$ lookups to the $4$ lookup tables and $3$ exor operations.
			\end{betterlist}
		\end{betterlist}
		\item \underline{Round Structure and Internal Structure:}
		\begin{betterlist}
			\item state $A$ (i.e., the $128$-bit data path) can be arranged in a $4\times 4$ \alert{state matrix} with $A_0,\ldots, A_{15}$ denoting the $16$-byte input of AES
		\end{betterlist}
		\begin{minipage}[b]{0.64\linewidth}
			\includegraphics[width=\linewidth]{./figures/aes_round_structure.png}
		\end{minipage}
		\begin{minipage}[b]{0.34\linewidth}
			\includegraphics[width=0.5\linewidth]{./figures/fourtimesfourmatrix.png}
			\includegraphics[width=\linewidth]{./figures/shiftrow_matrix.png} (every field $B_i$ corresponds to $SubByte(A_{ShiftRow^{-1}(i)})$)
			\includegraphics[width=\linewidth]{./figures/mixcolumn.png}
			\includegraphics[width=\linewidth]{./figures/aes_algorithm.png}
		\end{minipage}
		\begin{minipage}[b]{0.49\linewidth}
			\includegraphics[width=\linewidth]{./figures/key_schedule.png}
		\end{minipage}
		\begin{minipage}[b]{0.49\linewidth}
			\includegraphics[height=0.6\linewidth, angle=90]{./figures/functiong.png}
			\includegraphics[width=\linewidth]{./figures/aes_round_structure_details.png}
		\end{minipage}
		\begin{betterlist}
			\item \alert{Byte Substitution Layer:}
			\begin{betterlist}
				\item $16$ \alert{identical} S-Boxes that are \alert{bijective} (can be \alert{uniquely reversed})
				\item only \alert{nonlinear} elements of AES, i.e., $ByteSub(A_i) \oplus ByteSub(A_j) \ne ByteSub(A_i \oplus A_j)$, for $i, j = 0,\ldots,15$
				\item in software implementations, the S-Box is usually realized as a lookup table
				\item described as computing \alert{multiplicative inverse} in $GF(2^8)$

				\includegraphics[width=0.6\linewidth]{./figures/importanceofsboxes.png}
			\end{betterlist}
			\item \alert{Diffusion Layer:} Provides diffusion over all input state bits. Performs a linear operation on state matrices $A$ and $B$, i.e., $DIFF(A) \oplus DIFF(B) = DIFF(A \oplus B)$
			\begin{betterlist}
				\item \alert{ShiftRows Sublayer:} Rows of the state matrix are shifted cyclically
				\item \alert{MixColumn Sublayer:} Linear transformation which mixes each column of the state matrix. All arithmetic is done in the Galois field $GF(2^8)$ ($\{0, 1\}^8$ with addition as bitwise exor and an \enquote{appropriate} multiplication). So one does multiplication with the same matrix and this matrix is fixed for AES. This matrix needs to have the property of being \alert{invertable}
			\end{betterlist}
			\item \alert{Key Addition Layer:}
			\begin{betterlist}
				\item $C \oplus k_i$, state matrix $C = C_0C_1\ldots C_{15}$, \alert{subkey} $k_i$ generated in the \alert{key schedule}, $\#subkeys = \#rounds + 1$
				% , different key schedules for the d{i}fferent key sizes
				\item \alert{word-oriented:} $1$ word = $32$ bits
				\item \alert{round coefficient} $RC$ represents an element of $GF(2^8)$. Until $RC[8]$ it is leftshift, then one can't shift anymore and chooses elements of the Galois field again, starting with $RC[1] = x^0 = (00000001)_2$
			\end{betterlist}
		\end{betterlist}
		\item \alert{Decryption:}, All layers must be inverted, Inverse S-Box: $A_i = S^{-1}(B_i) = S^{-1}(S(A_i))$ usually realized as a lookup table, The product of the inverse of the $4\times 4$ and the $4\times 4$ matrix (in $GF(2^8)$) is the identity matrix ($1$es from top left to bottom right), Key Addition layer is its own inverse, Decryption key schedule. Before starting decryption, first compute all subkeys from the actual key (as done for encryption) and apply in reverse order

		\begin{minipage}[b]{0.5\linewidth}
			\includegraphics[width=0.7\linewidth]{./figures/invshiftrowslayer.png}
		\end{minipage}
		\begin{minipage}[b]{0.5\linewidth}
			\includegraphics[width=0.7\linewidth]{./figures/inversemixcolumnlayer.png}
		\end{minipage}
		\item \underline{Attacks / Security:}, \sout{Brute-force attack:} Due to the key length of $128$, $192$ or $256$ bits, a brute-force attack is not possible, \sout{Analytical attacks:} There is no analytical attack known that is better than brute-force, Side-channel attack
	\end{betterlist}
\end{minipage}
\begin{minipage}[t]{0.2\linewidth}
	\begin{betterlist}
		\item \underline{Encrypting longer plain text:}
		\begin{betterlist}
			\item \alert{ECB} = Electronic Code Book Mode (Straightforward application of block cipher)
			\begin{betterlist}
				\item Problem that with the same key identical plain text blocks are mapped to the same cipher text blocks (it is deterministic). Each pixel $\hat= 1$ Byte, $16$ pixels = $1$ AES-block
			\end{betterlist}
			\includegraphics[width=0.8\linewidth]{./figures/ecb.png}
			\includegraphics[width=0.8\linewidth]{./figures/ecb2.png}
			\begin{betterlist}
				\item \alert{Traffic analysis and substitution attack:} If know block with encoding of account number, without knowing how encryption works, one can replace ones own encrypted account number with account number of other account in other transmission
			\end{betterlist}
			\item \alert{CBC} = Cipher Block Chaining Mode
			\begin{betterlist}
				\item \underline{advantage:} no \alert{traffic analysis} possible
			\end{betterlist}

			\includegraphics[width=0.7\linewidth]{./figures/cbc.png}

			\includegraphics[width=0.5\linewidth]{./figures/cbc2.png}
		\end{betterlist}
	\end{betterlist}
	\fbox{RSA}
	\begin{betterlist}
		\item \alert{Key Generation:}
		\begin{enumerate}
			\item choose two large primes $p$, $q$
			\item compute $n = p \cdot q$
			\item compute $\Phi(n) = (p - 1) \cdot (q - 1)$
			\begin{betterlist}
				\item $\Phi(n) = |\{a \mid a\in \{0, \ldots, n-1\}, gcd(a, n) = 1\}|$, is equal to the number of invertible / relatively prime elements in $\mathbb{Z}/n\mathbb{Z}$
			\end{betterlist}
			\item select an arbitrary public exponent $e \in \{1, 2, \ldots, \Phi(n) - 1\}$ such that $gcd(e, \Phi(n) ) = 1$
			\begin{betterlist}
				\item computations are done in $\mathbb{Z}/ \Phi(n)\mathbb{Z}$, $e$ must have inverse in $\mathbb{Z}_{\Phi(n)}$
			\end{betterlist}
			\item compute the private key $d \in \{1, 2, \ldots , \Phi(n) - 1\}$ s.t. $d \cdot e \equiv 1 \mod \Phi(n)$
			\begin{betterlist}
				\item E.g. computed with extended Euklid algorithm computing $gcd(e, \Phi(n))$
				\item $d$ is the inverse of $e$ in $\mathbb{Z}_{\Phi(n)}$, $d$ has $4096$ bits, $d\le 2^{4096}-1$
			\end{betterlist}
			\item RETURN $k_{pub} = (n, e), k_{pr} = d$
		\end{enumerate}
		\item \alert{Ecnryption:} $y = x^e \mod n$, \alert{Decryption:} $x = y^d \mod n$
		\item \alert{Authentication / Signing:}
		\begin{betterlist}
			\item $(x^e)^d = x^{ed} = (x^d)^e \equiv x \mod n$, thus it is also possible to encrypt with the private key and decrypt with the public key
			\item[\color{PrimaryColor}\textbf{1.} ] A sends $(M, e_{K_{prA}}(M))$ to B
			\item[\color{PrimaryColor}\textbf{2.} ] B checks whether $M = d_{K_{pubA}}(e_{K_{prA}}(M))$ on recieving it
			\item to make it more efficient A uses a known hash function to compute a shorter $hash(M)$ and encrypt this: $e_{K_{prA}}(hash(M))$
		\end{betterlist}
		\item \alert{Attacks / Security:}
		\begin{betterlist}
			\item timing and accoustic \enquote{chosen cipher text} attack
			\item relies on the hardness to derive the \alert{private exponent} $d$ given the public key $(n, e)$
			\item if it would be possible to factorize $n$, then it would also be possible to compute $\Phi(n)= (p - 1) \cdot (q - 1)$. Use very big prime numbers $p$ and $q$ to make it hard to factorize $n$ into $p$ and $q$
			\item with the public key $e$ it would then be possible to compute the inverse of $e$ in $\mathbb{Z}_{\Phi(n)}$
			\begin{betterlist}
				\item with Euklid‘s algorithm $gcd(e, \Phi(n) ) = 1$ is computed as well as integers $x$ and $y$ with $x \cdot e + y \cdot \Phi(n) = 1$
				\item then $x$ mod $\Phi(n)$ is the multiplicative inverse, i.e., $x$ mod $\Phi(n)$ is the private key $d$
			\end{betterlist}
		\end{betterlist}
	\end{betterlist}
	\fbox{Mathematical background}
	\begin{betterlist}
		\item \underline{Overview:}
		\begin{betterlist}
			\item \alert{finite field} $(\{0, 1\}^8, +, \cdot)=GF(2^8)$ is a special case of a Galois field $GF(p^k)$, with a prime number $p$ and a natural number $k$, having $p^k$ elements
			\begin{betterlist}
				\item AES needs fitting definitions of $+$ and $\cdot$ on $\{0, 1\}^8$ to turn it into a \alert{finite field}. Small finite field with $256$ elements
				\item The irreducible polynomial used in AES is Part of its specification. It is $g(X) = X^8 + X^4 + X^3 + X + 1$. Several irreducable polynomials of degree $8$
				\item one needs finite field property at point where one wants to invert the MixColumn Operation, one needs the property of having multiplicative inverse, to derive inverse matrix
				% \item AES Summary and Explanation, you can use this complete nice mathematical background for aes and just construct a multiplication table you just take two bytes use this mathematical approach and compute the product of two bytes which result in a byte and then you take this table and you forgot about all the mathematical background and you can still do computations in aes because in aes you Just need this table this is true for aes but this is not true for what we will see next this RSA for RSA we really cannot compress everything you must know into one table for this we need some some insight into mathematical background. Byte, length 8, degree 7, Irreducible then each row contains a 1, there see ninverse element to row element, apart from 0, Small hint key schedule of AES, remainder of polynomial division, MixColumn multiplication connection, single operations are always additions or multiplications of bytes
			\end{betterlist}
			\item $(\mathbb{Z}/m\mathbb{Z}, +, \cdot)$, is a \alert{field} and coincides with $GF(m)$ if $m$ is a prime number, else it is a Commutative ring with multiplicative identity $\overline{1}$, if $n$ is prime it is a field
			\begin{betterlist}
				\item to be useable for AES, $m$ must be a prime number, but $2^8-1$ isn't
				\item RSA, modulo arithmetic, calculations in the ring $(\mathbb{Z}/m\mathbb{Z}, +, \cdot)$. RSA is a huge residue class ring, $2.048$ Bits, in the order of $2^{2046}$, $m$ is product of two really huge prime numbers, just on table not possible
			\end{betterlist}
		\end{betterlist}
		\begin{betterlist}
			\item \alert{Groups}
			\begin{betterlist}
				\item $(R, *)$, $R$ is a non-empty set, $*$: $R \times R \rightarrow R$ is a \alert{group} \textit{iff}
				\begin{betterlist}
					\item $*$ is \alert{associative}
					\item an \alert{(unique) identity element} (unit element) $n \in R$ with $a * n = n * a = a \enspace\forall a\in R$
					\item for each $a\in R$ exists an \alert{inverse element} $a^{-1}\in R$ with $a * a^{-1} = a^{-1} * a = n$
				\end{betterlist}
				\item \alert{abelian group} \textit{iff} $*$ is commutative
			\end{betterlist}
			\begin{betterlist}
				\item \alert{Fields (germ. Körper)}
				\begin{betterlist}
					\item $(F, +, \cdot)$, $F$ is a non-empty set, $+,\cdot$: $F \times F \rightarrow F$ is a \alert{field} \textit{iff}
					\begin{betterlist}
						\item $(F, +)$ is an \alert{abelian group}
						\item \alert{Multiplication} is \alert{associative}
						\begin{betterlist}
							\item already required by \alert{abelian group} property
						\end{betterlist}
						\item \alert{Multiplication} is \alert{commutative}
						\begin{betterlist}
							\item already required by \alert{abelian group} property
						\end{betterlist}
						\item $(F\setminus \{0\}, \cdot)$ is an \alert{abelian group} ($0$ is the additive identity)
						\item \alert{Distribuitivity}
					\end{betterlist}
					\item \alert{Difference} to \alert{commutative rings} with (multiplicative) identity: For each element of $F\setminus\{0\}$ there is a multiplicative inverse
				\end{betterlist}
			\end{betterlist}
			\begin{betterlist}
				\item \alert{Rings}
				\begin{betterlist}
					\item $(R, +, \cdot)$, $R$ is a non-empty set, $+,\cdot$: $R \times R \rightarrow R$ is a \alert{ring} \textit{iff}
					\begin{betterlist}
						\item $(R, +)$ is an \alert{abelian group}
						\item \alert{Multiplication} is \alert{associative},
						\item \alert{(Special) Distributivity}: $a \cdot (b + c) = a \cdot b + a \cdot c$ and $(b + c)\cdot a = b \cdot a + c\cdot  a$ (commutativity of multiplication not required)
					\end{betterlist}
					\item \alert{commutative ring} \textit{iff} the multiplication is also commutative
				\end{betterlist}
			\end{betterlist}
		\end{betterlist}
		\fbox{Greatest common devisor (gcd)}
		\begin{betterlist}
			\item \underline{Prime factorization:}
			\begin{betterlist}
				\item $24 = 2\cdot 12 = 2\cdot 2\cdot 6 = \textcolor{PrimaryColor}{2}\cdot \textcolor{PrimaryColor}{2}\cdot 2\cdot \textcolor{PrimaryColor}{3}$. $36 = 2\cdot 18 = 2\cdot 2\cdot 9 = \textcolor{PrimaryColor}{2}\cdot \textcolor{PrimaryColor}{2}\cdot \textcolor{PrimaryColor}{3}\cdot 3$, Not $2\cdot 18 = 2 \cdot 3\cdot 6$, is only correct be coincidence, choose smallest possible prime number first
				\item $gcd(24, 36) = \textcolor{PrimaryColor}{2}\cdot \textcolor{PrimaryColor}{2}\cdot \textcolor{PrimaryColor}{3} = 12$
			\end{betterlist}
			\item \underline{Devisor series:}
			\begin{betterlist}
				\item $devseries(24) = (1, 2, 3, 4, 6, 8, \textcolor{PrimaryColor}{12}, 24)$. $devseries(36) = (1, 2, 3, 4, 6, 9, \textcolor{PrimaryColor}{12}, 18, 36)$
				\item $gcd(24, 36) = \textcolor{PrimaryColor}{12}$
			\end{betterlist}
			\item \underline{Euklidian algorithm:}
			\begin{betterlist}
				\item $36\mod 24 = 12$. $24\mod \textcolor{PrimaryColor}{12} = 0$
				\item $gcd(36,24) = 12$
			\end{betterlist}
			\item \alert{Least common multiple (lcm)}
			\begin{betterlist}
				\item $gcd(6, 8) = \dfrac{6\cdot 8}{lcm(6, 8)} = \dfrac{48}{24} = 2$
			\end{betterlist}
			\begin{betterlist}
				\item \underline{Prime factorisation:}
				\begin{betterlist}
					\item $84 = 2\cdot 2\cdot 3\cdot 7 = 2^2\cdot 3\cdot \textcolor{PrimaryColor}{7}$. $120 = 2\cdot 2\cdot 2\cdot 3\cdot 5= \textcolor{PrimaryColor}{2^3}\cdot \textcolor{PrimaryColor}{3}\cdot \textcolor{PrimaryColor}{5}$
					\item $lcm(84, 120) = \textcolor{PrimaryColor}{2^3}\cdot \textcolor{PrimaryColor}{3}\cdot\textcolor{PrimaryColor}{5}\cdot \textcolor{PrimaryColor}{7} = 840$
				\end{betterlist}
			\end{betterlist}
			\begin{betterlist}
				\item \underline{Multiple series:}
				\begin{betterlist}
					\item $mulseries(6) = (6, 12, 18, \textcolor{PrimaryColor}{24}, 30, 36, 42, 48)$. $mulseries(8) = (8, 16, \textcolor{PrimaryColor}{24}, 32, 40, 48)$
					\item $lcm(6, 8) = \textcolor{PrimaryColor}{24}$
				\end{betterlist}
			\end{betterlist}
			\begin{betterlist}
				\item \underline{Greatest common divisor (gcd):}
				\begin{betterlist}
					\item $lcm(6, 8) = \dfrac{6\cdot 8}{gcd(6, 8)} = \dfrac{48}{2} = 24$
				\end{betterlist}
			\end{betterlist}
		\end{betterlist}
	\end{betterlist}
\end{minipage}
\begin{minipage}[t]{0.2\linewidth}
	\fbox{Residue class ring}
	\begin{betterlist}
		\item $\boxed{12 / 10 = 1 \wedge 12 \mod 10 = 2 \enspace(\text{remainder})} \Rightarrow 2 \equiv 12 \mod 10 \Leftrightarrow 2 + 1 \cdot 10 = 12 + 0 \cdot 10 \Leftrightarrow \boxed{2 + 1 \cdot 10 = 12}\Leftrightarrow 2 + 2 \cdot 10 = 12 + 1 \cdot 10$ ($12$ is the dividend, because it's larger than $2$, $0\le 2< 10$)
		\item \alert{Division with remainder in $\mathbb{Z}$:} For each $a \in \mathbb{Z}$ there is a unique integer $r$ with $0 \le r < m$ and $a = q \cdot m + r$ for some $q \in Z$ and $m \in \mathbb{N}, m > 1$
		\begin{betterlist}
			\item $10 / 4 = 1\enspace R:2$ (was bleibt übrig, wenn man Vielfache des Divisors so nah wie möglich aber kleiner an Dividend bekommen will) or $10 \mod 4 = 2$ (wieviel über Modul / Devisor drüber, wenn man Vielfache des Divisors so nah wie möglich aber kleiner an Dividend bekommen will), $4 / 10 = 0\enspace R:4$ (bei Vielfachen $0$ des Modul / Devisor  wieviel es bis zum Dividend ist) or $4 \mod 10 = 4$ (bei Vielfachen $0$ des Modul / Devisor um wieviel man darüber ist)
		\end{betterlist}
		\item $a, b \in Z$ are \alert{congruent modulo} $m$ ($a \equiv b \mod m$) \textit{iff} $a - b = q \cdot m$ for some $q \in Z$
		\begin{betterlist}
			\item $a \equiv b \mod m$ iff the division with remainder wrt. $m$ gives the same remainder for $a$ and $b$
		\end{betterlist}
		\item The \alert{residue class} of $r \in \mathbb{Z}$ with $0 \le r < m$ is the set $\overline{r} = \{a \in \mathbb{Z} \mid a \equiv r \mod m\} = \{q \cdot m + r \mid q \in \mathbb{Z}\}$
		\begin{betterlist}
			\item $(\mathbb{Z}/m\mathbb{Z}, +, \cdot), \mathbb{Z}/m\mathbb{Z} = \{\overline{0}, \overline{1}, \ldots, \overline{m-1}\}$
			\item for $a \in \overline{r}$ the integer $a \mod m$ is the unique element $r$ of $\overline{r}=\overline{a}=\{0\cdot m + r, 1\cdot m + r, \ldots, a,\ldots\}=\{q\cdot m + r \mid q\in\mathbb{Z}\}$ with $0 \le r < m$ (so in the example $\overline{13} = \overline{3}$)
			\item each $i \in \mathbb{Z}$ is in exactly one of $m$ pairwise disjoint residue classes: $\overline{0}, \overline{1}, \ldots, \overline{m-1}$
		\end{betterlist}
		\item If $a_1 \equiv a_2 \operatorname{mod} m$, $b_1 \equiv b_2 \operatorname{mod} m$ then
		\begin{betterlist}
			\item $a_1 + b_1 \equiv a_2 + b_2 \operatorname{mod} m$
			\item $a_1 \cdot b_1 \equiv a_2 \cdot b_2 \operatorname{mod} m$
		\end{betterlist}
		\item \underline{Addition and Multiplication well definied:} $\overline{a} + \overline{b} = \overline{a + b}$, $\overline{a} \cdot \overline{b} = \overline{a \cdot b}$
		\begin{betterlist}
			\item Addition and multiplication on $\mathbb{Z}/m\mathbb{Z}$ are \alert{well-defined}, since for the result it does not matter which representatives of $a$ and $b$ are chosen
			\item residue class ring $(\mathbb{Z}/m\mathbb{Z}, +, \cdot)$ forms a \alert{commutative ring} with \alert{multiplicative identity} $\overline{1}$ for all $\overline{p} \in \mathbb{Z}/m\mathbb{Z}$
			\item \underline{Example:} \alert{residue class ring:} $\mathbb{Z}/5\mathbb{Z} = \{\overline{0}, \overline{1}, \overline{2}, \overline{3}, \overline{4}\}$ and one \alert{residue class:} $\overline{2} = \{q\cdot 5 + 2 \mid q\in \mathbb{Z}\}$, if one does computation one does not handle infinite sets but handle representatives: $\overline{2} + \overline{3} + \overline{4} = \overline{2 + 3 + 4} = \overline{4}$, modulo operation gives smallest possible element in residue class
			\item \alert{Modular division:} $\overline{b}/\overline{a} = \overline{b}\cdot \overline{a}^{-1}$
			\item \alert{Modular reduction:}
			\begin{betterlist}
				\item $3^8 \mod 7 = ((81 \mod 7) \cdot (81 \mod 7)) \mod 7 = 4 \cdot 4 \mod 7 = 16 \mod 7 \equiv 2 \mod 7$
			\end{betterlist}
		\end{betterlist}
	\end{betterlist}
	\fbox{Polynomial rings over $GF(2)$}
	\begin{betterlist}
		\item $F[X]$: All polynomials in one variable $X$ over the field $F$, coefficients are elements of $F$
		\item $F[X]_n$: Subset of $F[X]$ with $deg(g) < n$ for polynomials $g$
		\item we map $\{0,1\}^k$ bijectively to $GF(2)[X]_k$ by the mapping $\varphi(v_{k-1}, \ldots, v_0) = v_{k-1} X^{k-1} + \ldots + v_2 X^2 + v_1 X + v_0$ in order to be able to define a \alert{multiplication} on $\{0,1\}^k$
		\begin{betterlist}
			\item the usual \alert{polynomial addition} in $GF(2)[X]_k$ \enquote{is compatible} with bitwise exor on $\{0,1\}^k$
		\end{betterlist}
		\item \alert{Residue Class Ring Modulo a Polynomial:} $\overline{F(X)} = F[X] / g(X)$%$:=\{\overline{u(X)} \mid u(X) \in F[X]\}$
		\begin{betterlist}
			\item \alert{residue class of $u(X)$ modulo $g(X)$}: $\overline{u(X)}:=\{v(X) \in F[X] \mid v(X) \bmod g(X)=u(X) \bmod g(X)\}$,\quad$u(X),g(X) \in F[X] \text { with } \operatorname{deg}(g(X))\geq 1$
			\item exactly $2^k$ different residue classes modulo $g(X)\in GF(2)[X]_{k+1}$, the classes $\overline{r(X)}$ with $deg(r(X)) < k$ in the residue class ring $GF(2)[X]/g(X)$
			\item \alert{Addition and Multiplication in $F[X]/g(x)$:} $\overline{u(X)}+\overline{v(X)}:=\overline{u(X)+v(X)}$ and $\overline{u(X)} \cdot \overline{v(X)}:=\overline{u(X) \cdot v(X)}$
			\begin{betterlist}
				\item again well-defined, because it doesn't matter what representetives one chooses
				\item \alert{bijective mapping} $\psi:\{0,1\}^k\rightarrow G F(2)[X] / g(X)$\\
				with $\psi\left(v_{k-1}, \ldots, v_0\right)=\overline{v_{k-1} X^{k-1}+\ldots+v_1 X+v_0}$ and $g(X)\in GF(2)[X]_{k+1}$
				\item \alert{Addition} in $GF(2)[X]/g(X)$ is bitwise exor on $\{0,1\}^k$%, because if have polynomial with degree smaller than $k$ and a polynomial with degree smaller than $k$, than the division with $g(X)$ doesn't change anything, becase we already have something smaller than $k$, so the remainder is the element itself
				\item \alert{Multiplication}: $\left(v_{k-1}, \ldots, v_0\right) \cdot\left(w_{k-1}, \ldots, w_0\right):=\psi^{-1}\left(\psi\left(v_{k-1}, \ldots, v_0\right) \cdot \psi\left(w_{k-1}, \ldots, w_0\right)\right)$
				\begin{betterlist}
					\item multiplication in $\{0,1\}^k$ \enquote{via} multiplication in $GF(2)[X]/g(X)$, works since $GF(2)[X]/g(X)$ is closed under multiplication%. So product of two bitvectors defined by using the mapping into residue classes, doing the mulitplication of residue classes and then mapping back
					% \item Example, polymomial with $X^4$ would be out of the polynomial ring with degree smaller than $k=3$, therefore consider residue classes which means one takes result and reduce by polymomial with degree $k=3$, so remainder has a degree smaller than $3$
				\end{betterlist}
			\end{betterlist}
			\begin{betterlist}
				\item for $(GF(2)[X]/g(X), +, \cdot)$ to be a field, there must be multiplicative inverse for all elements $\ne 0$
				\begin{betterlist}
					% \item if $(GF(2)[X]/g(X), +, \cdot)$ is a field, then also $(\{0, 1\}^k, +, \cdot)$
					\item $g(X)$ must be \alert{irreducable}
					\item a polynomial $g(X) \in F[X]$ with $deg(g(X)) > 0$ is \alert{irreducible} \textit{iff} the following holds: If $g(X) = u(X) \cdot v(X)$ for $u(X), v(X) \in F[X]$ then $u(X) \in F$ or $v(X) \in F$
					\begin{betterlist}
						% \item \alert{irreducable} intuitively means that one doesn't have a decomposition of $g(X)$ into two non-trivial factors, so if one has $g(x) = u(X)\cdot v(X)$ then either $u(X)$ or $v(X)$ have to be a field element, trivial if one of them is a field element and non-trivial if one can really decompose it into two non-trivial parts, it's similiar to prime numbers, if have integer number, one can also ask whether one can decompose it into the product of two non-trivial numbers or whether for each decomposition into two factors at least one for them has to be the one, if one computes the decomposition into prime factors, one only has one prime factor, one cannot decompose the prime numbers into non-trivial factorisation.
						\item Field element $\hat =$ Polynomial of degreee $0$
					\end{betterlist}
				\end{betterlist}
			\end{betterlist}
			\item \underline{Polynomial Residue Class Ring:} Let $g(X)\in F[X]$ with $deg(g(X)) > 0$. $g(X)$ is \alert{irreducible} \textit{iff} $(F[X]/g(X), +, \cdot)$ is a field
			% \begin{betterlist}
			% 	\item \underline{Lemma: Polynomial Residue Class Ring:} For each $u(X), v(X) \in F[X] \setminus \{0\}$ with $max(deg(u(X), deg(v(X)) > 0$ there is a gcd $g(X) \in F[X]$ and there is a representation $g(X) = q_u(X) \cdot u(X) + q_v(X) ∙ v(X)$ with $q_u(X), q_v(X) \in F[X]$
			% \end{betterlist}
		\end{betterlist}
	\end{betterlist}
	\fbox{Invertible Elements}
	\begin{betterlist}
		\item \underline{Theorem (MA):} Let $n \in \mathbb{N}, n > 1$. $n$ is a prime number \textit{iff} $(\mathbb{Z}/n\mathbb{Z}, +, \cdot)$ is a field
		\begin{betterlist}
			% \item $n$ prime number $\hat =$ irreducable polynomial $g(X)$
			\item \alert{Prime Number}: A number $n \in \mathbb{N} \setminus \{0, 1\}$ is a prime number \textit{iff} the following holds: If $n = u \cdot v$ for $u, v \in N$ then $u = 1$ or $v = 1$
			% \item Proof, inverse of $\overline{1}$ is $\overline{1}$, for all elements besides $\overline{0}$ there's an inverse element, if $n$ would not be a prime number, then there would be a non-trivial decomposition into two numbers where both numbers are from this set: $\{2, \ldots, n-1\}$ and therefore we can conclude that $n$ must be a prime number
			\begin{betterlist}
				\item Theorem (MA') implies Theorem(MA)
			\end{betterlist}
		\end{betterlist}
		\item \underline{Theorem (MA’):} Let $n \in \mathbb{N}, n > 1$. The inverse of $\overline{a} \in (\mathbb{Z}_n, +, \cdot)$ exists \textit{iff} $gcd(a, n) = 1$
		\begin{betterlist}
			\item $a$ and $n$ are \alert{relatively prime} \alert{iff} $gcd(a, n) = 1$
			% \item this does not only say something about um n equal to a prime number but it also says something about other rings where n is not a prime number and for those rings this theorem exactly characterizes the invertible elements, this are the elements a bar where the greatest common divisor of a and n here is equal to one which means a and n are relatively prime
			% \begin{betterlist}
			% 	\item \underline{reason for $1$:} It is the neutral element of multiplication: $m \cdot m^{-1} = 1$
			% \end{betterlist}
			\item if $p$ is even then the greatest common devisor of $2^k$ and $p$ is at least $2$ which is not $1$ of course and therefore if $p$ is even then it's not invertible. If $p$ is odd then the prime factor decomposition doesn't contain $2$ which means the greatest common divisor of an odd $p$ and $2$ to the power of $k$ is $1$ and then we immediately have that this element is invertible % which means in this special case with this theorem we can completely characterize the even elements are not invertible, the odd elements are invertible
			\begin{betterlist}
				\item $2^k$ only has $2$ and $1$ as devisors, $2\cdot k$ has a lot of devisors including $1$ and $2$, thus the gcd is $1\cdot 2 = 2$, thus $2^k$ is not invertible
				\item $2^k$ only has $2$ and $1$ as devisors, $2\cdot k+1$ has a lot of devisors excluding $2$, thus the gcd is $1$, thus $2^k+1$ is invertible
			\end{betterlist}
			\item \underline{Lemma (MA):} For each $u, v \in \mathbb{Z} \setminus \{0\}$ there is a gcd $g \in \mathbb{N} \setminus \{0\} \subseteq \mathbb{Z} \setminus \{0\}$ and there is a representation $g = q_u \cdot u + q_v \cdot v$ with $q_u, q_v \in \mathbb{Z}$.
		\end{betterlist}
		\item \alert{Eulers Theorem:} Let $a\in \mathbb{Z}$, $n\in \mathbb{N}\setminus \{0\}$ with $gcd(a, n) = 1$. Then $a^{\Phi(n)}\equiv 1 \mod n$
		\begin{betterlist}
			\item If $gcd(a, n) = 1$, then $\overline{a^{\Phi(n)-1}}$ is the \alert{mulitplicative inverse} of $\overline{a}$ in $\mathbb{Z}/n\mathbb{Z}$
		\end{betterlist}
	\end{betterlist}
	\fbox{Polynomial Division}
	\begin{betterlist}
		\item in normal division one would substract, but since we are doing computations based on $GF(2)$, addition and substraction are the same, doing XOR and therefore each element is it's own inverse. Final result as soon as remainder is smaller than divisor. If one divides by a polynomial of degree $k$, one obtains a remainder with degree smaller than $k$
		% \item \underline{Lemma: Division with remainder:} For $u(X)$, $g(X) \in F[X]$ with $g(X)\ne 0$ there exist unique polynomials $q(X), r(X) \in F[X]$ with $u(X) = q(X) g(X) + r(X)$ and $deg(r(X)) < deg(g(X))$ or $r(X) = 0$
		% \begin{betterlist}
		% 	\item $u(X) \mod g(X) = r(X)$, $u(X) \operatorname{div} g(X) = q(X)$
		% 	\item $r(X)$ is a unique remainder
		% \end{betterlist}
	\end{betterlist}
	\fbox{Finite / Galois Fields}
	\begin{betterlist}
		\item $GF(2) = (\mathbb{Z}/2\mathbb{Z}, +, \cdot)$ (same as $(\{0, 1\}, \oplus, \land)$) forms a field with additive identity $0$, multiplicative identity $1$ and $1$ as the multplicative inverse of $1$
		\item Making $(\{0, 1\}^k, +, \cdot)$ a finite field
		\begin{betterlist}
			\item define addition on $(\{0,1\}^k, +, \cdot)$ as bitwise Xor
			\begin{betterlist}
				\item Xor on $\{0,1\}$ is the same as $+$ on $GF(2) = \mathbb{Z}/2\mathbb{Z} = \{\overline{0}, \overline{1}\}$
			\end{betterlist}
			\item definition of $\cdot$ on $\{0,1\}^k$ such that the result becomes a finite field
			\begin{betterlist}
				\item the And operation is $\cdot$ on $GF(2)$
				\item to be done by reduction to the consideration of so-called polynomial rings over $GF(2)$
			\end{betterlist}
			\item \underline{Why not $\mathbb{Z}/2^k\mathbb{Z}$?:} an element $e$ that is even is not invertable in $\mathbb{Z}/2^k\mathbb{Z}$ and therefore can't be a field, all elements in $\overline{1} = \{1 + q\cdot 2^k \mid q\in \mathbb{Z}\}$ are odd as $q\cdot 2^k$ is always even, $a\cdot e$ is even, because $e$ is even, so it can't be in a set where all elements are odd
		\end{betterlist}
	\end{betterlist}
	\fbox{Attacks by Microarchitectural Data Sampling}
	\begin{betterlist}
		\item \alert{Instruction Set Architecture (ISA) of a processor:} interface it provides to the software it executes. Specifies set of instructions and registers and memory processed by the instructions
		\item \alert{Architectural states:} states defined by the ISA, i.e., memory cells and user-visible registers
		\item \alert{Microarchitectural states:} processor states not defined in the ISA, e.g. states of functional units, states of reservation stations, cache contents etc.
		\item It is ensured that effects of invalid out-of-order executions or discarded speculative executions do not change architectural states. However they may change microarchitectural states. Reading out microarchitectural states as side-channel information may leak information. Vulnerability on the hardware level, not on software level
	\end{betterlist}
	\fbox{Spectre:}
	\begin{betterlist}
		\item Leak information directly from user applications
		\item \underline{Preconditions for attacker:}
		\begin{enumerate}
			\item based on unexpected code executions due to speculative execution
			\begin{betterlist}
				\item Tries to predict whether branch is taken or not based on previous executions of branch instruction. Speculatively execute instructions at predicted position, avoid changes of architectural states during \alert{speculative execution}. If branch condition is finally evaluated and branch was mispredicted: Flush the effects of speculative executions (like pipeline flushing, invalidation of register writes in retiring phases etc.)%. Acceleration if branch correctly predicted, but at least correct architectural state if mispredicted
			\end{betterlist}
			\item can influence executed code of the victim
			\begin{betterlist}
				\item JavaScipt code is instrumented by web browser for memory protection (\enquote{sandboxing})
			\end{betterlist}
		\end{enumerate}
		\item \underline{Steps:}
		\begin{betterlist}
			\item \underline{instrumented code:} \verb|if (x < array1_size) y = probe_array[array1[x] << 12];|
			\begin{betterlist}
				\item \verb|array1| is an array of unsigned bytes of size \verb|array1_size|
				\item \verb|probe_array| is an array of unsigned bytes of size $1$ MB = $220$ Bytes
				% \item \verb|array1[x] << 12| cannot be larger than $2^{20}$ , so checking for access to \verb|probe_array| is not necessary
				\item choose \verb|x > array1_size| such that \verb|sd = array1[x]| is a secret data byte in the address space of the victim
				\item execute instrumented code several times with \verb|x < array1_size| until branch prediction predicts if-condition to be true
				% \item then \verb|x > array1_size| is executed such that \verb|sd = array1[x]| is secret data byte in the address space of the victim. \verb|y = probe_array[array1[x] << 12]| is executed by speculative execution
				\item speculative execution is aborted as soon as \verb|x < array1_size| evaluates to \verb|false|.
			\end{betterlist}
			\item Readout of cache information as in Meltdown
			\begin{betterlist}
				\item \verb|probe_array| is uncached (to enable readout of microarchitectural state). Caching by iterating the attack
				\item Uncaching by cache flushing or cache eviction. Evict certain cache line just by (at most) $A$ memory accesses with the same set number. Cache eviction instead of flushing needed in JavaScript code, since JavaScript lacks instructions for cache flushing
			\end{betterlist}
		\end{betterlist}
		\item \underline{Preconditions to win the \enquote{race}:}
		\begin{enumerate}
			\item \verb|array1_size| is uncached (to slow down if-condition checking)
			\item \verb|sd = array1[x]| is cached (to accelerate \verb|probe_array[array1[x] << 12]|)
		\end{enumerate}
		\item \underline{Possible countermeasures:}
		\begin{betterlist}
			\item Stricter sandboxing
			\begin{betterlist}
				\item Many modern browsers execute each website in a separate process
				\item No access to browser‘s address space possible
				% \item Spectre attack was demonstrated with Google Chrome version 62.0.3202
				% \item Modern Google Chrome browsers are not vulnerable anymore
			\end{betterlist}
			\item No speculative execution?
			\begin{betterlist}
				\item Huge performance degradation
			\end{betterlist}
		\end{betterlist}
	\end{betterlist}
\end{minipage}
\begin{minipage}[t]{0.2\linewidth}
	\fbox{Meltdown:}
	\begin{betterlist}
		\item uses Effects of \alert{out-of-order execution} to transport secret data into \alert{microarchitectural state} ($=$ buffers in reservation stations) and  uses \alert{data caching} to extract secret from microarchitectural state to \alert{architectural state}
		\begin{betterlist}
			\item breaks the isolation between user applications and the operating system. Allows a program to access the memory (of other programs and the operating system), even when it is not authorized to do so
		\end{betterlist}
		\item \underline{Preconditions for attacker}
		\begin{enumerate}
			% \item[\bfseries\color{PrimaryColor}$\bullet$] run on same machine and ability to start processes on this machine
			\item[\bfseries\color{PrimaryColor}$\bullet$] able to execute code on the attacked machine
			\item out-of-order execution with forwarding
			\begin{betterlist}
				\item \alert{out-of-order execution:} several instructions issued to several functional units in parallel, may be finished in an order different from the order in the program
				\item \alert{forwarding:} in Retiring phase after execution of the instruction $i$ by a FU $n$ a result token is generated which is sent (forwarded) to all reservation stations waiting for the result of FU $n$. Instruction can executed before register has been written in case of RAW (= read after write), if calculation result that should be written to this is forwarded to FU dealing with this instruction
			\end{betterlist}
			\item virtual memory managment with / based on paging and kernel space mapped into virtual address space of each process
			\begin{betterlist}
				% \item each process virtually uses it's complete address space (of e.g. $2^{64}$ addresses). Both \alert{virtual memory} and \alert{physical memory} are partitioned into \alert{pages} of the same size (e.g. $4 KB = 2^{12} Byte$). Most significant bits (e.g. $64 – 12 = 52$ bits) of virtual address = \alert{page number}. Most significant bits (e.g. $64 – 12 = 52$ bits) of physical address = \alert{page frame number}. Access to virtual page number $v$: Hardware Memory Management Unit (\alert{MMU}) checks in page table whether process has physical memory for page $v$. \underline{If yes:} MMU provides physical page frame number $p$ and makes access to $p$. \underline{If no:} \alert{Page fault}, operating system makes new physical memory page with page frame number $p$ available, enters $p$ for virtual page number $v$ into page table. Each process has its own \alert{page table}
				\item \underline{advantage of including kernel space into process page tables:} TLB does not need to be flushed for privileged accesses to kernel space, e.g. system calls
			\end{betterlist}
			\item use of caches not only for Translation Lookaside Buffer (TLB) but also for data and instruction and data caches for memory accesses, in particular data caching
			\begin{betterlist}
				\item modern CPUs use instruction and data caches for memory accesses to avoid slow memory accesses as far as possible
				\item fast cache memory storing page table entries recently accessed. Lookup in TLB first. Access page table only in case of TLB miss
			\end{betterlist}

			\includegraphics[width=0.8\linewidth]{./figures/associative_cache.png}
		\end{enumerate}
		\item \underline{Steps:}
		\begin{enumerate}
			\item unauthorized READ of one byte from \verb|secret_kernel_address| is managed by Reservation Station $R_s$. The following READ in \verb|probe_array| is issued to Reservation Station $R_p$, before the READ from \verb|secret_kernel_address| has been finished. As soon as the secret data byte \verb|sd := M[secret_kernel_address]| arrives in $R_s$, it is forwarded to $R_p$ which reads \verb|probe_array[sd << 12]|. During the read of \verb|probe_array[sd << 12]| data are cached. The hardware memory protection raises an exception which is registered in the retiring phase of $R_s$ , writing into \verb|IN1| is prevented, exception is handled. However the secret data \verb|sd| left traces in the cache
			\item read out of the changed microarchitectural state: Read from \verb|probe_array[0 << 12]|, \ldots \verb|probe_array[255 << 12]|. Measure the access time in all $256$ cases. If access to address $i \ll 12$ is fast, all other accesses slow, then the leaked secret is $i$
			\begin{betterlist}
				\item left shift by $12$, since a processor does not read single bytes into the cache, but cache lines (surroundings of address)
				\item $256$ different access to \verb|probe_array| because the read byte can have $256$ different values and one just uses the \verb|probe_array| to find out which value has been read, because the address that can quickly be read corresponds to the forwarded value
				\item ensure that the contents of \verb|probe_array| are not cached before the attack. E.g. achieved by flushing the cache lines using x86 instruction \verb|clflush|
			\end{betterlist}
		\end{enumerate}
		\includegraphics[width=0.8\linewidth]{./figures/meltdown_visualisation.png}
		\item \underline{Ways out of abortion by exception handling:}
		\begin{enumerate}
			\item \underline{Fork-and-crash:} Fork attacking application before accessing invalid memory location. Access invalid memory location only in child process. Recover the secret by probing in the parent process
			\item \underline{Exception handling:} Install an own signal handler for segmentation violation that does not crash the process
			\item \underline{Exception suppressing via TSX:} Use Intel‘s Transactional Synchronization Extensions (TSX). Transaction = Sequence of instructions that execute atomically. All instructions of a transaction are inverted, if one of them fails. But no exception raised!. Just wrap the attacking code into a TSX transaction ...
		\end{enumerate}
		\item \uline{only works, if race between exception handling and cache loading (reading \texttt{probe\_array[sd]}) is won by cache loading:}
		\begin{enumerate}
			\item try to read from \verb|secret_kernel_address| already before actual attack (e.g. by other processes). \underline{Goal:} Bring \verb|sd = M[secret_kernel_address]| into cache, so \verb|sd| is available earlier
			\item assuming that \verb|probe_array| starts at the beginning of a memory page and the page size is $2^{12}$, we first access $probe\_array[0 \ll 12 + 2^{11}], \ldots, probe\_array[255 \ll 12 + 2^{11}]$ (access all $256$ \verb|probe_array| pages with addresses in the middle of the pages). \underline{Goal:} Page addresses go into TLB, accelerated access to \verb|probe_array|...
			\item \sout{bringing physical address for \texttt{secret\_kernel\_address} into TLB won't help because it would accelerate both exception handling and cache loading}
		\end{enumerate}
		\item \underline{Possible countermeasures:}
		\begin{betterlist}
			\item Do not map kernel memory into address space of user processes. \underline{Disadvantages:}
			\begin{betterlist}
				\item For every system call the TLB has to be flushed. Performance problem
			\end{betterlist}
			\item fix vulnerability in hardware
			\begin{betterlist}
				\item check access rights before loading
				\item or implement hardware in a way that race is always won by access right checking + aborting the following instructions
				\item in case of right violation: Flush the cache completely or possibly flush the "last accessed" cache lines (needs some hardware modification)
			\end{betterlist}
		\end{betterlist}
	\end{betterlist}
	\fbox{Side Channel Attacks}
	\begin{betterlist}
		\item \uline{Observable (physical, not logical) side channel \alert{outputs} for side channel attacks:}
		\begin{betterlist}
			\item \alert{Power consumption}, \underline{Two types:} \alert{static power (data independent):} typically leakage, \alert{dynamic power (data / activity dependent):} stems from circuit activity and each signal change consumes dynamic power, \underline{Dynamic CMOS Power Consumption:} \alert{Switching current} from VDD to load output capacitance when \alert{output} switches from $0$ to $1$, \alert{Through current} from VDD to GND when both p-channel transistor and n-channel transistor turned on briefly during switch $0 \rightarrow 1$ or $1 \rightarrow 0$
			\item \alert{Electro-magnetic emissions}, \alert{Sound (accoustic)}, \alert{Light emissions (optical)}, \alert{Timing behavior, delay (timing and delay)}
		\end{betterlist}
	\end{betterlist}
	\fbox{Timing Attacks}
	\begin{betterlist}
		\item \underline{Timing attack against RSA:} Simple timing attack over number of $1$'s in Square and Multiply. If number of $1$'s is \alert{very small} or \alert{very high}, then such a simple timing attack enables \alert{brute-force attack}, Similiar attack possible as for accoustic chosen ciphertext attack
		\item similar to SPA countermeasures
	\end{betterlist}
	\fbox{Attack over electromagnetic side channels}
	\begin{betterlist}
		\item electrical transitions induce EM field captured by inductive probe. Obtain current signal on the die by integrating the recorded signal. Changes / derivation of current $\hat=$ EM field $\rightarrow$ similar to power analysis
		% \item can be used for \enquote{reverse engineering} of chip properties. Areas with high activity = CPU, functional units. Local information (resolution depends on probe). 
		\item \underline{Advantage:} Allows localized readings. \underline{Disadvantages:} Experimentally complicated. Geometrical scanning can be tedious. Low level and noisy signals (decapsulation required)
		\item \underline{Attacks:} approaches similar to power analysis possible (differential, correlation)
		\item \underline{Countermeasures:} E.g. shielding against electro-magnetic radiation, Faraday cages, ...
	\end{betterlist}
	\fbox{Attack over acoustic side channels}
	\begin{betterlist}
		\item \alert{Acoustic attack against RSA}
		\begin{betterlist}
			\item attack on modular exponentiation step $y^{d \mod (q−1)} \mod q$ to compute $q$ (attacking $p$ would be possible as well)
			\item if $q$ is known, then $p = n/q$ is known and $\Phi(n)= (p − 1) \cdot (q − 1)$ is known and $d$ can be computed from $e$
			\item assume that before round $i$ the $i$ most significant bits of $q$, i.e., $(q_{2047} \ldots q_{2048−i})$ are already known
			\item choose ciphertext $y_i = (q_{2047} \ldots q_{2048−i} 011 \ldots 1)$
			\item \alert{Case 1:} $q_{2048−i−1} = 1$, then $q > y^i$, then $(y^i)_q=y^i$ goes into square and multiply algorithm with exponent $d \mod (q − 1)$
			\item \alert{Case 2:} $q_{2048−i−1} = 0$, then $q \le y^i$, then $(y^i)_q=(y^i - q)$ goes into square and multiply algorithm with exponent $d \mod (q − 1)$
			\item square and multiply algorithm always multiplies with $(y^i)_q$. Different acoustic behaviour depending on $(y^i)_q$, because in the two different cases $(y^i)_q$ have vastly different values
			\item after estimating $q_{2048−i−1}$ from acoustic analysis go to round $i + 1$ with known $i + 1$ most significant bits $(q_{2047} \ldots q_{2048−i−1})$

		\end{betterlist}
		\item \underline{Countermeasures:} Acoustic shielding, Carefully designed acoustic noise generator to hide acoustic signal?, Parallel software load for hiding? (multi-core processors, FPGA-implementations), \enquote{Cipher text randomization} to compromise chosen cipher text approach: Instead of decrypting cipher text $y$. Choose random text $r$ (not completely random, but invertible). Decrypt $r^e \cdot y$, i.e., $r^e \cdot y$ is used for exponentiation instead of $y$. Multiply the result by $r^{−1}$. $(r^e \cdot y)^d \cdot r^{−1} \mod n \equiv r^{ed} \cdot r^{−1} \cdot y^d \mod n \equiv r \cdot r^{−1} \cdot y^d \mod n \equiv y^d \mod n$
	\end{betterlist}
	\fbox{Chinese Remainder Theorem (CRT)}
	\begin{betterlist}
		\item accelerated exponentiation. The number of operations is not reduced, but the bit width of the operands
		\item possible computation of $x = y^d \mod n$ with $n = p \cdot q$, $p$, $q$ primes
		\begin{betterlist}
			\item \underline{Transformation into CRT domain:} $y_p \equiv y \mod p, y_q \equiv y \mod q$
			\item \underline{Exponentiation in CRT domain:}\\
			$x_p \equiv y_p^{d \mod (p-1)} \mod p, x_q \equiv y_q^{d \mod (q-1)} \mod q$
			\item \underline{Backtransformation using CRT}: $x \equiv [q \cdot c_p] \cdot x_p + [p \cdot c_q] \cdot x_q \mod n$
			\begin{betterlist}
				\item where $c_p$ is the inverse of $q$ in $\mathbb{Z}/p\mathbb{Z}$, $c_q$ is the inverse of $p$ in $\mathbb{Z}/q\mathbb{Z}$.
			\end{betterlist}
		\end{betterlist}
	\end{betterlist}
\end{minipage}

\newpage

\begin{minipage}[t]{0.2\linewidth}
\end{minipage}
\begin{minipage}[t]{0.2\linewidth}
	\fbox{Power Attacks}
	\begin{betterlist}
		\item in \alert{smart cards}, one operation running at a time $\rightarrow$ simple power tracing is possible. In \alert{high-end processors} or \alert{FPGAs} typically parallel computations prevent visual SPA inspection $\rightarrow$ DPA
		\item \alert{Simple Power Analysis (SPA):}
		\begin{betterlist}
			\item targets variable instruction flow. Can reveal also data in special cases
			\item internal structure of \alert{DES} by looking at power trace (find out implemented algorithm by number of rounds etc.)
			\begin{betterlist}
				\item \sout{no direct key extraction possible for \alert{DES}}
			\end{betterlist}
			\item with higher resolution analysis on the level of single instructions (like conditional jump taken or not)
			\item \underline{data comparison:} involves string and memory comparison operations performing a conditional branch when a mismatch is found
			\item \underline{leak RSA key via square and multiply algorithm:}
			\begin{betterlist}
				\item Data dependent jump. Square always executed. Multiply depends on data. In the case of RSA, data $=$ private key
				\item \underline{Countermeasures:} in genereal execute dummy instructions to avoid leakage by power profile. Additional cost for increasing security
			\end{betterlist}
			\item \underline{Countermeasures:} \alert{1)} avoid procedures that use secret information for conditional branching operations via \enquote{creative coding} and \enquote{performance penalty} \alert{2)} add code to hide power differences \alert{3)} countermeasures from DPA and CPA
		\end{betterlist}
		\item \alert{Differential Power Analysis (DPA):}
		\begin{betterlist}
			\item targets data-dependence. Different operands present different power. Analyzes multiple execution flows. DPA typically able to make tiny differences in power consumption visible
			\item \underline{(statistical) aspect of DPA:} \alert{Averaging} over many traces to cancel out noise and \alert{form groups of measurements} and compute differences of averages
			\item \underline{Basic Principle:}
			\begin{betterlist}
				\item consider one target gate in the circuit (for hardware implementation) or one target operation (for software implementation)
				\item apply sequence of input patterns $P_0, P_1, \ldots, P_n$. Measure power consumed for each input pattern
				\item \underline{Create two sets:}
				\begin{betterlist}
					\item $S^+$ = set of patterns where output of target gate is $1$
					\begin{betterlist}
						\item if previous value of target gate was $0$, then target gate contributes to increased power consumption
						\item if previous value of target gate was $1$, then target gate does not contribute to increased power consumption
					\end{betterlist}
					\item $S^−$ = set of transitions where output of target gate is $0$
					\begin{betterlist}
						\item target gate does not contribute to increased power consumption (independently from previous value)
					\end{betterlist}
				\end{betterlist}
				% \item contribution of a single gate to overall power consumption is small, but nevertheless visible in the average power consumption of the two sets $S^+$ and $S^−$
				\item differences of single power consumptions for other gates cancel out between $S^+$ and $S^−$ by averaging. $AveragePower(S^+) - AveragePower(S^−) > 0$
			\end{betterlist}
			\includegraphics[width=0.8\linewidth]{./figures/dpa_average.png}

			\item order of applying patterns not unimportant, as there has to be a switch from $0$ to $1$ in order to have a increased power consumption, so one has the best result if one applies always one pattern from $S^+$, then one from $S^-$. If order is random it should also be ok, since on average \enquote{half of the transitions in $S^+$} go from $0$ to $1$ and other half from $1$ to $1$, in $S^-$ there's never a $0\rightarrow 1$ transition
			\item \underline{\alert{one / single bit distinguisher} for partitioning into $S^+(k_s)$ and $S^−(k_s)$:} A location in the algorithm where knowledge on a small subset of key bits enables the computation of a bit value. Gate output, output bit of an operation which one can compute, if plain and / or cipher text + a (small) subset of the key is known. Hope something is correlated with key bit assumption, if correlation holds partitioning is ok, then can derive some information

			% \includegraphics[width=\linewidth]{./figures/distinguisher_not_always_working.png}
			\includegraphics[width=0.6\linewidth]{./figures/distinguisher_not_always_working_short.png}
			\begin{betterlist}
				\item effects cancel out, because transition happens at almost the same time at both places
			\end{betterlist}
			\item \alert{DPA attack on DES:}
			\begin{betterlist}
				\item with the correct assumption on $k_s$ the value of $(L_{15})_j (k_s, C_i)$ is correct with \enquote{probability $1$} $\Rightarrow$ $AveragePower(S^+(k_s)) - AveragePower(S^−(k_s)) > 0$
				\item if assumption on $k_s$ is wrong, the value of $(L_{15})_j (k_s, C_i)$ is correct with \enquote{probability $\approx 0.5$} $\Rightarrow$ $AveragePower(S^+(k_s)) - AveragePower(S^−(k_s)) \approx 0$
				\item since the point in time when exactly $(L_{15})_j$ is computed is unknown, DPA does not record \alert{single power values} for plain texts $P_i$, but \alert{power traces} over a certain amount of time
				% \item the power traces for different plain texts $P_i$ have to be precisely synchronized wrt. the start time of the recording
			\end{betterlist}
			\includegraphics[width=0.8\linewidth]{./figures/dpa_attack_on_des.png}

			\begin{betterlist}
				\item Compute average traces for $S^+(k_s)$ and $S^−(k_s)$. Subtract average traces. Zoom in for analyzing differential trace. Repeat for all keys $k_s$
				\item Method reveals $6$ bits of $k_{16}$. Repeat for different bit $j$ of $L_{15}$, revealing $6$ other bits. By this, $48$ out of $56$ bits of user key $k$ are known. \underline{Two options:} brute-force attack to compute remaining $8$ bits or continue with previous rounds
			\end{betterlist}
		\end{betterlist}
		\begin{betterlist}
			\item \alert{DPA attack on AES:}
			\begin{betterlist}
				\item use a bit (e.g. LSB) of the output of first S-box in round $1$ for partitioning. Depends on first key byte. Number of key hypotheses is $256$. Just repeat the attack for remaining $15$ S-Boxes and key bytes
				\item average traces for all $256$ possible key bytes with output bit $0$ and $1$ ($S^+(k_i)$ and $S^-(k_i)$) and then compute differential trace for all key bytes
			\end{betterlist}
			\item \underline{Countermeasures to DPA:} Difficult, but try to increase at least the number of samples needed for obtaining meaningful results by:
			\begin{betterlist}
				\item Signal size reduction
				\begin{betterlist}
					\item Use operations leaking less information in power consumption
					\item Reduce power consumption by different gate realizations (technology)
				\end{betterlist}
				\item Adding noise to power consumption measurements
				\begin{betterlist}
					\item Random noise cancels out by averaging (but more samples needed)
					\item Non-random contributions to hide key-dependent power consumption (\enquote{leak masking})
					\item Temporal noise (like varying clock speeds) for disturbing trace synchronization (shift measurements against each other, then can avoid sharp peak in differential power trace, e.g. random generator that influences clock speed)
				\end{betterlist}
				\item Balance power consumption (e.g. by dual-rail precharge logic, two transistors which always switch in opposite direction, 0 $\rightarrow$ 1 and 1 $\rightarrow$ 0 have same power consumption)
				\item Power supply filters (simplest just capacitors which just consume / cancel the peaks)
				\item Frequent key exchange to prevent attacks with large amount of samples
			\end{betterlist}
		\end{betterlist}
		\item \alert{Correlation Power Analysis (CPA):} Goes beyond the usage of binary distinguishers (as for DPA), Often less traces are needed than with DPA
		\begin{betterlist}
			\item \underline{basic idea:} compute a correlation between \alert{power consumption} and \alert{processed values} (over several bits)
			\begin{betterlist}
				\item consider \alert{Hamming weight (HW)} of the intermediate value $x$ (e.g. a byte) that directly \alert{correlates with power consumption}, \underline{Larger $HW(x)$:} larger power consumption, \underline{Smaller $HW(x)$:} smaller power consumption, \underline{example:} Hamming weight of output of first S-box in round $1$ of AES
				% \item $X$ = power consumptions (for $n$ different \alert{plain texts}). $Y$ = hamming weights of some intermediate value (like output of first S-box in round $1$ of AES based on a certain key byte assumption)%. Choose the key byte hypothesis where correlation for some point in time is maximized. Repeat the previous steps for every key part in order to recover the full key
				\item assume we have $n$ \alert{power traces (of plain texts)}, each with $p$ data points $d_j^k$ $(1 \le k \le n, 1 \le j \le p)$. There are $m$ subkey guesses, for each subkey guess $i$ and each power trace the \alert{hamming weight of the guessed intermdiate value} (like output of first S-box in round $1$ of AES based on a certain key byte assumption) is $h_i^k$ $(1 \le k \le n, 1 \le i \le m)$. We have to compute $p \cdot m$ correlation coefficients $ρ_{j,i}$ for each time $j$ and each subkey guess $i$:

				\includegraphics[width=0.4\linewidth]{./figures/pearson_correlation_coefficient.png}
				% \item \alert{Pearson‘s correlation coefficient:} $−1 \le \rho_{X,Y} \le 1$
				%
				% \includegraphics[width=0.1\linewidth]{./figures/pearson_symbol.png}
				% \includegraphics[width=0.4\linewidth]{./figures/pearson_correlation_coefficient.png}
				% \begin{betterlist}
				% 	\item $X$ = Power consumptions (for $n$ different plain texts)
				% 	\item $Y$ = Hamming weights of some intermediate value (like output of first S-box in round $1$ of AES based on a certain key byte assumption)
				% \end{betterlist}
				\item we select the key guess $i$ with the highest $\rho_{j,i}$. Repeat the previous steps for every key part in order to recover the full key
			\end{betterlist}
		\end{betterlist}
	\end{betterlist}
	\fbox{How to inject faults}
	\begin{betterlist}
		\item \underline{Usable (physical, not logical) side channel \alert{inputs} for fault injection:} Supply voltage. Clock frequency. Temperature. Light
		\item \alert{Non-Invasive Fault Injection Attacks}
		\begin{betterlist}
			\item Lowest cost (need oscilloscopes, waveform generators, ...). No damage to the target IC
			\item \alert{Clock Glitching:} Increase clock speed for short time (one or more cycles). Prevent flip-flops from latching correct data and \enquote{skips instructions}. Requires knowledge on when to attack what
			\item \alert{Voltage Glitching:} Burst of high or low voltage. Increase or decrease gate speeds. Extreme case: $VDD < VTH \Rightarrow$ Change behavior of transistors. Effects as for clock glitching + change control logic outputs / change memory outputs. Requires knowledge on when to attack what
		\end{betterlist}
		\item \alert{Semi-Invasive Fault Injection Attacks}
		\begin{betterlist}
			\item Intermediate cost (need better oscilloscopes, logic analyzers, test boards, ...). Minimal physical tampering required.
			\item Preceded by decapsulation of the IC ($\Rightarrow$ semi-invasive). Decapsulation with \alert{mechanical} or \alert{chemical} methods
			\item \alert{Local Heating:}  High power laser is used to selectively heat small areas. Hot enough to change $V_{th}$ but not hot enough to damage. Trial and error with location is used to determine useful glitches
			\item \alert{Flash Glitching:} Magnified camera flash can cause mass glitching. Tinfoil masks created to cause selective glitching. Trial and error with location and timing is used to determine useful glitches
			\item \alert{Laser Glitching:} Infrared laser is used to selectively glitch small areas. Trial and error with location and timing is used to determine useful glitches. Process is more precise than Flash Glitching
			\item \alert{Backside Imaging:} Substrate exposed to infrared light / X-ray. Transistor layout is visible through substrate. Reverse engineering of block-level functionality: determine size of data bus, determine location of control logic, determine location of security logic. With infrared light. Picture taken with standard low-cost monochrome CCD camera
			\item \alert{Laser Scanning:} See memory structures and read stored values
		\end{betterlist}
		\item \alert{Invasive Fault Injection Attacks:} High cost. E.g. Removing layers of an IC, scanning by electron microscopes, small microprobes. Destructive. Modifies attacked IC itself
		\begin{betterlist}
			\item \underline{Attacks:} \alert{Signal injection:} Use probes to enforce certain logical values / flip logical values. Purpose: Modify control signals / data values on the chip. Modify memory contents. Forcefully bypass security protection, \alert{Disconnect nets in the circuit by laser cutting}, \alert{Modify nets by wire bonding}, \alert{Destroy transistors / wires by high voltage between two probes}
		\end{betterlist}
	\end{betterlist}
\end{minipage}
\begin{minipage}[t]{0.2\linewidth}
	\begin{betterlist}
		\item \underline{Other attacks:} \alert{Get physical access to all structures of the IC:} Decapsulation. Use of acids to remove layers one by one. Image each layer before removing it, \alert{Reverse Engineering:} Provide knowledge about design of IC. Layout reconstruction from images. Build netlist. Find out all functions of IC, \alert{Memory Extraction:} Read contents of ROM from layout reconstruction. Scan contents of EEPROM/FLASH, \alert{Micro Probing:} Microprobes can also provide side channel outputs. Listen to control lines. Listen to data bus
		\item \underline{IC Modifications:}, \alert{Decapsulation}, \alert{Laser Cutting:} Not completely destructive. Selective exposure of lower layers. Selectively disconnect nets, \alert{Test Point Creation:} Cut test points into IC. More spots for micro probing / signal injection below top layer. Access more signals, \alert{Wire Bonding:} Use laser cutting to expose net / cut test point for bonding target. Add wire for signal insertion or for modifying circuit paths as needed
	\end{betterlist}
	\fbox{Fault injection countermeasures}
	% \item it is currently believed that an attacker with infinite resources can break an arbitrary device by side-channel analysis and fault injection. Moreover, security must be balanced against performance, power consumption and cost, so countermeasures are subject to limitations
	\begin{betterlist}
		\item \alert{Non-Invasive Fault Injection countermeasures:} add voltage and frequency sensors to detect voltage / frequency glitching attacks
		\item \alert{Semi-Invasive Fault Injection countermeasures:} ambient light sensors and switches against decapsulation of the device
		\item \alert{Invasive Fault Injection counntermeasures}
		\begin{betterlist}
			\item \alert{Probing Attempt Detector:} to detect probing. \underline{Idea:} Frequency depends on delay. Based on a ring oscillator. A ring oscillator (RO) with an attacked victim line temporarily oscillates with a reduced frequency. Use two ring oscillators with (almost) identical frequencies. Detect non-negligable frequency differences between reference RO and RO with victim line
			% A probe on the victim line increases its capacity and thus the delay of the ring

			\includegraphics[width=0.8\linewidth]{./figures/probing_attempt_detector.png}
			\item \alert{Top-layer Sensor Meshes:} to avoid access to chip internals. Additional metallization layers form a sensor mesh above the actual circuit and do not carry any critical signals. All the paths in a sensor mesh are continuously monitored for interruptions and short-circuits while power is available. Prevents laser cutter or selective etching access to the bus lines. Mesh layer hides the lower layer which makes navigation on the chip surface for probing and FIB (Focused Ion Beam) editing more tedious
		\end{betterlist}
		\item \alert{All types of Fault Injection} use \enquote{standard} error detection / error correction methods
		\begin{betterlist}
			% \item Re-use of \enquote{classical} \alert{error detection / correction} techniques to \alert{detect} fault injection attacks
			\item \alert{Soft Error:} temporarily changing a logic value in the circuit due to a random natural event
			% \begin{betterlist}
			%   \item while \alert{Fault Injection} temporarily changes a logic value in the circuit due to an attack
			% \end{betterlist}
			\item \alert{error detection:}
			\begin{betterlist}
				\item \alert{self-checking design:} Functional unit designed in a way that faults manifest themselves as invalid (error-space) outputs. Invalid outputs are detectable / correctable by an external code checker

				\includegraphics[width=0.8\linewidth]{./figures/self_checking_design.png}
				\item \alert{error-detecting codes:}  A simple error-detecting code (detects all single-bit errors): Attach an even parity bit to each $k$-bit data word. Check bit = XOR of all data bits. \alert{Data space:} All $2^k$ possible $k$-bit words. \alert{Code space:} All $2^k$ possible even-parity $(k + 1)$-bit codewords. \alert{Error space:} All $2^k$ possible odd-parity $(k + 1)$-bit noncodewords

				\begin{betterlist}
					\item many redundancy techniques can be considered as coding schemes. \alert{Duplex:} Using code $\{00, 11\}$. Bit $0$ encoded as $00$, $1$ as $11$. Detects any error in one version. \alert{Triplex:} Using code $\{000, 111\}$. Corrects all single errors. If we triplicate the voter to obtain 3 results, we perform $f(x)$ on coded inputs, getting coded outputs

					% \includegraphics[width=0.6\linewidth]{./figures/error_detecting_codes.png}
					% \includegraphics[width=0.4\linewidth]{./figures/redundancy_as_coding_scheme.png}
					\item \alert{checkpointing \& recovery:} Store system state at checkpoint, revert if fault / attack is detected

					% \includegraphics[width=0.6\linewidth]{./figures/checkpointing_recovery.png}
					\item \alert{self-destruction:} When attack is detected: Destroy circuit
				\end{betterlist}

				% \includegraphics[width=0.3\linewidth]{./figures/parity_bit.png} 
			\end{betterlist}
			\item \alert{error correction:}
			\begin{betterlist}
				\item \alert{triple modular redundancy:} the voting element accepts the outputs from the three sources and delivers the \alert{majority vote as its output}. \underline{This is a $2$-of-$3$ system:} as long as a majority of the modules produce correct results, the system will be functional
				% \includegraphics[width=0.6\linewidth]{./figures/triple_modular_redundancy.png}
			\end{betterlist}
		\end{betterlist}
	\end{betterlist}
	\fbox{Using fault injections to extract secret information}
	\begin{betterlist}
		\item \alert{Differential Fault Injection Attacks}
		\begin{betterlist}
			\item \underline{Fundamental Idea:} Malicious modification of internal data during cipher execution leads to a change in data and final observable result. This often requires precise information on timing, algorithm, data used, etc... Comparison between faulty and fault free execution reveals secret information (e.g. derive secret key by differential cryptanalysis). Also applicable to some non-crypto systems, e.g., jump over password check routine by changing its result bit
			\item \alert{fault model:} E.g. Single/multiple bit-flips at positions chosen by attacker or Localized fault in, e.g., a byte of the cipher state: the attacker cannot influence which bits will be flipped, but can observe which bits have been flipped or same, but attacker doesn’t know which bits were flipped. Fault effect can last for one clock cycle, multiple clock cycles or forever (permanent fault)
			\begin{betterlist}
				\item \underline{in practise limited precision:} spatial (location) and temporal precision (timing). An attack with too strong assumptions not matched by the used equipment will yield invalid results
			\end{betterlist}
			\item \alert{Fault Injection + Known Plaintext Attack:}
			\begin{betterlist}
				\item \alert{Fault model:} Suppose the adversary can change any bit $k_i$ of secret key $k$ to $0$ but not to $1$
				\item \underline{Encrypt without any faults:} $y = e_K(x)$. Select a position $i$, change key bit $k_i$ to $0$, encrypt again: $y’ = e_{K’}(x)$. If $y = y'$, the key bit $k_i$ was $0$, otherwise it was $1$. To retrieve the complete key, repeat for all $i$
				\begin{betterlist}
					\item \underline{Alternative:} apply less fault injections; use brute-force search for the rest
				\end{betterlist}
			\end{betterlist}
			\item \alert{Fault Attack on RSA:}
			\begin{betterlist}
				\item only decryption $m = c^d \mod n$ is subject to attacks
				\item \alert{fault model:} attacker can flip a single bit in key $d$, but doesn’t know which bit was flipped
				\item assume attacker can observe $m$ and $c$. Generate m without and $m'$ with fault injection. We can derive the flipped bit by trying two tests for all possible positions $i$:
				\begin{enumerate}
					\item if there is an $i$ such that $m’ = m \cdot c^{2^i} \mod n$, then $d$ had $0$ at position $i$ and it was flipped to $1$: $d_i = 0$
					\item if there is an $i$ such that $m = m’ \cdot c^{2^i} \mod n$, then $d_i = 1$
				\end{enumerate}
			\end{betterlist}
		\end{betterlist}
	\end{betterlist}
	\fbox{Test Infrastructure}
	\begin{betterlist}
		\item \underline{trade-off between testing and security:} \underline{testing goal:} Make internal behaviour externally observable, \underline{security goal:} Keep internal behaviour secret
		\item \alert{test:} input for the circuit, that makes the fault effect visible at the outputs
		\item \alert{single stuck-at fault:} exactly one wire in the entire circuit is defective. the faulty wire permanently has the value $0$ or $1$. The defect can be situated at the input / output of a gate or at a primary input
		\item \underline{Testing requires internal signals of the circuit to be:}, \alert{controllable} (assign arbitrary values to the signal) and, \alert{observable} (observe signal changes at the circuit outputs)
		\item a fault is \alert{testable} iff it is controllable and observable at the same time
		\item \alert{Design for Testability:} methods to increase controllability and observability
		\item \alert{Scan chains:} Makes it possible to bring FlipFlops in sequential circuit into a given state for testing. Test structure (hardware) is added to the design: test control (TC) primary input, replace flip-flops with scan flip-flops (SFF) and connect them to one or more scan shift registers for the test mode and make input/output of every scan shift register controllable/observable from PI/PO

		\includegraphics[width=0.6\linewidth]{./figures/scan_chain.png}
		\includegraphics[width=0.4\linewidth]{./figures/test_point_insertion.png}
		\item \alert{Test Point Insertion:} $sa-0$ (stuck-at) fault is not controllable. Make $sa0$ controllable by adding gate + additional primary
		input
		\item \alert{Boundary Scan:} Boundary scan applied to modules of a SoC (System-on-a-Chip). Used to isolate different modules in a circuit. Can be used to test the modules and the interconnects between them
		\begin{betterlist}
			\item Testing interconnects (EXTEST): Scan in data into $R$ out of one or several modules. Latch the results into $R_{in}$ of the following modules. Scan out the data stored in $R_{in}$.
			\item Testing a module (INTEST): Scan in data into $R_{in}$ of a module. Latch the results into $R_{out}$ of the module. Scan out the data stored in $R_{out}$
		\end{betterlist}

		\includegraphics[width=\linewidth]{./figures/boundary_scan.png}
		\item \alert{JTAG:}
		\begin{betterlist}
			\item \underline{Control:} \underline{TDO:} Test Data Output, \underline{TDI:} Test Data Input, \underline{TMS:} Test Mode Select, \underline{TCK:} Test Clock, \underline{TRST:} Resets TAP Controller
			\item \underline{Three Basic Modes:} \alert{EXTEST mode (external test):} Testing interconnects, \alert{INTEST mode (internal test):} Testing modules, \alert{BYPASS mode:} Replace scan chain of the module by a single FF. \underline{Purpose:} Skip module testing and Shorten overall scan chain
			\item \underline{Access to Internal Module Registers:} Parts of shift register may be connected with \enquote{corresponding circuit register}, \underline{Update operation:} Copy from shift register into circuit register, \underline{Capture operation:} Copy from circuit register into shift register, \underline{Usual procedure:} \alert{Test mode:} shift data in and update, \alert{Functional mode:} Perform normal circuit operations, \alert{Test mode:} Capture and Shift data out
			\item \underline{Simplest version to connecting JTAG Devices:} \alert{Daisy chaining:} Serially connected via TDI, TDO. Control signals TMS, TCK, TRST are the same, Long chain, long delays, More complex structures possible
			\item \underline{Disadvantage of JTAG:} Structure is basically fixed, inflexible
		\end{betterlist}
	\end{betterlist}
\end{minipage}
\begin{minipage}[t]{0.2\linewidth}
	\begin{betterlist}
		\item
		\begin{minipage}[b]{0.3\linewidth}
			\includegraphics[width=\linewidth]{./figures/jtag_device.png}
			\includegraphics[width=\linewidth]{./figures/internal_module_registers.png}
		\end{minipage}
		\begin{minipage}[b]{0.7\linewidth}
			\includegraphics[width=\linewidth]{./figures/connecting_jtag_devices2.png}
		\end{minipage}
		% \item Reconfigurable Scan Networks (RSNs)
		% \begin{betterlist}
		% 	\item Difficulties to access input pins of chips on a board. E.g. because of Ball Grid Arrays. Make pins externally accessible
		% \end{betterlist}
	\end{betterlist}
	\fbox{Attacking Design-for-Testability}
	\begin{betterlist}
		\item all DFT structures (scan, JTAG...) are potential side-channels. If the secret key is stored in a scan chain, the attacker can simply shift it out (or shift a new key in). If the register which holds the cipher state after each round is part of the scan chain, the attacker can shift out the states
		\begin{betterlist}
			\item different devices may come from different vendors with different trust levels. E.g. in functional mode device $2$ stores the key in it's register, in test mode the key is shifted out via device $3$
		\end{betterlist}
		\item \alert{Countermeasures}
		\begin{enumerate}
			\item \alert{Removal/Destruction of JTAG:} does not leave a way to in-field test
			\begin{betterlist}
				\item use BIST (Build-in Self Test) for testing instead

				\includegraphics[width=0.4\linewidth]{./figures/bist.png}
				\begin{betterlist}
					\item \underline{Disadvantages:} if have to store test set + store test responses, then huge memory consumption. pseudo-random test sequences (Linear feedback shift registers) + compressed output signatures $\rightarrow$ low fault coverage. Fault diagnosis with BIST not possible
				\end{betterlist}
				\item Similarly to removal of JTAG one can use security fuses to disable JTAG before the hardware leaves the factory. There are different levels of disabled JTAG
				\item \underline{Problem:} No further use of JTAG for debugging anymore
			\end{betterlist}
			\item \alert{Removal of sensitive data during test:} Two new modes of operation: \alert{Insecure mode:} Switching between test mode and normal mode allowed and \alert{Secure mode:} No switching into test mode. Loading secret key only possible in secure mode. No switching back from secure to insecure mode possible: Only via power-off reset. Power-off reset clears all register contents, including the register holding the key. Key cannot be shifted out in test mode

			\includegraphics[width=\linewidth]{./figures/removal_of_sensitive_data.png}
			\item \alert{Authentication for JTAG:} Only priviledged users should be able to use JTAG testing devices. Access to JTAG regulated using cryptographic functions
			\begin{enumerate}
				\item May be implemented with public / private key authentication: Tester/Updater needs a certificate of authentication signed by a designated third party. Authenticator’s public key is known to JTAG system. Using the known public key, the JTAG system can decrypt the certificate and determine whether the tester/updater is trusted. Trusted testers/updaters are allowed access to JTAG system, untrusted are blocked

				\includegraphics[width=\linewidth]{./figures/authentication_for_jtag.png}
				\item \alert{Lightweight Scan Protection:} Authorized user and secure scan chain have a common fixed key. If scan chain is accessed with wrong key, observed data are distorted / randomized. Key bits distributed into scan sequence (here several scan chains): dummy FFs! Compared with correct key by Key Checking Logic (KCL). Result of comparison saved into FF when changing from scan-in to functional mode. Random Bit Generator (RGB) used to generate $q$ random bits. Used to randomize output bit stream iff $secure = 0$ (wrong key was used). Replace AND by negated EXOR to flip input bit in case of $0$-input!

				\includegraphics[width=0.6\linewidth]{./figures/lightweight_scan_protection0.png}

				\includegraphics[width=\linewidth]{./figures/lightweight_scan_protection.png}
			\end{enumerate}
		\end{enumerate}
	\end{betterlist}
	\fbox{Counterfeiting}
	\begin{betterlist}
		\item \alert{Counterfeiting:} Customer receives a \enquote{fake chip}
		\item \underline{different types of \enquote{faking} possible:}
		\begin{enumerate}
			\item \alert{original IC with same quality delivered:} Foundry can produce more parts (overproduction by external fab). Fake yield data and sell the extra chips to the market. Can produce extra chips without sending the information to the design house
			% \begin{betterlist}
			% \item from overproduction by external fab
			% \end{betterlist}
			\item \alert{original IC (from the expected manufacturer, with same functionality) delivered, but with lower quality than expected:}
			\begin{enumerate}[label=\color{PrimaryColor}\bfseries\alph*.]
				\item \alert{recycled (refurbished) ICs:} Earlier aging then expected: Chips wear-out and eventually break, have defects due to physical aging effects and have loss in performance until chip stops working
				\begin{betterlist}
					\item re-marked parts are either recycled components, new components to change the specification of the component (e. g. commercial grade $\rightarrow$ military grade)
				\end{betterlist}
				\item \alert{defective parts / out-of-spec parts by external fab or external tester:} Untrusted Foundry can sell defective parts and out-of-spec parts. \alert{Defective parts:} A chip may fail at one particular structural test pattern. (The number of test patterns may vary in between several thousands.). It is highly unlikely that defect will appear in normal operation of the chip in first few hours or days or months. Eventually, it will fail at some point of time. \alert{Out-of-spec parts:} Fail to perform at the design specification (leakage current, dynamic current, performance, etc.). The chip might fail at extreme physical/environmental conditions
			\end{enumerate}
			\item \alert{a functionally identical / similar IC delivered by another manufacturer (stolen IP, reverse engineered):} Unauthorized production of a part. \alert{Difference} between \alert{overproduction} and \alert{cloned} is that cloned parts do not have the authorized IP, could be fabricated in a different foundry. Cloned parts are either \alert{Pirated IP:} Counterfeiters acquire the IP in an illegal manner (saved the design cost of the IP) or \alert{Reversed Engineered:} Counterfeiters reverse engineer the design and make a new one just like the original design
			\item \alert{different IC with similar functionality delivered, but degraded performance:} Several reasons for \enquote{ICs with similar functionality, but degraded performance}: Completely new fake design, does not reach the quality level of the original design. Parts are cloned, but some components designed from scratch. Inferior system integration of cloned components. Original parts, but sorted out, see (2b)
			\item \alert{IC with malicious (added or modified) functionality delivered:} \alert{Hardware Trojan:}
			\begin{betterlist}
				\item malicious addition or modification to the existing functionality. \alert{What hardware Trojans can do:} Change the functionality, reduce the reliability and leak valuable information
				\item \underline{IC/IP Trust Problem:}
				\begin{betterlist}
					\item IP Vendor and System Integrator. IP vendor may place a Trojan in the IP. \alert{IP Trust problem}
					\item Designer and Foundry. Foundry may place a Trojan in the layout design. \alert{IC Trust problem}
				\end{betterlist}
				\item \alert{Back Door:} Adversary can add additional circuitry to leak information from the fabricated chip. Such a Trojan cannot be detected easily since it does not change the normal functionality of the circuit. \underline{Possible ways to leak information:} Adding an antenna for wireless information transmission, use existing interfaces of the chip to leak information when interfaces are not used by the application, more advanced information transport via side channels like power consumption, electromagnetic radiation or even path delay
				\item \alert{Time Bomb:}
				\begin{betterlist}
					\item Time bomb may be \alert{actively triggered:} Activated when counter gets a specified value, Finite State Machine (FSM) goes into a certain state, A certain condition on data (like a key) is satisfied
					\item \alert{Or passivley triggered:} modify wire / transistor widths violating design rules, causing reliability issues
					\item Damage may be caused by overheating due to e.g. frequent switching operations
				\end{betterlist}
			\end{betterlist}
		\end{enumerate}
	\end{betterlist}
\end{minipage}
\begin{minipage}[t]{0.2\linewidth}
	\begin{betterlist}
		\item \alert{Digital Trojans:}
		\begin{betterlist}
			\item \alert{Combinational Trojan:} or \alert{Sequential (Synchronous) or Sequential (Asynchronous):}

			\includegraphics[width=0.33\linewidth]{./figures/combinational_trojan.png}
			\includegraphics[width=0.33\linewidth]{./figures/sequential_synchronous.png}
			\includegraphics[width=0.33\linewidth]{./figures/sequential_asynchronous.png}
			\item \alert{Functional:} Addition or deletion of components
			\item \alert{Parametric:} \underline{Modifications of existing components:} Wire: e.g. thinning of wires, Logic: Weakening of a transistor, modification to physical geometry of a gate, Modification to power distribution network. Sabotage reliability, increase the likelihood of a functional or performance failure
		\end{betterlist}
	\end{betterlist}
	\fbox{Counterfeit / Trojan Detection and Avoidance}
	\begin{betterlist}
		\item \alert{Recycled / refurbished ICs, ICs with degraded performance:}
		\begin{betterlist}
			\item \alert{Visual inspection (Physical inspection / testing)}
			\begin{betterlist}
				\item \alert{External Visual Inspection (EVI):} \underline{Check of:} Date and Lot Codes, OEM Shipping labels, Lead quality, Dimensions \& Weight, Marking Quality. Optical examination at a suitable magnification and with suitable lighting with Microscopes, scanning electron microscopes (SEMs), ... Identify scratches from sanding, Ghost markings, Burnt markings from low quality laser. Results compared with reference sample images
				\item \alert{X-Ray Inspection:} Determines: If the package contains a die, consistent size/shape of the die, consistent internal construction, if the die has all wire bonds attached. Exact die and bond wire location to avoid damage during decapsulation%. Works best if known good reference
				dies are available
				\item \alert{X-Ray Fluorescence (XRF) Spectroscopy:} Tool for material composition detection. Non destructive. Destructive, if internal material composition needed. Sampling required
				\item \alert{Scanning Acoustic Microscopy:} Scanning Acoustic Microscopy is non-invasive, non-destructive. Reveals cracks, voids, delamination, metallization burnout, Uses de-ionized water or alcohol as medium
			\end{betterlist}
			\item \alert{Testing (Electrical testing)}, Main focus on Very-large-scale integration circuits and high cost parts like Microprocessor where counterfeiter will probably put much effort to counterfeit. \underline{Precondition:} Test sets (test programs for Automated Test Equipment (ATE)) must be available or be derived from HDL description of tested module that have to be available. Similar to manufacturing test after production of the chip
			\begin{betterlist}
				\item \alert{Electrical Tests:} \underline{Iddq testing:} measuring the supply current (Idd) in idle state (no switching). Many manufacturing faults lead to increased static power consumption
				\item \alert{Logic and Delay Tests:}
				\begin{betterlist}
					\item \alert{Check whether the chip / SoC produces expected responses within expected delay:} Test patterns for logic tests may be produced by structural ATPG or may be functional tests, Dedicated test patterns for delay testing possible
					\item \alert{Memory Tests (e.g. MARCH tests):} Read/write operations are performed on a memory to verify its functionality, Can also be applied for counterfeit detection.
					\item \alert{Microprocessor Tests:} Microprocessors are binned in different groups depending on the maximum functional frequency ($f_{max}$)
				\end{betterlist}
				\item \alert{Temperature Cycling / Burn-In}
				\begin{betterlist}
					\item \alert{Testing the chip at extremes of operating range:} Military Grade, Industrial Grade, Commercial Grade
					\item \alert{Burn-in:}
					\begin{betterlist}
						\item \underline{the device is operated at an elevated temperature (stress condition):} Normally used to find infant mortality failures, Also useful to assure reliability, Find out commercial grade components marked as military grade
						\item find out defective components or components that were not designed to perform under stress conditions
					\end{betterlist}
				\end{betterlist}
			\end{betterlist}
		\end{betterlist}
		\item \alert{Cloned, over-produced, out-of-spec, and defective ICs:}
		\begin{betterlist}
			\item \alert{Hardware metering} is a set of security protocols that enable the design house to achieve post-fabrication control over their ICs.  Provides a way to uniquely fingerprint or tag each chip and/or each chip’s functionality. It is even possible to distinguish between different chips manufactured with the same mask
			\item \alert{Passive Hardware Metering:} Give each IC a unique identifier. Foundry and IP owner have database with valid identifiers. Any chip without valid identifier is a counterfeit. Guessing valid ID's should not work. \underline{Disadvantage:} Overproduction / cloning can only be detected, not prevented. Overproduced chips can be detected, but are working. Low probability to observe two identical (copied) IDs in practice
			\begin{betterlist}
				\item \alert{Reproducible Identifiers:} Unique ID’s are stored on the chip package, on die, or in a memory on-chip, \underline{Examples:} Indented serial numbers, Digitally stored serial numbers, \underline{Advantages:} Do not depend on randomness, Easy to track / identify, \underline{Disadvantages:} Easy to clone/modify, Easy to overproduce
				\item \alert{Unclonable Identifiers:} Uses random process variations in silicon to generate random unique numbers called \alert{fingerprints}. \underline{Advantages:} Values cannot be reproduced or altered deliberately due to randomness in process variations
				\begin{betterlist}
					\item \alert{Intrinsic Methods:} If no additional logic is needed. Unique identification if external test vectors can be applied, Uses IC leakage, power and timing (unique due to process variations)%, Does not need additional logic and can be readily used on existing designs
					\item \alert{Extrinsic Methods:} If additional logic is required to generate these values (fingerprints)
					\begin{betterlist}
						\item \alert{Physical Unclonable Function (PUF):} Is a function that maps a set of challenges to a set of responses based on a complex physical system.  Generate IDs / keys from a complex physical system, The function can only be evaluated with the physical system, Is unique for each physical system because of random process variation., PUFs generate volatile secrets (only exist in a digital form when a chip is powered on and running), Harder for an invasive attack (must accurately measure PUF delays while power on)
						\item \underline{Quality requirements:} \alert{Uniqueness:} Different output for each measured chip. \alert{Reliability:} Identical output for repeated measurement on same chip. Trade-off wrt. sensitivity of the PUF concerning small process variations
						\item \alert{Arbiter-PUF:}
						\begin{betterlist}
							\item Compare two paths with an identical delay in design, Random process variation determines which path is faster, An arbiter outputs 1-bit digital response
							\item Path delays in an IC are statistically distributed due to random manufacturing variations
						\end{betterlist}

						\includegraphics[width=0.6\linewidth]{./figures/arbiter_puf.png}
						\item \alert{Ring-Oscillator PUF:}

						\includegraphics[width=0.8\linewidth]{./figures/ring_oscillator.png}
						\item \alert{Butterfly PUF}. \alert{SRAM PUF}
					\end{betterlist}
				\end{betterlist}
			\end{betterlist}
		\end{betterlist}
		\item \alert{Hardware Trojans:}
		\begin{betterlist}
			\item \alert{Identification of HDL-level / netlist level modifications}
			\begin{betterlist}
				\item \alert{IP Trust:} targets malicious modifications in third-party IP cores. IPs from untrusted vendors need to be verified for trust before use in a system design
				\item \alert{Formal verification:} Proves that a certain function is implemented correctly. Ensuring IP core is working exactly as specificied. \alert{Property/Model checking:} System is described in a formal model (HDL), The desired behavior is expressed as a set of (formal) properties, The properties are checked against the model. \alert{Equivalence checking:} Check the equivalence of RTL code, gate-level netlist and layout data
				\item \alert{Design Validation Techniques:} Identifies areas that have been exercised / checked. \alert{(Incomplete) simulation}. \alert{Coverage Analysis for Simulation:} Produces metrics to \alert{Code coverage:} \underline{Line coverage:} Shows which lines of the RTL have been executed, \underline{Statement Coverage:} Spans multiple lines, more precise, \underline{FSM Coverage:} Show which state can be reached, \underline{Toggle:} Each signal in gate-level netlist should switch. \alert{Functional coverage:} Check assertions
				% \item Ensuring IP core is working exactly as specificied, nothing less nothing more
			\end{betterlist}
			\item \alert{Identification layout level modifications}
			\begin{betterlist}
				\item \alert{IC Trust:} The objective is to ensure that the fabricated chip/system will carry out only our desired function and nothing more
				\item \alert{Destructive Approaches:} Expensive and time consuming. Reverse engineering to extract layer-by-layer images (e.g. by using scanning electron microscope), Identify unexpected transistors, gates or routing elements by comparison with golden sample
				\item \alert{Non-destructive Approaches:}
				\begin{betterlist}
					\item \alert{Run-time monitoring:} Monitor abnormal behavior during run-time. Add redundant components to ensure trust of critical computations
					\item \alert{Test time:} Detect Trojans by testing
					\begin{betterlist}
						\item \alert{Logic-testing-based approaches:} \underline{focuses on test-vector generation for:} Activating a Trojan circuit, Observing its malicious effect on the payload at the primary outputs, Both functional and structural test vectors are applicable. \alert{Advantages:} Straightforward, re-use existing test vector computation. \alert{Disadvantages:} Difficulty in exciting or observing low controllability / observability nodes. It cannot trigger Trojans that are activated externally and can only observe functional Trojans
						\begin{betterlist}
							\item Approaches to improve Trojan detection:
							\item Insert \alert{test points} to improve controllability / observability
							\item \alert{Modified ATPG} (automatic test pattern generation): \enquote{Statistical Approach for Hardware Trojan Detection}, Generates a set of test vectors that can trigger each rare node to its rare value multiple times ($N$ times), \underline{Hope:} If a Trojan is triggered by a combination of rare events, then the test set has at least one triggering vector%, Similar to N-detect test used in stuck-at ATPG (automatic test pattern generation), where test set is generated to detect each single stuck-at fault in a circuit by at least N different patterns
						\end{betterlist}
						% \item Difficulty in exciting or observing low controllability / observability nodes, Intentionally inserted Trojans are often triggered under rare conditions
					\end{betterlist}
				\end{betterlist}
			\end{betterlist}
		\end{betterlist}
	\end{betterlist}
\end{minipage}
\begin{minipage}[t]{0.2\linewidth}
	\begin{betterlist}
		\item \alert{Side-channel analysis-based approaches:} \uline{are based on observing the effect of an inserted Trojan on a physical parameter such as:} \alert{IDDQ:} Extra gates will consume leakage power, \alert{IDDT:} Extra switching activities will consume more dynamic power, \alert{Path delay:} Additional gates and capacitance will increase path delay (\underline{Observing delay:} A change in physical dimension of the wires and transistors can also change path delay), \alert{EM:} Electromagnetic radiation due to switching activity. \underline{Advantages:} Effective for Trojans which do not cause observable malfunction in the circuits (e.g. since they are not activated yet), \underline{Disadvantages:} Large process variations and measurement noise can mask the effect of the Trojan circuits, especially for small Trojans
		\item \alert{Design for Hardware Trust approaches:} to support Trojan detection / prevention approaches
		\begin{betterlist}
			\item \underline{Design changes for improving hardware Trojan detection methods:} \alert{Design changes for improving detection of delay changes} (problem: reconvergent paths, avoid or break by test points), \alert{Rare event removal} (e.g. test point insertion)
			\item \underline{Prevent hardware Trojan insertion}: \alert{Dead space elimination in layout}, \alert{Design obfuscation:} Transform design into functionally equivalent one, which it is much harder for attackers to understand, making reverse engineering much more difficult to perform
		\end{betterlist}
		\item \alert{Cloned, over-produced, out-of-spec, and defective ICs continue:}
		\begin{betterlist}
			\item \alert{Active Hardware Metering:} Provides an active mechanism to control, monitor, lock, or unlock the ICs after fabrication, Foundry is only able to produce locked ICs, Only designer / IP owner can unlock the IC. \underline{Advantage:} Overproduced chips do not work. \underline{Disadvantage:} IC with stolen IP may be possibly produced without locking mechanism (if locking mechanism can be easily separated from remaining design). Additional effort for unlocking (communication between designer and foundry)
			\begin{betterlist}
				\item \alert{Booster FSM:} Foundry produces chip with FSM which is put into random initial state by PUF. Only IP owner with knowledge of FSM knows for each state an input sequence to bring FSM into the actual \alert{reset state}: IP owner reads out random initial state, Determines correct input sequence, Stores input sequence on chip. \underline{Disadvantages:} Additional memory for storing initializing input sequence, Additional control logic for initialization, Additional time, chip has to wait until entire sequence has been shifted in.

				\includegraphics[width=0.8\linewidth]{./figures/booster_fsm.png}
				\item \alert{EPIC:} This technique tries to allow IP Owner to have control over number of chips activated. Uses logic locking to lock correct functionality of chip, At the gate level. XOR gates are placed on selected non-critical paths. Path outputs modified s.t. XOR’ing path outputs with key bits is needed to obtain correct output bits. Requires that every chip is activated with the external key. Only IP owner knows and sends the key
				\begin{betterlist}
					\item \underline{Different kinds of keys in EPIC:} \alert{Common key CK}, Identical key to activate all chips, \alert{Random chip key RCK}, Pair of private and public key individually generated on each chip, To secure the transmission of CK, \alert{Master key MK}, Pair of private and public key of the IP owner, To sign the encrypted key message which activates a chip, To avoid attacks by sending fake keys CK'
					\item Public Master Key (MK-Pub) is embedded in RTL. XOR gates are controlled by Common Key. Correct Common Key unlocks circuit's correct functionality, $k$-XOR gates need a common key of length $k$. TRNG (True Random Number Generator, e.g. PUF) used to generate Random Chip Keys (RCK) on start up, Upon power-up each chip generates a pair of private and public RCKs (RCK-private, RCK-public) which are burned into programmable fuses. Fab sends RCK-public to IP owner
					\item IP owner generates Input Key (IK) by encrypting Common Key (CK) with RCK-public and signs it with MK-private. IP owner sends IK to the foundry, IK is only for a single chip owning RCK-private. When entered into the chip, IK is decrypted using RCK-private and the signature is checked using MK-public. Decrypting IK results in CK which unlocks the chip’s correct functionality
				\end{betterlist}
			\end{betterlist}

			\includegraphics[width=0.2\linewidth]{./figures/epic_non_critical.png}
			\includegraphics[width=0.8\linewidth]{./figures/epic_high_level.png}

			\begin{minipage}[b]{0.5\linewidth}

				\includegraphics[width=\linewidth]{./figures/signature_not_used.png}
				% \includegraphics[width=0.5\linewidth]{./figures/signature_not_used.png} 
			\end{minipage}
			\begin{minipage}[b]{0.5\linewidth}

				\includegraphics[width=\linewidth]{./figures/signature_not_used15.png}
				\includegraphics[width=\linewidth]{./figures/signature_not_used2.png}
			\end{minipage}

			\item \underline{Analysis of Booster FSM and EPIC:}
			\begin{betterlist}
				\item \alert{Effective against cloned ICs:} ICs need individual information in order to be functional which only IP owner can generate
				\item \alert{Problem, if testing is outsourced as well:} Chip has to be activated for testing. Not efficient against over-produced, out-of-Spec ICs and defective ICs! \underline{Over-produced:} Fab could claim low yield and request more activations than needed, IP Owner has no way to verify yield or number of functional chips. \underline{Out-of-Spec and defective ICs:} Foundry/assembly can send out chips that are out of spec or defective (they are activated), IP Owner has no more communication with foundry
			\end{betterlist}
			\item \alert{SST:} Adds multiple layers of communication between IP owner, foundry, and assembly. Ensures that IP owner will know exactly how many chips pass the test and how many have failed. \underline{Basic Idea:} Unlocking for test mode does not make chip fully functional, Only IP owner can decide whether test passed or not, Only good ICs are unlocked in the end
			\begin{betterlist}
				\item Three-input XOR logic added to non-critical paths. IN0 and IN1 need to be identical for functional operation. Input IN0 is connected to a TRNG (e.g. PUF). TRNG generates a random number TRN. \underline{Same TRN is needed at foundry and assembly:} TRNG outputs are burnt into fuses so same TRN can be read. Makes random number stable for reading it out
				\item Second input IN1 gets modified Mod TRN. Only IP Owner knows how he has modified TRN. Only IP Owner can decide whether test responses are correct or not (because IP Owner knows what he did and therefore knows what would expect from correct chip, he would expect test results modified with modifications he did)
				\item Testing of packaged chip as before with Mod TRN. For good ICs IP owner sends FKEY which is encrypted version of unmodified TRN. TRN applied to IN1 (and IN0). Encryption ensures that answer with (encrypted) TRN cannot come from third party
				\item Relies on the fact that foundry / assembly cannot change functionality of the IC. Effective against overproduced ICs, cloned ICs, and defective ICs. \underline{Overproduced:} IP Owner has control over number of TRNs received and TKEY/FKEYS sent to foundry/assembly. \underline{Cloned:} Chips are not functional unless FKEY has been produced by IP Owner. \underline{Defective ICs:} Foundry sends test results to IP owner who checks results and decides if chip has correct test responses (chip is not yet functional at this stage)
				\item no global key $ck$, individual key for each chip, use TRNG not for private public key, but for producing unlocking key. Wherever IP owner flipped key (TRN), there also output of 3-input XOR is flipped. IP-Owner knows the assembly has to deliver for each FKEY the IP-Owner send, the IP-Owner expects a fully working chip from the assembly. \underline{Advantage:} Protection against key-leakage, because individual to each chip can only unlock this chip. Old attack now possible: Just take overproduced chip, one does not have the FKEY, one just applies something and compare output with functional chip, then one could produce small correction circuit for the outputs. But only if using bad locking mechanism which locks at the outputs, need locking mechanism whichs distributes XOR into the circuit. %Other attack: Replace TRNG by deterministic one, generally one can remove any security mechanism

				\includegraphics[width=0.5\linewidth]{./figures/xor_mask.png}
				$TKEY = encrypt_{k\,priv\,IP-Owner}(mod\,TRN)$

				\includegraphics[width=0.5\linewidth]{./figures/sst_communication_flow_foundry.png}
				\includegraphics[width=0.5\linewidth]{./figures/sst_communication_flow_foundry2.png}
			\end{betterlist}
		\end{betterlist}
	\end{betterlist}
\end{minipage}
\end{document}
