\documentclass{standalone}

\input{./content/packages}
\input{./content/desgin}
\input{./content/declarations}

\begin{document}
\begin{mindmap}
  \begin{mindmapcontent}
    \node (middle) at (current page.center) {Verification of Digital Circuits
      \resizebox{\textwidth}{!}{
        \begin{minipage}[t]{18cm}
        \end{minipage}
      }
    }
    child {
      node {Basics}
      child {
        node {Complexity classes
          \resizebox{\textwidth}{!}{
            \begin{minipage}[t]{12cm}
              \begin{itemize}
                \item \alert{P}: Problems that can be solved in Polynomial time in the size of the input
                \begin{itemize}
                  \item sorting ($n\cdot log(n)$), deciding if sequence is sortedv, shortest path in graph, matrix mulitplication (naively in $n^3$)
                \end{itemize}
                \item \alert{NP}: $N$ for nondeterministic, can guess a solution (yes answer) and verify efficiently that it is a solution
                \begin{itemize}
                  \item \alert{complete:} It's the hardest in it's class, if can solve SAT, one can solve all the problems in $NP$
                  \begin{itemize}
                    \item traveling salesman, bring in database in certain normal form, knapsack
                    \item noone has ever found an algorithm that solves them efficiently without guessing, all have exponential runtime and also noone was able to proof that there's no efficient algorithm
                  \end{itemize}
                \end{itemize}
                \item \alert{co-NP}: Can't guess the yes answer, one can guess the no
                \begin{itemize}
                  \item noone was able to proof whether NP and co-NP are the same, so one has to disitingiush them
                  \item equivalence checking for combinational circuits is \alert{co-NP complete}, can find an input that deals different outputs, therefore it's NOT equivalent
                \end{itemize}
              \end{itemize}
            \end{minipage}
          }
        }
      }
      child {
        node {Propositional Logic
          \resizebox{\textwidth}{!}{
            \begin{minipage}[t]{12cm}
              \begin{itemize}
                \item \script{128}{Syntax inductively and as context-free grammar}
                \item \script{129}{Semantics}
                \item \script{131}{Literal, Clause, Conjunctive Normal Form (CNF) (f.)}
                \begin{itemize}
                  \item \script{170}{Notation: Set of literals, empty clause}, order of literals does not matter and duplicates do not matter, empty set has role like the neutral element of disjunction, thus the empty clause is \alert{unsatisfiable} by definition \script{172}{Notation: CNF formula set of clauses, empty formula}, empty formula is a set of clauses, if one adds an empty set of clauses nothing changes, the clauses are connected with AND, one has connect $1$ with AND such that nothing changes, thus a empty formula is \alert{satisfiayble} by definition
                  \item \script{171}{Operations on clauses} and \script{172}{Union of two CNF formulas}
                \end{itemize}
                \item \script{144}{Equivalence}
              \end{itemize}
            \end{minipage}
          }
        }
        child {
          node {Resolution
            \resizebox{\textwidth}{!}{
              \begin{minipage}[t]{14cm}
                \begin{itemize}
                  \item \script{174}{Definition, resolvent}: $L\in C_1, \neg L \in C_2, R = (C_1 - \{L\}) \cup (C_2 - \{\neg L\})$, $R = C_1 \otimes_L C_2$
                  \begin{itemize}
                    \item \script{175}{Examples}, can delete all tautology clauses, because they are useless, at the bottom example for empty clause
                  \end{itemize}
                  \item \script{176}{Resolution Lemma}: Let $F$ be a CNF formula and $R$ be the resolvent of two clauses $C_1$ and $C_2$ from $F$. Then $F$ and $F \cup \{R\}$ are \alert{(logically) equivalent}: $F \equiv F \cup \{R\}$
                  \begin{itemize}
                    \item \script{177}{Proof}, \underline{one direction}: trivial, if assignment satisfies all clauses including the resolvent, then all the clauses without the resolvent are satisfied, \underline{other direction}: formula f satisfiable and show that also resolvent is satisfied, A a satisficing assignment of formula f, A is a model of f, if $L$ is true then $C_1$ was satisfied becaus of that, $C_2$ is also satisfied, otherwise the formula would not be satisfied, but it's not satisfied because of $L$, because the $\neg L$ is false, so $C_2$ without the $L$ has to contain another literal that is satisfied and that Literal is also contained in the resolvent and therefore the resolvent is satisfied. The other case wors exactly the same way%, $L$ is assigne to false, then $C_2$ is satisfied because of the $\neg L$, but $C_1$ cannot be satisfied because of the $L$, so $C_1$ has to contain another satisfying literal and that other satisfying literal ends up in the resolvent and satisfies it
                  \end{itemize}
                  \item \script{178}{$Res(F)$ etc.}
                  \begin{itemize}
                    \item $Res(F) = F \cup \{R \mid R \text{ is the resolvent of two clauses in } F\}$
                    \item $Res^0(F) = F$
                    \item $Res^{t+1}(F ) = Res(Res^t(F)) \text{ for } t \ge 0$
                    \item $Res^*(F ) = lim_{t\ge 0}\enspace Res^t(F)$
                    \item do as long as fomrula changes, only finitely many clauses, so it has to terminate
                  \end{itemize}
                  \item \script{179}{Resolution Theorem}: A CNF formula F is \alert{unsatisfiable} \textit{iff} $\square \in Res^*(F)$
                  \begin{itemize}
                    \item \script{180}{Proof}, proof two things: 
                    \begin{itemize}
                      \item \underline{if one can dervive the empty clause the formula is unsatisfied}: Only proof one half, if one can derive the empty clause, the formula is unsatisfied, resolution lemma: can add resolvents to the formula and it's logicaly equivalent, the empty clause is a resolvent, so one can add the empty clause to the formula and every formula that contains the empty clause is unsatisfied, the formula with the resolvent is unsatisfieable, therefore the original formula is unsatisfiable
                      \item \underline{if formula is unsatisfied, one can derive the empty clause:} later eliminate variables using resolution you canot only add resolvents but you can if you do it right get rid of variables using resolution and the result is a equally satisfiable formula. You just apply resolution to eliminate all the variables and you know the result is equisatisfiable to original If one eliminates all the variables there are only two cases of formulas without variables the empty formula satisfiable or the formula that only contains the empty clause that's unsatisfiable so that means when you eliminate all the variables you end up either with empty formula empty clause and you know the outcome is equally satisfible to the original formula that means when the outcome is the empty Formula the original formula was satisfiable if the outcome is the empty close then the original formula was unsatisfiable whenever it's unsatisfied we have to get the empty Clause because it can't get the empty formula 
                    \end{itemize}
                  \end{itemize}
                \end{itemize}
              \end{minipage}
            }
          }
        }
      }
      child {
        node {Important Definitions
          \resizebox{\textwidth}{!}{
            \begin{minipage}[t]{12cm}
              \begin{itemize}
                \item \underline{essential definitions:}
                  \begin{itemize}
                    \item \alert{verification method:} Check equivalence between specification and implementation
                    \item \alert{formal verification:} Mathematical proofs of correctness
                      \begin{itemize}
                        \item one uses \alert{formal methods} to avoid and detect design errors
                        \item because validation by simulation can never cover the complete system behavior
                      \end{itemize}
                    \item \alert{security:} A system should not leak information that should be kept secret
                    \item \alert{safety:} System does what it should do, implementation behaves as said in the specification (in this lecture)
                    \item \alert{canonical:} Exactly one representation
                    \item \alert{topological sort:} A graph traversal in which each node v is visited only after all its dependencies are visited
                    \begin{itemize}
                      \item a topological ordering is possible \alert{iff} the graph is a directed acyclic graph (DAG)
                      \item \underline{algorithm:} The algorithm loops through each node of the graph, in an arbitrary order, initiating a depth-first search that terminates when it hits any node that has already been visited since the beginning of the topological sort or the node has no outgoing edges (i.e. a leaf node)
                    \end{itemize}
                  \end{itemize}
              \end{itemize}
            \end{minipage}
          }
        }
      }
      child {
        node {Design of integrated circuits
          \resizebox{\textwidth}{!}{
            \begin{minipage}[t]{12cm}
              \begin{itemize}
                \item \underline{\script{22}{design of integrated circuits}:} 
                  \begin{itemize}
                    \item start with abstract specification and make it more and more concrete
                    \item implementation of the level before is the specification of the next level
                    \item equivalence checking for single steps easier than between initial specification and final implementation, similiarity is much higher
                    % \item more abstract SystemC Specification can be above Register-Transfer-Level
                    \item \alert{Initial Specification:} Usually in natural language
                      % \begin{itemize}
                      %   \item would need a specification in formal language e.g. specification by properties, on high level called design properties
                      % \end{itemize}
                  \end{itemize}
                  \begin{enumerate}[label=\color{PrimaryColor}\arabic*.]
                    \item \alert{Register-Transfer-Level:} Registers, Operations, Memory, no exact implementation for e.g. multiplier, don't fix the details
                      % \begin{itemize}
                      %   \item[$\textcolor{SwitchColor}{\blacksquare}$] Implementation in Hardware Description Language e.g. VHDL, Verilog
                      % \end{itemize}
                    \item \alert{Gate-Level:} Gates (AND, OR, etc.)
                    \item \alert{Layout-Level:} Placement (fix places of different components / gates) and routing (fix where connections go)
                  \end{enumerate}
                  \begin{itemize}
                    \item \alert{Final implementation:} Design data for producing the chip
                  \end{itemize}
              \end{itemize}
            \end{minipage}
          }
        }
      }
    }
    child {
      node {Basic technologies}
      child {
        node {Binary decision diagrams (BDDs)
          \resizebox{\textwidth}{!}{
            \begin{minipage}[t]{8cm}
              \begin{itemize}
                \item \script{41}{Syntax}
                \item \script{42}{Semantic}
                \item \script{45}{Example}
                \item \script{46}{Drawbacks}
                \item  The \alert{size} is given by the number of non-terminal nodes
                \item \underline{Limitations of BDDs:}
                \begin{itemize}
                  \item Canonical representation has to deal with the available memory.
                  \item Not directly usable with sequential circuits.
                  \item Not directly usable when the specification is a set of properties.
                \end{itemize}
              \end{itemize}
            \end{minipage}
          }
        }
        child {
          node {Construction of ROBDDs}
          child {
            node {Forward construction / symbolic simulation
              \resizebox{\textwidth}{!}{
                \begin{minipage}[t]{12cm}
                  \begin{itemize}
                    \item \script{104}{Algorithm}
                    \item \script{105}{Example}
                  \end{itemize}
                \end{minipage}
              }
            }
            child {
              node {ITE-Operator
                \resizebox{\textwidth}{!}{
                  \begin{minipage}[t]{14cm}
                    \begin{itemize}
                      \item all the binary operation can be reduced to a call to ITE (\enquote{If-Then-Else}-Operator)
                      \item \script{90}{Definition}: $ITE(F, G, H) = (F\wedge G)\vee(\neg F\wedge H)$
                      \begin{itemize}
                        \item the expression derives from the fact that a ITE node can be interpreted as a \alert{multiplexer} with inputs $G$ and $H$ and selector $F$
                        \item $AND(F, G) = ITE(F, G, 0) = (F\wedge G)\vee(\neg F\wedge 0) = F\wedge G$
                        \item $OR(F, G) = ITE(F, 1, G) = (F\wedge 1)\vee(\neg F\wedge G) = F \vee (\neg F \wedge G) = F\vee G$
                        \item $NOT(F) = ITE(F, 0, 1) = (F\wedge 0)\vee(\neg F\wedge 1) = \neg F$
                      \end{itemize}
                    \item \script{91}{Theorem and Proof}: $ITE(F, G, H) = (\neg x_i \wedge ITE(F_{\neg x_i}, G_{\neg x_i}, H_{\neg x_i}))\vee(x_i\wedge ITE(F_{x_i}, G_{x_i}, H_{x_i}))$
                    \item \script{93}{Algorithm to Compute a new ROBDD for ITE(F, G, H) out of ROBDD's F, G and H (ff.)}
                      \begin{itemize}
                        \item \underline{Base cases:} 
                          \begin{itemize}
                            \item $ITE(1, F, G) = ITE(0, G, F) = ITE(F, 1, 0) = ITE(G, F, F) = F$
                            \item $NOT(F) = ITE(F , 0, 1) = \neg F$
                          \end{itemize}
                        \item \script{99}{Runtime}
                      \end{itemize}
                    \end{itemize}
                  \end{minipage}
                }
              }
            }
          }
          child {
            node {Backward construction
              \resizebox{\textwidth}{!}{
                \begin{minipage}[t]{12cm}
                  \begin{itemize}
                    \item \script{116}{Algorithm}
                    \item \script{120}{Example}
                  \end{itemize}
                \end{minipage}
              }
            }
            child {
              node {Substitution operator, compose
                \resizebox{\textwidth}{!}{
                  \begin{minipage}[t]{12cm}
                    \begin{itemize}
                      \item \script{117}{Definition}: $compose(F, G, x_i)(x_1, \ldots , x_n) = F (x_1 , \ldots , x_{i-1}, G (x_1 , \ldots , x_n), x_{i+1}, \ldots , x_n)$
                      \item \script{118}{Theorem}: $compose(F, G, x_i) = ITE(G, F_{x_i}, F_{\neg x_i})$
                      \begin{itemize}
                        \item \script{119}{Proof}
                      \end{itemize}
                    \end{itemize}
                  \end{minipage}
                }
              }
            }
          }
        }
        child {
          node {Reduced Ordered Binary Decision Diagrams (ROBDDs)
            \resizebox{\textwidth}{!}{
              \begin{minipage}[t]{12cm}
                \begin{itemize}
                  \item A BDD G is a Reduced Ordered Binary Decision Diagram iff it is ordered and reduced
                    \begin{itemize}
                      \item In this context, reduced means that none of the reduction rules (\enquote{isomorphism} and \enquote{Shannon}) can be applied (anymore).
                    \end{itemize}
                  \item \script{57}{Example}
                  \item (\script{62}{Remark})
                  \item \script{65}{Proof of the Canonicity of ROBDDs}
                  \begin{itemize}
                    \item \script{64}{Definition Isomorphism}
                  \end{itemize}
                \end{itemize}
              \end{minipage}
            }
          }
          child {
            node {Reduction Rules
              \resizebox{\textwidth}{!}{
                \begin{minipage}[t]{12cm}
                  \begin{itemize}
                    \item OBDDs can be reduced to ROBDDs in layers starting from the terminal nodes
                  \end{itemize}
                \end{minipage}
              }
            }
            child {
              node {\enquote{Isomorphism} reduction
                \resizebox{\textwidth}{!}{
                  \begin{minipage}[t]{12cm}
                    \begin{itemize}
                      \item \script{51}{Definition}
                      \item \script{52}{Example}
                    \end{itemize}
                  \end{minipage}
                }
              }
            }
            child {
              node {\enquote{Shannon} reduction
                \resizebox{\textwidth}{!}{
                  \begin{minipage}[t]{12cm}
                    \begin{itemize}
                      \item \script{53}{Definition and Example}
                    \end{itemize}
                  \end{minipage}
                }
              }
            }
          }
          child {
            node {Ordered BDDs (OBDDs)
              \resizebox{\textwidth}{!}{
                \begin{minipage}[t]{12cm}
                  \begin{itemize}
                    \item A BDD G over the set of variables $X_n = \{x_1, \ldots, x_n\}$ is ordered, iff it is \alert{free} and the \alert{variables on every path} from the root to a terminal node occur in the \alert{same order}
                    \item \script{48}{information about variable order}
                    \item \script{49}{example}
                    \item This is still not enough, there can be redundancy in the OBDD
                  \end{itemize}
                \end{minipage}
              }
            }
            child {
              node {Free BDDs
                \resizebox{\textwidth}{!}{
                  \begin{minipage}[t]{12cm}
                    \begin{itemize}
                      \item A BDD G is free, iff each variable along every path from the root to a terminal node occurs at most once.
                      \item \script{47}{Example}
                    \end{itemize}
                  \end{minipage}
                }
              }
            }
          }
        }
        child {
          node {Shannon theorem
            \resizebox{\textwidth}{!}{
              \begin{minipage}[t]{8cm}
                \begin{itemize}
                  \item \script{43}{Definition}: $F = (\neg x_i\wedge F_{\neg x_i})\vee(x_i\wedge F_{x_i})$
                  \item \script{44}{Proof}
                  \item for BDD's Composition rule and Decomposition rule have the same structure
                \end{itemize}
              \end{minipage}
            }
          }
        }
        child {
          node {Use of ROBDDs in Verification
            \resizebox{\textwidth}{!}{
              \begin{minipage}[t]{12cm}
                \begin{itemize}
                  \item the size of a ROBDD depends strongly on the variable order $\pi$ one chooses
                  \begin{itemize}
                    \item \script{81}{example (f.)}
                  \end{itemize}
                  \item every cofactor regarding the first n variables consitutes a different Boolean function
                  \begin{itemize}
                    \item $2n$ different cofactors
                    \item \script{83}{example}
                  \end{itemize}
                \end{itemize}
              \end{minipage}
            }
          }
          child {
            node {Finding optimal variable order
              \resizebox{\textwidth}{!}{
                \begin{minipage}[t]{8cm}
                  \begin{itemize}
                    \item \alert{Theorem (Bollig, Savicky, Wegener, 1994):} Given a ROBDD with variable order $\pi$, the problem of finding a new variable order $\pi\prime$ with minimal ROBDD-size is NP-Complete
                      \begin{itemize}
                        \item \underline{but there are \alert{Heuristics}:}
                          \begin{itemize}
                            \item define an initial variable order based on the circuit representation
                            \item perform dynamic reordering within an existing variable order to reduce the size of the ROBDD
                          \end{itemize}
                      \end{itemize}
                  \end{itemize}
                \end{minipage}
              }
            }
            child {
              node {Define an initial variable order
                \resizebox{\textwidth}{!}{
                  \begin{minipage}[t]{12cm}
                    \begin{itemize}
                      \item \script{107}{Method of Malik}
                      \item \script{108}{Example}
                    \end{itemize}
                  \end{minipage}
                }
              }
            }
            child {
              node {Dynamic modification of the variable ordering
                \resizebox{\textwidth}{!}{
                  \begin{minipage}[t]{12cm}
                    \begin{itemize}
                      \item \script{110}{General Algorithm}
                      \begin{itemize}
                        \item \script{112}{Sifting}
                        \begin{itemize}
                          \item \script{113}{Example}
                          \item \script{114}{Runtime}
                        \end{itemize}
                      \end{itemize}
                    \end{itemize}
                  \end{minipage}
                }
              }
            }
          }
          child {
            node {Not applicable for all pratical functions
              \resizebox{\textwidth}{!}{
                \begin{minipage}[t]{12cm}
                  \begin{itemize}
                    \item \alert{Theorem (Shannon):} \enquote{Almost every} Boolean function $F\colon\, \mathbb{B}^n\rightarrow\mathbb{B}$ requires more than $(2^n / n) 2$-input gates for an optimal implementation
                    \begin{itemize}
                      \item holds also for ROBDDs, because they can be seen as multiplexer circuits
                      \item \underline{should we care?}: not really, because one does equivalence checking mostly for circuits that are not exponential (the others that are not \enquote{almost every} usually occur, because we're interested in functions with structure)
                    \end{itemize}
                    \item \alert{Lemma (Bryant, 1986):} Independently from the variable order, multiplication is representable with ROBDDs only with exponential complexity in the bit-width
                    \begin{itemize}
                      \item there exist actually polynomial mutlipliers, but there are no ROBDDs with polynomial complexity in the bit-width for them
                    \end{itemize}
                  \end{itemize}
                \end{minipage}
              }
            }
          }
        }
      }
      child {
        node {Satisfiability solvers (SAT / QBF)
          \resizebox{\textwidth}{!}{
            \begin{minipage}[t]{12cm}
              \begin{itemize}
                \item \script{130}{Satisfiable, Model, Unsatisfiable}
                \item \script{133}{Satisfiability-Problem (SAT-Problem)}
                \item \script{164}{Complexity of the SAT Problem}, NP-complete
                % what does NP-Complete mean summary: https://youtu.be/doDYnn9sXWg?feature=shared&t=2286
                % complexity of equivalence checking: https://youtu.be/doDYnn9sXWg?feature=shared&t=2586
                % restrictions ot SAT: https://youtu.be/doDYnn9sXWg?feature=shared&t=2715
                % horn formulas: https://youtu.be/doDYnn9sXWg?feature=shared&t=2761
                \item \script{165}{Practice and Applications}, in worst case all algorithm have exponential runtime, but worst case and pratical case are different
                \item \script{167}{Overview on SAT Algorithms (f.)}
                \begin{itemize}
                  \item \script{167}{complete:} run until either they have found a solution or they can prove there's none, decide all formulas if one has enough time, always terminate and always give right answer
                  \item \script{168}{incomplete methods:} typically can only find satisfying assignments, if one has a formula with many satisfying assignments, if one has a unsatisfiable formula, they will not terminate, they just look for solutions that modify assignment check again etc.
                  \begin{itemize}
                    \item scheduling problem, need to find good order, one knows that there's an order that works 
                    \item in verification they play no role at all, because verification problems either unsatifiying assignments or a few not working corner cases and then incomplete methods are not good at all, either they don't terminate or need very long time to find one of these rare satisfying assignments. Therefore in verification typically only have these complete methods that systematically search for satisfying assignments and can also prove that the formula is unsatisfiable
                    \item typically verification is applied if you cannot find any wrong answers anymore by just doing simulation
                  \end{itemize}
                \end{itemize}
                \item \underline{different kinds of SAT:} $k$-SAT, every clause exactly $k$-literals, $3$-SAT, $2$-SAT (efficiently solvable)
                \begin{itemize}
                  \item \alert{Horn-Formulas:} arbitrary length but contain at most on positive literal (or other way round at most one negative literal), relevance in Prolog, Prolog Statements are Horn clauses, clause with only one literal (if 0 and 1 at the same time, then unsatisfiable), otherwise end up with formula where all clauses have at least length $2$, that means every clause contains a negative literal, if there are no unit clauses, the formula can be satisfied by simply setting all remaining variables negative, can be done efficiently without backtracking
                \end{itemize}
              \end{itemize}
            \end{minipage}
          }
        }
        child {
          node {Naive method
            \resizebox{\textwidth}{!}{
              \begin{minipage}[t]{12cm}
                \begin{itemize}
                  \item \script{181}{Algorithm}
                  \item \script{182}{Complexity}, is limited by the number of different possible clauses (cnf formula is a \alert{set} of \alert{clauses}, not of maxterms, so there are $3$ states and not only $2$)
                  \item \script{183}{Examples (ff.)}, resulting tautology $(x_2, \neg x_2)$ of first and fourth can be ignored
                  \begin{itemize}
                    \item we do not have to resolve two Clauses from F again because we already did that so we always take either two Clauses from the new ones orthird one Clause from F and one new Clause 
                  \end{itemize}
                \end{itemize}
              \end{minipage}
            }
          }
        }
        child {
          node {DP-Algorithm
            \resizebox{\textwidth}{!}{
              \begin{minipage}[t]{14cm}
                \begin{itemize}
                  \item based on \alert{variable elimination} method and uses a couple of optimizations:
                  \begin{itemize}
                    \item \script{189}{Subsumption check}: Let $C_1$ and $C_2$ be two clauses. $C_1$ subsumes $C_2$ iff all literals occurring in $C_1$ also occur in $C_2$: $C_1 \subseteq C_2$
                      \begin{itemize}
                        \item \alert{Idea:} To satisfy a CNF formula $F$, all clauses need to be satisfied, in particular $C_1$. Since all literals of $C_1$ are also contained in $C_2$, every satisfying assignment of $C_1$ also satisfies $C_2$. Therefore $C_2$ does not need to be considered separately and can be deleted. One has to satify $C_1$ in any case for a satifying assigment, if on would satisify the additional literal in $C_2$, still the literals in $C_1$ have to be satisfied that would also satisfy $C_2$
                        % \item the other way does not know if you satisfy C2 then you can satisfy using the additional literal and that does not help for satisfying C1 so you need to set up one more literal but that's not necessary because the one in C1 is sufficient
                        \item \script{190}{Example}
                      \end{itemize}
                    \item \script{191}{Pure literal detection}: Let $F$ be a CNF-formula and $L$ a literal contained in $F$. $L$ is a \alert{pure literal} \textit{iff} $L$ is contained in $F$ either only positive or only negative, but not both $L$ and $\neg L$ appear in $F$. For satsifyiability one just needs one satisfying assignment, for making the literal true and removing clauses one will in every case find a satisfying assignment, but if one would make the literal false, there would be remaning clauses that have to be satisfied and could cause contradictions with the clauses not containing the literals. The first case would only have to satisfy the clauses without this literal, while in the second clauses the clauses without this literal and the ones that contained this literal would have to be satisfied, so one in always on the better side by choosing the literal to be true
                    \begin{itemize}
                      \item \alert{Idea:} Delete from $F$ all clauses which contain a pure literal. They can be satisfied by an according assignment to $L$. This cannot prevent any other clause from being satisfied, because $\neg L$ does not appear in $F$
                      \item \script{192}{Example}
                    \end{itemize}
                    \item these optimizations are not complete in the sense they are sufficient to solve the formula so we need one potentially expensive operation which does the the actual work and that is Variable Elimination
                    \item \script{193}{Variable Elimination}: The DP-algorithm applies \alert{resolution} to eliminate a variable $x_i$ completely from the formula, i. e., all occurrences of $x_i$ and $\neg x_i$. The goal is to reduce the number of variables.
                      \begin{itemize}
                        \item \script{194}{$P$, $N$ and $W$}
                        \item \script{195}{$P \otimes_{x_i} N$}
                        \item \script{196}{Theorem: $F = P \cup N \cup W$ and $F' = (P \otimes_{x_i} N) \wedge W$ satisfiability equivalent}
                          \begin{itemize}
                            \item \script{196}{Proof} and \href{/home/areo/Documents/Studium/Summaries/Verification_of_Digital_Circuits/figures/lecture06_sat_36_05.pdf}{\inlinebox{More detailed proof}}, replace the unions with and. %we still have to apply distributivity for that we take one Clause from the P one Clause from the n and take their Union so and do that with all the combinations what do we get we pick one Clause from that set that's a the same Clause as in p but x i is set to zero so x i is removed and we take one Clause from n the original clause contained the not x i with an x i to one so that's removed because it's zero that's just a resolvent 
                              %get all these ressolvants by applying distributivity to these clauses but we have to pick one element from P one element from n and take the or that's the same as the resolving that you get by picking one clause from P one Clause from n and then resolving it on x i that removes the x i from the p Clause the not x_i from the n clause the same have the W plus all resolvents 
                              Here we see exactly what variable elimination with the resolution does replaces x_i once by 0 once by 1 takes the or because one of the two parts has to be satisfied bring it back to CNF and you get the same as the resolution
                            \item we can reduce checking satisfiability of a formula $F$ to checking satisfiability of $F'$. $F'$ does not contain the variable $x_i$ anymore. If $F'$ is satisfiable, this also holds for $F$ and vice-versa
                            \item will sooner or later terminate because you only have a finite number of variables
                          \end{itemize}
                        \item choose an appropriate variable $x_i$, perform resolution between all pairs of clauses which contain $x_i$ and $\neg x_i$, resp., and replace the original clauses (containing $x_i$ or $\neg x_i$) by the resolvents
                        \item usually the number of resolvents is larger than the number of original clauses which are replaced, i. e., the formula grows in size during variable elimination
                        \item \script{201}{Example}, tautology ignored, at the end one can eliminate X3 if one wants that gives the empty Clause so the formula was unsatisfiable
                      \end{itemize}                             
                    \item \script{202}{Davis-Putnam Algorithm}, unit Clause: we delete all the Clauses that that contain L because that s these are satisfied and from the remaining Clauses that unit resolution step is we resolve all the Clauses that contain not L with the unit Clause that removes the not L from all clauses then we call DP on the simplified formula so delete all satisfied Clauses delete all unsatisfied literals and call it recursively. If all doesn't help one elimantes a variable in the last step so you cannot get an infinite sequence of DP calls
                  \end{itemize}
                  \item the optimizations improve the runtime behavior in practice, but not the worst case complexity of the naı̈ve method, based on resolution plus a few optimizations%, they improve the running time in practice and the memory consumption but not in the worst case
                  \begin{itemize}
                    \item the main problem here is memory consumption so generating all these resolvents is costly
                  \end{itemize}
                \end{itemize}
              \end{minipage}
            }
          }
        }
        child {
          node {DLL/DPLL-Algorithm
            \resizebox{\textwidth}{!}{
              \begin{minipage}[t]{12cm}
                \begin{itemize}
                  \item circumvents the memory problems of resolution-based techniques through a distinction of cases, which leads to \alert{depth-first search}
                  \item \alert{Idea:} If a CNF formula $F$ is satisfiable, then for a variable $x_i$ either $x_i = 1$ or $x_i = 0$ must hold $\Rightarrow$ try both cases one after the other
                  \item \script{206}{DLL-Algorithm}:
                  \begin{itemize}
                    \item Assign $L$ to $1$. Delete all clauses containing $L$. Delete all occurrences of $\neg L$ % At the end we first set the literal to True, try to solve the formula we get by that, if it's satisfiable we are finished otherwise we flip the value to false try again and if that's also unsatisfiable the formula is unsatisfiable 
                    \item \alert{Unit Clause}: A clause consisting of a single literal $L$ is called a unit clause. $L$ is the corresponding unit literal. For $P \otimes_{x_i} N$ with $N =\emptyset$ the result is $\emptyset$, because the condition in the set definition of the $P \otimes_{x_i} N$ is never satisfied, so one gets an empty formula
                    \item \script{208}{Example (ff.)}
                    \item \script{226}{Summary}
                    \item the running time is still exponential because in the worst case we just have to to try all the assignments in N variables and there are 2^n assignments. \underline{Memory Problem:} When we have to do backtracking we need to go back to the old formula so you have to keep the old copy and you create a new formula with the modifications. With many variables the depth of the DFS Tree can be the number of variables
                  \end{itemize}
                \end{itemize}
              \end{minipage}
            }
          }
        }
        child {
          node {Modern SAT-Algorithms
            \resizebox{\textwidth}{!}{
              \begin{minipage}[t]{14cm}
                \begin{itemize}
                  \item \script{237}{Basic techniques of today’s SAT solvers}
                    \begin{itemize}
                      \item preprocessing
                      \item alternation between ...
                        \begin{itemize}
                          \item choose the next decision variable, decide its value
                          \item boolean Constraint Propagation / Unit Propagation
                          \item if applicable, conflict analysis and backtracking
                        \end{itemize}
                      \item at some fixed points of the search process
                        \begin{itemize}
                          \item Unlearning (some conflict clauses)
                          \item Restarts
                        \end{itemize}
                    \end{itemize}
                  \item \script{238}{Algorithm}
                  \begin{itemize}
                    \item BCP processes all the implications and detects a conflict if we have a conflict we run conflict analysis we get back a backtrack level if the backtrack level is $0$ we know the formula is unsatisfiable if it's not zero but greater than zero then we can do backtracking and finally if the decision juristic has nothing to do anymore, meaning all the variables are assigned then the formula is satisfiable so that also means we do not check if the formula is already satisfied that might happen before all the variables are assigned but a solver does not detect that it just runs until all variables are assigned and if no conflict has happened the formula satisfied why is that the case because it's cheaper to just run until all variables are assigned then detecting if the formula satisfied so nobody checks if the formula satisfied because that requires running overall clauses and in between you sometimes do just unlearning and restarts and so on
                    \item want to get a satisfying assignment at the end if you did pre-processing then you have to be careful the satisfying assignment you get from the solver is the satisfying assignment of the formula after pre-processing but you don't want the satisfying assignment of the formula after pre-processing but before pre-processing because you don't mind what the solver does of the formula and it can happen that the satisfying assignment you get does not work for the original formula, you might have to add a few more assignments because you're eliminated variables it might also happen that you have to modify that assignment because you deleted some clauses that you were allowed to delete but you get a wrong assignment then and you have to correct it
                  \end{itemize}
                \end{itemize}
              \end{minipage}
            }
          }
          child {
            node {Preprocessing
              \resizebox{\textwidth}{!}{
                \begin{minipage}[t]{12cm}
                  \begin{itemize}
                    \item \script{240}{in the algorithm}
                    \item \script{241}{goal, practical observations, find good compromise}
                    \item \script{242}{preprocessing techniques}
                  \end{itemize}
                \end{minipage}
              }
            }
            child {
              node {Unit Propagation
                \resizebox{\textwidth}{!}{
                  \begin{minipage}[t]{12cm}
                    \begin{itemize}
                      \item if omitted, then immediately performed during solving process
                      \item \underline{procedure:}
                      \begin{itemize}
                        \item identify unit clauses in the CNF
                        \item assign units, simplify
                        \item if you get an empty clause formula is unsatisfiable otherwise in the end the CNF does not contain any unique clauses
                        % \item ... until the CNF is free from unit clauses
                      \end{itemize}
                    \end{itemize}
                  \end{minipage}
                }
              }
            }
            child {
              node {Unit Propagation Lookahead (UPLA)
                \resizebox{\textwidth}{!}{
                  \begin{minipage}[t]{12cm}
                    \begin{itemize}
                      \item fix a variable $x_i$ to $0$, check implications; then change its value to $x_i = 1$, check implications. Simplify the formula exploiting the \script{244}{consequences}, and also $(x_i = 0 \rightarrow x_j = 1) \wedge (x_i = 1 \rightarrow x_j = 0) \Rightarrow x_i \equiv \neg x_j$
                      \item ones pretends to have a unit clause and checks what happens, all you need for that is already implemented in the solver the only thing you need is BCP and you need BCP anyway what's the drawback Now it only works if you have clauses of length $2$ if all clauses in the formula have a length longer than two by assigning one variable you don't get any implications, it requires binary clauses and it only makes sense to apply UPLA to variables that appear in binary claes the rest can just be skipped. And because some of the variables might be missing after applying UPLA you have to do something after solving the formula namely add more variable assignments you have to keep track if variables are equivalent or so
                      \item \script{245}{Advantages and Disadvantages}
                    \end{itemize}
                  \end{minipage}
                }
              }
            }
            child {
              node {Self-subsuming resolution
                \resizebox{\textwidth}{!}{
                  \begin{minipage}[t]{12cm}
                    \begin{itemize}
                      % \item apply resolution to two clauses and resolution result subsumes one of the clauses
                      \item apply resolution such that the outcome is a subset of one of the operands. why can we replace it you can always add the resolvend to the clause then apply the subsumption checking and that deletes one of the two so it's just replace and outcome is a logically equivalent formula 
. Saves literals
                      \item \script{246}{Example}
                    \end{itemize}
                  \end{minipage}
                }
              }
            }% / clause distribution ?
            child {
              node {Elimination by Resolution
                \resizebox{\textwidth}{!}{
                  \begin{minipage}[t]{12cm}
                    \begin{itemize}
                      \item \alert{variable elimination} applied to a variable of the CNF formula, seen in DP
                      \item it is applied only if it leads to a simplification of the formula
                      \item so deleting Clause is not always good of course it makes the formula shorter but later during the solution process the solver goes the hard way to derive conflict clauses they are just resolved and added so it's not always good to delete clauses also it makes the formula shorter if you could add the good conflict clause in the beginning the solver would be much faster so it's not clear what helps
                      \item \script{247}{Example}
                    \end{itemize}
                  \end{minipage}
                }
              }
            }
            child {
              node {Variable elimination by substitution
                \resizebox{\textwidth}{!}{
                  \begin{minipage}[t]{12cm}
                    \begin{itemize}
                      \item if clauses represent a gate like in the Tseitin transformation, these clauses can be removed and then every occurence of the variable that corresponds to the output of the gate has to be replaced by the other side of the equation for the remaning clauses
                      \item potentially saves variables, literals and clauses, it is applied only if it leads to a simplification of the formula
                      \item \script{248}{Example}
                    \end{itemize}
                  \end{minipage}
                }
              }
            }
            child {
              node {Forward subsumption and Backward subsumption
                \resizebox{\textwidth}{!}{
                  \begin{minipage}[t]{16cm}
                    \begin{itemize}
                      \item \alert{Forward Subsumption:} Test if a clause generated during one of the other preprocessing techniques is subsumed by one clause of the initial formula. Remove all the clauses subsumed
                      \item \alert{Backward Subsumption:} Test if a clause generated during one of the other preprocessing techniques subsumes one (or more) clauses of the initial formula. Remove all the clauses subsumed
                      \item in principle you do subsumption checking whenever you add a clause to the clause database there's function add_clause that gets a new clause and adds it to the list of all clauses whenever you do that you can check for subsumption and there are two variables as the new Clause is the short one the subsuming clause the subset is newly added and the long one is already in the clause database or the other way around you have a short clause in the clause database and you want to add a new clause which is a super set of the one you already have in the first case when you add the short clause you can replace the long with the short in the second case where you add the long one you can just ignore it
                      \item forward subsumption is you add the long one backward subsumption is you add the short one now why do we distinguish it really here because the running time of the check is completely different 
                      \item backwards subsumption now one of the data structures in the preprocessor is typically the occurrence list so for every lital you have a list of all clauses which this lital occures so you have a list of X1 list for not X1 list for X2 for not X2 and so on so when you add the short clause how can you find all candidates that could be subsumed by the new clause if you add X1 X2 
                      \item all candidates that can be subsumed by X1 X2 contain X1 and they also contain an X2 so you can look either at the occurrence list of X1 or at the occurrence list of X2 and you just pick the shorter one you have to only run over the shortest occurrences that's quite efficient 
                      \item forward subsumption: you have the long clause, the only thing you know is the short clause contains at least one of the literals of the long clause so you have to run over all occurrence to find all possible candidates and running over all occurrences is worse than just running off the best one shortest one and therefore forward subsumption is expensive backward subsumption is quite cheap 
                      \item backward subsumption is done all the time forward subsumption from time to time only 
                    \end{itemize}
                  \end{minipage}
                }
              }
            }
            child {
              node {Blocked Clause Elimination
                \resizebox{\textwidth}{!}{
                  \begin{minipage}[t]{12cm}
                    \begin{itemize}
                      \item let $C$ be a clause and $\ell \in C$ a literal, $C$ is blocked by $\ell$ \texttt{iff} for all clauses $D$ with $\neg\ell \in D$ holds: $C \otimes_{\ell} D$ is a tautology
                      \item \alert{Blocked clauses} can be deleted without changing satisfiability
                    \end{itemize}
                  \end{minipage}
                }
              }
            }
            child {
              node {Equivalent Literals
                \resizebox{\textwidth}{!}{
                  \begin{minipage}[t]{12cm}
                    \begin{itemize}
                      \item take only the binary clauses $\{\ell, \kappa\}$
                      \item create the \alert{binary clause graph} $G = (V, E)$ with
                      \begin{itemize}
                        \item $V = \{x, \neg x \mid x \text{ variable}\}$
                        \item $E = \{(\neg \ell, \kappa), (\neg \kappa, \ell) \mid \{\ell, \kappa\} \in \varphi\}$
                      \end{itemize}
                      \item all literals in strongly connected components can be replaced by one representative
                      \item if there is a path from $\neg \ell$ to $\ell$ for some literal $\ell$, we can replace $\ell$ by $1$
                    \end{itemize}
                  \end{minipage}
                }
              }
            }
          }
          child {
            node {Improvements
              \resizebox{\textwidth}{!}{
                \begin{minipage}[t]{16cm}
                  \begin{itemize}
                    \item \script{224}{Improvements to DLL}: We do we actually modify the formula we can just say oh that clause is satisfied that's one bit of information and we can keep an assignment of the variables then you can just look it up if a variable is unsatisfied or not that's one major Improvement and of course we can carefully select which literal to assign we can learn from the conflicts so we can find out what are the reasons why the formula is unsatisfied not always all decisions are responsible for a unsatisfied formula but only a subset and we want to find out which subset 
                    \begin{itemize}
                      \item \alert{pre-processing} before you solve the formula the goal is simplify a formula simplify means get rid of some of the clauses get rid of some of the variables shorten some clauses just simplify 
                      \item \alert{decision heuristics} pick a good variable and a good value for that variable when you make the decision. It's obvious that a good decision juristic helps on satisfiable formulas it also helps on unsatisfiable formulas because the sooner you run into a conflict the smaller part of the search Tree is that you have to look at if you run directly into conflict there's no reason to continue at this point you just try the other part so the sooner you run into conflict the better
                      \item \alert{BCP} is just the process of finding all unit clauses in principle it's trivial run over the formula check each clause is there only one unassigned literal left, it's not easy to do it fast looking at all clauses is too expensive, BCP is how do you do it as fast as possible. BCP is find all unit clauses as fast as possible
                      \item \alert{conflict analysis} happens when you run it a conflict conflict is you have an unsatisfied clause an empty clause then you want to find out which were the assignments that triggered this conflict which are responsible for getting an empty clause and you use that for backtracking that information there are two variants of backtracking one is called chronological backtracking and the other one non-chronological \alert{chronological} is what you have seen go back to the last decision and keep it. \alert{Non-chronological} backtracking tries to undo as many decisions as possible such as you just resolve the conflict and sometimes you can undo more assignments that's called non-chronological backtracking and the only information is that you need is which is the reason for the conflict yeah unlearning so conflict analysis also adds an additional clause to the formula that says not that bad assignment again so for instance if the if you found out in conflict analysis that assigning x 1 to true and X2 to false are the reason for the conflict so whenever you assign X1 to 1 and X2 to false you will get a conflict so you never want to do that again how can you say that oh you say either X 1 is false or X 2 is true so you have to Clause not X1 or X2 whenever you try to get that bad assignment again when you assign X1 to one then that clause becomes a unit clause and says oh X2 has to be one that's a conflict clause and you add it to the Clause database in order to prevent the solve from running into the same conflict again so the problem is you run into millions of conflicts during the solution process and you often learn more clauses than your original formula had and you have to store all of that in memory you have to process them all during bollean constraint propagation so the more you of these conflict Clauses you have the more work you have to put into BCP and there is a tradeoff between many conflict Clauses which hope hopefully trigger some implication from time to time and slowing down easy and therefore from time to time you just delete conflict clauses to reduce the memory overhead and to prevent BCP from slowing out that's \alert{unlearning conflict clauses}
                      \item \alert{restarts} something strange you just start from scratch again so it can happen that the solver gets stuck into in some bad part of the search space so you have a tree you learn conflict and conflict and conflict and conflict but you make little progress so you only learn really long little useful conflict clauses and then it makes sense to say oh let's start again you keep the good conflict clause that you have learned you keep the information the decision heuristics has learned about good variables and you start from scretch and it seems to help so the hope is the information that you have learned drives you into a different part of the search space not into the bad one when you get stuck but you first look at the different part and there you learn additional conflict losses and they might be useful to handle this difficult part of the search space and therefore you make these restarts from time to time you have to be bit careful if you restart too often you can end up doing restarts in a cycle so you restart you solve a little bit you restart you solve a little bit again you restart you solve a little bit again and so on you can get stuck so typically you choose the interval between two restarts such that it diverges it gets longer longer you make few and fewer restarts 
                    \end{itemize}
                  \end{itemize}
                \end{minipage}
              }
            }
          }
          child {
            node {Differences to DLL
              \resizebox{\textwidth}{!}{
                \begin{minipage}[t]{14cm}
                  \begin{itemize} 
                    \item \underline{Differences:}
                      \begin{itemize}
                        \item \script{228}{Difference $1$: Recursion and modification of formula (f.)}
                          \begin{itemize}
                            \item \underline{DLL}:
                              \begin{itemize}
                                \item recursive procedure
                                \item for the transition from the recursion level $r$ to the level $r + 1$ the given formula is modified (clauses being satisfied are removed and \enquote{unsatisfied literals} are erased)
                                \item for backtracking from level $r + 1$ to $r$ the original (sub)formula at level $r$ must be restored
                              \end{itemize}
                            \item \underline{Modern SAT}:
                              \begin{itemize}
                                \item non-recursive procedure 
                                \item apart from special cases, during the search process neither satisfied clauses nor resolved literals are removed from the CNF formula no removal from CNF formula
                                \item usually the \alert{pure literal} rule is not applied, overhead for detecting pure literals is larger than what it helps. Pure literals can occur after preprocessing when you assign variables and you can ignore the satisfied clauses and in the remaining not yet satisfied sources there can be pure literals. \alert{Subsumption check} is applied by modern SAT-algorithms only during preprocessing. \alert{Variable elimination} is applied by modern SAT during preprocessing. Here elimination of a variable is only done if it reduces the formula size (or only slightly increases it)
                                \item we never modify clauses except in pre-processing
                              \end{itemize}
                          \end{itemize}
                        \item \script{230}{Difference $2$: Unit clause definition (f.)}
                          \begin{itemize}
                            \item In DLL a clause is made of exactly one literal. In modern procedures also the clauses where all the literals but one are assigned with negated polarity are denoted with the term unit clause. \script{231}{Example of implication}
                            \item \script{232}{Boolean Constraint Propagation (BCP) or Unit Propagation and example}: Determining all the implications forced by the assignment of a variable
                          \end{itemize}
                        \item \script{233}{Difference $3$: Contradiction / conflict (f.)}
                          \begin{itemize}
                            \item empty clause for DLL, Unsatisfied clause for modern SAT algorithms in which all literals are assigned to false. \script{233}{Example}
                          \end{itemize}
                        \item \script{234}{Difference $4$: Conflict analysis and backtracking: (f.)}
                          \begin{itemize}
                            \item \underline{DLL:} The combination of the previously done decisions will always be considered as the origin of a conflict. Backtracking (recursive back tracing) to the recursion level of the last \enquote{branching} in which one case for a variable assignment has not been explored yet. If none exists the given CNF formula is unsatisfiable. Backtracking always goes back one decision level
                            \item \underline{Modern SAT:} Complex and deep analysis of the conflict setting, because not all the previously made \enquote{branchings} must be involved in the current conflict Derivation via resolution and learning of a \alert{conflict clause} for the given formula. The conflict clause avoids to run into the identical conflict again by including all the literals that are responsible (because of their assignment) for the current contradiction. Backtrack with the help of the conflict clause or output UNSATISFIABLE. What are the actual assignments that led to the conflict and rule out the ones that are not involved in the conflict
                          \end{itemize}
                      \end{itemize}
                  \end{itemize}
                \end{minipage}
              }
            }
          }
        }
      }
      child {
        node {And-inverter graphs (AIGs)
        }
      }
    }
    child {
      node (test) {Property checking
        \resizebox{\textwidth}{!}{
          \begin{minipage}[t]{12cm}
            \begin{itemize}
              \item Prove that a system specifies a set of properties
            \end{itemize}
          \end{minipage}
        }
      }
      child {
        node {Specification of properties with temporal logics}
      }
      child {
        node {Algorithms for checking properties of circuits}
      }
      child {
        node {Bounded model checking using SAT solvers}
      }
      child {
        node {Unbounded model checking}
        child {
          node {K-Induktion}
        }
        child {
          node {Craig interpolation}
        }
        child {
          node {Property directed reachability (PDR)}
        }
      }
    }
    child {
      node {Equivalence checking
        \resizebox{\textwidth}{!}{
          \begin{minipage}[t]{12cm}
            \begin{itemize}
              \item Prove that two designs have the same (functional) behavior
              \item Given two combinational circuits (i.e., without memory), do they compute the same boolean function?
              \item So one can't do better in all cases, doesn't work for all practical cases, but for many:
              \begin{itemize}
                \item Combinational Equivalence Checking is NP-hard, if there would be polynomial data in a canonical datastructure one would just have to translate both circuits into this datastructure and comparison is easy, can't assume there's a datastructure with polynomial size which is canonical
                \item some function tables are so random, it's not possible to compress them
                \item canonical disjunctive normal form, then one has as many terms as elements in the ON-Set
              \end{itemize}
            \end{itemize}
          \end{minipage}
        }
      }
      child {
        node {Combinational circuits}
        child {
          node {Application of BDDs and SAT for equivalence checking
            \resizebox{\textwidth}{!}{
              \begin{minipage}[t]{12cm}
                \begin{itemize}
                  \item \alert{Equivalence Checking Method:} Convert each circuit into a datastructure that has exactly one representation of each Boolean function. Then compare these representations
                  \item in \alert{BDD-based} equivalence checking the limiting resource is the \alert{available memory}, whereas in the \alert{SAT-based} approach this is the \alert{runtime} (exponential in the size of the formula) of the solving algorithm
                  \begin{itemize}
                    \item size of the formula will be linear in the size of the circuit, so if one can get the circuit into memory, one can also get the formula into memory
                  \end{itemize}
                \end{itemize}
              \end{minipage}
            }
          }
          child {
            node {SAT-based Equivalence Checking
              \resizebox{\textwidth}{!}{
                \begin{minipage}[t]{12cm}
                  \begin{itemize}
                    \item \script{135}{Approach}
                    \item \script{139}{Miter Circuit with multiple outputs (f.)}, convert Miter Circuit into propositional logic formula with the property of being satisfied if the miter circuit outputs a $1$ and the Miter circuit has the property that it's output is $1$ for a certain input assignment if the circuits behave differently
                    \item usually SAT-algorithms take as input only CNF formulas; that means the Boolean function of the miter circuit must be translated into a CNF representation
                    \item \script{162}{Example}
                  \end{itemize}
                \end{minipage}
              }
            }
            child {
              node {Conversion of a Propositional Logic Formula into CNF
                \resizebox{\textwidth}{!}{
                  \begin{minipage}[t]{12cm}
                    \begin{itemize}
                      \item every propositional logic formula $F$ can be translated into an equivalent CNF formula $F'$
                      \begin{itemize}
                        \item \script{144}{Proof}
                      \end{itemize}
                    \end{itemize}
                  \end{minipage}
                }
              }
              child {
                node {Satisfiability equivalent CNF (Tseitin Transformation)
                  \resizebox{\textwidth}{!}{
                    \begin{minipage}[t]{14cm}
                      \begin{itemize}
                        \item it doesn't work good to turn formula into equivalent CNF formula, instead turn miter circuit into formula that is satisfiable \textit{iff} the original two circuits are not equivalent. Don't need the same output for all possible assignments, only need satisfiable \textit{iff} not equivalent. Not logically equivalent to normal CNF, 
                          \item one gives up \alert{logical equivalence} and only requires \alert{equisatisfiability} because because in the formula $X\oplus Y$ you cannot assign the output variable $Z$ in the wrong way, but in the formula $Z \equiv X \oplus Y$ you can, because of the additional variables that would not be assigned in the original formula
                        \item define for $F$ an \alert{equisatisfiable} CNF $F'$ that is satisfiable \textit{iff} $F$ is satisfiable. Every line in the circuit has variable, not only the outputs % ist satisfiable gdw. andere seite....
                        \item \script{152}{Algorithm for conversion into \alert{satisfiability equivalent} CNF}
                        \item \script{153}{Gates}
                        \item \script{155}{Example (ff.)}, satisfying assignments of the formula are exactly the consistents assignments of the circuit, all the output has to be derived using the gate function from the gate, that does not mean one gets a $1$ at the output \script{157}{Example for reason for unit clause in the last line}, all clauses satisfied but output is $0$, can only satisfy this clause if assign output of the circuit to $1$, first 3 lines say that we need a consistent assignment, the output of each gate has to match the gate function applied to the inputs and last line says output must be $1$, this formula is satisfiable \textit{iff} there's a input assignment that makes the output $1$
                        \item as long as for the CNF representation of each single gate only a constant number of clauses is required, the number of clauses in the final CNF will be linear in the number of gates in the circuit (the same holds for the size of the formula)
                        \item \script{159}{Size comparison to equivalent CNF}, linear in the size of the circuit
                      \end{itemize}
                    \end{minipage}
                  }
                }
              }
              child {
                node (convcnf) {Equivalent CNF
                  \resizebox{\textwidth}{!}{
                    \begin{minipage}[t]{14cm}
                      \begin{itemize}
                        \item \script{145}{Algorithm for conversion into \alert{equivalent} CNF}, move nots inside the formula until they only appear directly in front of variables, elimnate double negation, move ands outside with distributivity
                          \begin{itemize}
                            \item \script{148}{Examples (ff.)}, already shortest CNF for the formulas
                          \end{itemize}
                        \item \script{146}{Size of a formula}, in wost case formula increases exponentialy in size
                          \begin{itemize}
                            \item \script{147}{Proof}
                          \end{itemize}
                      \end{itemize}
                    \end{minipage}
                  }
                }
              }
            }
          }
        }
        child {
          node {Exploitation of structural information}
        }
      }
      child {
        node {Sequential circuits}
        child {
          node {Product automata}
        }
        child {
          node {Characteristic functions}
        }
        child {
          node {Image and pre-image computations}
        }
        child {
          node {BDD-based methods for proving equivalence of two sequential circuits}
        }
        child {
          node {Generation of counterexamples}
        }
      }
    }
  \end{mindmapcontent}
  \begin{edges}
    \edge{test}{middle}
  \end{edges}
  \annotation{test}{annotation}
\end{mindmap}
\end{document}
