\documentclass[landscape, a4paper]{article}

\input{./content/packages}
\input{./content/desgin}
\input{./content/declarations}

\begin{document}
\fontsize{3pt}{3pt}\selectfont

\begin{minipage}[t]{0.2\linewidth}
	\fbox{General}
	\begin{betterlist}
		\item ML \alert{replaces the agent} with a math function $f$
		\begin{betterlist}
			\item an agent whose context are \alert{features} $x$ and its decision is the \alert{target} $y$
			\item \alert{trains} $f$ from \alert{observations} $\{(x_1 , y_1), \ldots , (x_N , y_N )\}$  such that $f(x_i) \approx y_i$, $\forall i \in \{1, \ldots , N\}$
		\end{betterlist}
	\end{betterlist}
	\fbox{Supervised Learning}
	\begin{betterlist}
		\item Target is given by an expert (ground-truth)
		\item Classification, Regression, Ranking
		\item \alert{Archetype:}
		\begin{betterlist}
			\item \alert{data dimensions:} $N$ instances having $M$ features
			\item \alert{features:} $x \in \mathbb{R}^{N\times M}$ and \alert{target:} $y \in \mathbb{R}^N$
			\item \alert{prediction model:} having parameters $ \theta \in R^k$ is $f:\mathbb{R}^M\times \mathbb{R}^K \rightarrow \mathbb{R}$
			\begin{betterlist}
				\item $\hat y_n := f(x_n, \theta)$, function that predicts the target
			\end{betterlist}
			\item \alert{loss function:} $\mathcal{L}(y_n, \hat y_n): \mathbb{R}\times\mathbb{R}\rightarrow \mathbb{R}$
			\begin{betterlist}
				\item quality of a prediction model $f(x, \theta)$
				\item difference between the \alert{estimated target} $\hat y$ and \alert{ground-truth target} $y$
				\item the term loss is used for minimization tasks, e.g. regression, sometimes a maximization of $\mathcal{L}(y, \hat y)$ is needed
			\end{betterlist}
			\item \alert{regularisation:} $\Omega(\theta): \mathbb{R}^k \rightarrow \mathbb{R}$ fights overfitting to the noise of the measured data
			\item \alert{objective function:} $\displaystyle \underset{\theta}{argmin} \sum^N_{n=1} \mathcal{L}(y_n, \hat y_n) + \Omega(\theta)$
		\end{betterlist}
	\end{betterlist}
  \fbox{Prediction Models}
	\begin{betterlist}
		\item Linear Model
		\begin{betterlist}
			\item $\displaystyle \hat{y}_n=\theta_0+\theta_1 x_{n, 1}+\theta_2 x_{n, 2}+\cdots+\theta_M x_{n, M}=\theta_0+\sum_{m=1}^M \theta_m x_{n, m}$
			\item Linear Regression
			\begin{betterlist}
				\item $f\left(\mathbf{x}_i ; \mathbf{w}\right)=w_0+w_1 x_{i, 1}+\ldots+w_D x_{i, D}=w_0+w^T x_i$
				\item non-linear function can be approximated by a linear function if one maps the feature x into a new dimensionality with a \alert{basis function}: $\phi: \mathbb{R}^D\rightarrow \mathbb{R}^M$
				\item \alert{enhanced linear regression model:} linear combinations of fixed \alert{nonlinear functions} of the input variables: $\displaystyle f(x_i, \omega) = \omega_0 + \sum^{M}_{j=1} \omega_j\phi(x_i)_j$
				\begin{betterlist}
					\item $f(x, w)$ is still a \alert{linear function} of the weights / parameters $w_i$
					\item $f(x, w)$ is a \alert{nonlinear} function of the input dimensions / variables $x_i$
					\item Analytical solution
					\begin{betterlist}
						\item setting the \alert{partial derivatives} w.r.t. $w$ to zero: $\displaystyle\dfrac{\partial}{\partial \omega} \sum^N_{n=1} \mathcal{L}(y_n, f_n(x, \omega)) = 0$
						\item solving for $\omega$
					\end{betterlist}
				\end{betterlist}
			\end{betterlist}
			\item Linear Classification
			\begin{betterlist}
				\item using \alert{logistic regression} which bounds the output of linear regression to $0 \le h_w(x) \le 1$
				\begin{betterlist}
					\item e.g. $h_w(x) = g(w^Tx)$ with \alert{sigmoid} function or \alert{logistic function} $\displaystyle g(z) = \frac{1}{1 + e^{-z}}$ introduces \alert{non-linearity}
					\item $h_w(x) = P(y=1|x; \omega)$, estimated probability, that $y = 1$
				\end{betterlist}
				\item Gradient Descent
				\begin{betterlist}
					\item  if there is \alert{no analytic solution}
					\item start with a guess for $\omega$
					\item move $\omega$ towards the minimum of $J(\omega)$
					\item minimize $J(\omega)$ by updating $\omega$ in the negative direction of $\dfrac{\partial J(\omega)}{\partial\omega}$: $\displaystyle\omega^{next} \leftarrow \omega^{prev} - \eta \frac{\partial J(\omega)}{\partial\omega^{prev}} $
					\item Gradients
					\begin{betterlist}
						\item for \alert{linear regression}
						\item for \alert{logistic regression}
					\end{betterlist}
					\item Stochastic Gradient Descent
					\begin{betterlist}
						\item for \alert{large dimensions}
						\item nice if the error function is \alert{convex}
					\end{betterlist}
				\end{betterlist}
			\end{betterlist}
		\end{betterlist}
		\item Polynomial Regression
		\begin{betterlist}
			\item $\displaystyle\hat{y}_n=\theta_0+\sum_{m=1}^M \theta_m x_{n, m}+\sum_{m=1}^M \sum_{m^{\prime}=1}^M \theta_{m, m^{\prime}} x_{n, m} x_{n, m^{\prime}}+\ldots$
			\item Decision Trees
			\begin{betterlist}
				\item as a Prediction Model
				\item as a Step-wise Function
			\end{betterlist}
			\item Neural Networks
			\begin{betterlist}
				\item Composite functions, i.e., functions of functions
				\item A neuron indexed i is a non-linear function $f_i(x, \theta_i)$
				\item If neuron $i$ is connected to neuron $j$ the model is $f_j (f_i (x, \theta_i ), \theta_j)$
			\end{betterlist}
		\end{betterlist}
	\end{betterlist}
  \fbox{Generalization Performance}
		\begin{betterlist}
			\item \alert{Overfitting} (High model variance): Model perfectly fits the training data (incl. noise). Captering noise.
			\item \alert{Underfitting} (High model bias): Model fails to fit the training data. Unable to capture complexity
			\item \alert{Generalization}: Model is accurate on test data
		\end{betterlist}
    \fbox{Loss Functions}
		\begin{betterlist}
			\item Regression
			\begin{betterlist}
				\item target is real-valued $y_n\in \mathbb{R}$
				\item \alert{Least-squares:} $\mathcal{L}(y_n, \hat y_n) := (y_n - \hat y_n)^2$
				\item \alert{L1:} $\mathcal{L}(y_n, \hat y_n) := |y_n - \hat y_n|$
			\end{betterlist}
			\item Binary Classification
			\begin{betterlist}
				\item \alert{Logistic loss}, $y_n\in\{0, 1\}$:
				\begin{itemize}
					\item $J\left(h_{\mathbf{w}}\left(y_i, \mathbf{x}_i\right)\right)=\left\{\begin{array}{rll}
							-\log \left(h_{\mathbf{w}}\left(\mathbf{x}_i\right)\right)   & \text { for } & y_i=1 \\
							-\log \left(1-h_{\mathbf{w}}\left(\mathbf{x}_i\right)\right) & \text { for } & y_i=0\end{array}\right)$
					\item \alert{avoid case destinction:}\\ $\mathcal{L}(y_n, \hat y_n) := -y_n log(\hat y_n) - (1 - y_n)log(1-\hat y_n)$
					\begin{itemize}
						\item is \alert{convex}, but there's no analytic solution
					\end{itemize}
				\end{itemize}
				\item \alert{Hinge loss}, $y_n\in\{-1,1\}$:
				\begin{itemize}
					\item $\mathcal{L}(y_n, \hat y_n) := max(0, 1 - y_n\hat y_n)$
				\end{itemize}
			\end{betterlist}
			\item Multi-class Classification
			\begin{betterlist}
				\item Re-express targets $y_n \in \{1, \ldots , C\}$ as one-vs-all, i.e. $y_{n, c} := \begin{cases}
						1 & y_n = C    \\
						0 & y_n \neq C
					\end{cases}$
				\item learn model parameters per class $\theta \in \mathbb{R}^{C\times K}$
				\item Estimations expressed as probabilities among classes [...]
				\item Logloss [...]
			\end{betterlist}
		\end{betterlist}
	\fbox{Unsupervised Learning}
	\begin{betterlist}
		\item Target contains no explicit labels of the context features
		\item Clustering, Dimensionality reduction, Anomaly/Outlier Detection
	\end{betterlist}
	\fbox{Probability Theory}
	\begin{betterlist}
		\item Bayes Rule
		\begin{betterlist}
			\item assume $x_1, x_2 \ldots, x_M$ are all independent given $y$ :\\ $\begin{aligned}[t]
					P\left(y \mid x_1, x_2 \ldots, x_M\right) & =P(y) \frac{P\left(x_1, x_2 \ldots, x_M \mid y\right)}{P\left(x_1, x_2 \ldots, x_M\right)}                                         \\
					                                          & =P(y) \frac{P\left(x_1 \mid y\right) P\left(x_2 \mid y\right) \ldots P\left(x_M \mid y\right)}{P\left(x_1, x_2 \ldots, x_M\right)}
				\end{aligned}$
			\item if the goal is only to predict $y$ we can drop the denominator:\\ $P\left(y \mid x_1, x_2 \ldots, x_M\right) \propto P(y) P\left(x_1 \mid y\right) P\left(x_2 \mid y\right) \ldots P\left(x_M \mid y\right)$
			\item Naive Bayes
			\begin{betterlist}
				\item assume $x_1, x_2 \ldots, x_M$ are all independent given $y$ :\\ $\begin{aligned}[t]
						P\left(y \mid x_1, x_2 \ldots, x_M\right) & =P(y) \frac{P\left(x_1, x_2 \ldots, x_M \mid y\right)}{P\left(x_1, x_2 \ldots, x_M\right)}                                         \\
						                                          & =P(y) \frac{P\left(x_1 \mid y\right) P\left(x_2 \mid y\right) \ldots P\left(x_M \mid y\right)}{P\left(x_1, x_2 \ldots, x_M\right)}
					\end{aligned}$
				\item if the goal is only to predict $y$ we can drop the denominator:\\ $P\left(y \mid x_1, x_2 \ldots, x_M\right) \propto P(y) P\left(x_1 \mid y\right) P\left(x_2 \mid y\right) \ldots P\left(x_M \mid y\right)$
			\end{betterlist}
		\end{betterlist}
		\item Maximum Likelihood Estimation
		\begin{betterlist}
			\item \alert{likelihood} of observing the \alert{target} $y \in \mathbb{R}^N$ is $\displaystyle \mathcal{L}(\theta) = \prod^N_{n=1} \hat p(y_n | x_n, \theta)$
			\begin{itemize}
				\item $\hat p(y |x, \theta)$ is the \alert{probability density function} for the target $y$ given features $x$ and parameters $\theta$
				\item assume the error in predicting the ground truth yn is normally distributed: $\epsilon | x \sim \mathcal{N}(0, \sigma^2)$, so $\hat y \sim \mathcal{N}(\theta_0 + \sum^M_{m=1} \theta_m x_m, \sigma^2)$, because of the linear model: $\displaystyle \hat y = \theta_0 + \sum^M_{m=1} \theta_m x_m$
			\end{itemize}
			\item \alert{Aim:} Estimate the $\theta$-s which maximize the likelihood
			\begin{itemize}
				\item $\underset{\theta}{\operatorname{argmax}}\;g(\theta)=\underset{\theta}{\operatorname{argmax}}\;\log (g(\theta))$
				\item $\displaystyle log\;\mathcal{L}(\theta) = \log \prod_{n=1}^N \hat{p}\left(y_n \mid \theta\right)=\sum_{n=1}^N \log \left(\hat{p}\left(y_n \mid \theta\right)\right)$
			\end{itemize}
		\end{betterlist}
	\end{betterlist}
\end{minipage}
\begin{minipage}[t]{0.2\linewidth}
\end{minipage}
\begin{minipage}[t]{0.2\linewidth}
\end{minipage}
\begin{minipage}[t]{0.2\linewidth}
\end{minipage}
\begin{minipage}[t]{0.2\linewidth}
\end{minipage}

\newpage

\begin{minipage}[t]{0.2\linewidth}
\end{minipage}
\begin{minipage}[t]{0.2\linewidth}
\end{minipage}
\begin{minipage}[t]{0.2\linewidth}
\end{minipage}
\begin{minipage}[t]{0.2\linewidth}
\end{minipage}
\begin{minipage}[t]{0.2\linewidth}
\end{minipage}

\end{document}
