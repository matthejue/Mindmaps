\documentclass[landscape, a4paper]{article}

\input{./content/packages}
\input{./content/desgin}
\input{./content/declarations}

\begin{document}
\fontsize{3pt}{3pt}\selectfont

\begin{minipage}[t]{0.2\linewidth}
	\fbox{General} \lecturenotes{/home/areo/Documents/Studium/Semester_2_Master/Program_Verification/slides/bonus/1._Introduction.md} \additionalslides{/home/areo/Documents/Studium/Semester_2_Master/Program_Verification/slides/bonus/1._Introduction.pdf}
	\begin{betterlist}
		\item \alert{Program Verifier:} Takes program and specification and determines whether the program satisfies or if it violates the specification. Tells that in all executions of program specification holds. Also want indication of how specification is violated (i.e. counter example, e.g. inputs to violate assert statement) and also in case of yes want proof, because the program verifier itself could have a bug. \underline{Typical specifications:} No division by zero, Array only accessed within its bounds, Termination, Memory safety, No assert statement is violated
		\item \href{https://ultimate-pa.org/?ui=tool&tool=automizer}{Ultimate Automizer}
		\item \underline{Challenges:}
		\begin{enumerate}
			\item \alert{Undecidability:} The program verification problem is undecidable. There's no algorithm that verify the program and always hold (\underline{compromise:} verification algorithm that always tells correct resutl when it terminates but may not terminate or algorithm that sometimes terminates and says it could not prove the program). \underline{Solution:} Do not try to develop algorithms that solve the problem for all programs. Algorithms that solve the problem for some programs are also helpful.
			\item \alert{Ambiguities:} Different programming languages disagree what should happen for a piece of code. \underline{Solution:} Use mathematical logic to give programming languages a precise semantics
			\item \alert{Correctness Proofs are Hard to Find:} We cannot track all executions.
		\end{enumerate}
	\end{betterlist}
	\fbox{Propositional Logic (PL)} \lecturenotes{/home/areo/Documents/Studium/Semester_2_Master/Program_Verification/slides/bonus/2._Propositional_Logic.md} \additionalslides{/home/areo/Documents/Studium/Semester_2_Master/Program_Verification/slides/bonus/2._Propositional_Logic.pdf}
	\begin{betterlist}
		\item \script{29}{Syntax} and \script{31}{Semantics}, \script{32}{Examples}
		\begin{betterlist}
			\item \alert{Abbreviations:} $true := \neg false$, $(F_1 \lor F2 ) := \neg (\neg F_1 \land \neg F2)$, $(F_1 \rightarrow F2) := (\neg F_1 \lor F2)$, $(F_1 \leftrightarrow F2) := ((F_1 \rightarrow F2) \land (F2 \rightarrow F_1))$
			\item \underline{Terminology:} We call true, false \alert{atoms}, If $X \in V_{PL}$, we call $X$ an \alert{atom}, If $F$ is an atom, we call $F$ and $\neg F$ a \alert{literal}, We call the symbols $\neg$, $\wedge$, $\vee$, $\rightarrow$, $\leftrightarrow$ \alert{logical connectives}
			\item order of \alert{precedence} for logical connectives: $\neg, \land, \lor, \rightarrow, \leftrightarrow$. Binary operators are \alert{right-associative} ($F_1 \rightarrow F_2 \rightarrow F_3$ is $F_1 \rightarrow (F_2 \rightarrow F_3 )$)
		\end{betterlist}
		\item We call a PL formula $F$ \alert{satisfiable} if there is a variable assignment $\rho$ such that the evaluation $[[F]]_\rho$ is true. Otherwise, we say that $F$ is \alert{unsatisfiable}. We call a PL formula $F$ \alert{valid} if for all variable assignments $\rho$ the evaluation $[[F]]\rho$ is true
		\begin{betterlist}
			\item Deciding \alert{satisfiability} of a PL formula is an \alert{NP-complete} problem. \alert{Truth table} has problem of limited applicability, because a truth table has one row per variable assignment, and there are $2^n$ (exponential) variable assignments for $n$ variables. There are many algorithms that work well in practice and that are known to be \alert{polynomial} on relevant \alert{subclasses of PL formulas}. \alert{SAT solver} for propositional logic. \alert{SMT solver} (satisfiability modulo theories) for first order logic modulo theories
		\end{betterlist}
		\item Let $\Gamma = \{F_1, \ldots F_n\}$ be a set of PL formulas, and let $F'$ be another PL formula $F'$. We say that $\Gamma$ \alert{entails} $F'$ if for all variable assignments $\rho$ we have that if $[[F_i]]\rho = true$ holds for all $i \in \{1, \ldots n\}$, then also $[[F']]\rho = true$ holds. We use $\models$ to denote this entailment relation and we say that the entailment $\Gamma \models F'$ holds if $\Gamma$ entails $F'$. \script{38}{Examples}. Prove that $\{F_1, \ldots F_n\}$ entails $F'$:
		\begin{betterlist}
			\item truth table (Not doable if number of variables is high)
			\item prove that the PL formula $F_1 \land \ldots \land F_n \rightarrow F'$ is valid (Requires algorithm for checking validity)
			\item prove that the PL formula $\neg(F_1 \land . . . \land F_n \rightarrow F')$ is not satisfiable (Requires algorithm for checking satisfiability, implemented in SMT solvers)
			\begin{betterlist}
				\item the PL formula $F$ is valid iff the PL formula $\neg F$ is unsatisfiable. \script{39}{Proof}
			\end{betterlist}
			\item proof system
		\end{betterlist}
		\item We call two PL formulas $F_1$ and $F_2$ \alert{equivalent}, denoted $F_1 \equiv F_2$, if they evaluate to the same truth value under each variable assignment. $F_1 \equiv F_2 \text{iff} \{F_1\} \models F_2 \text{and} \{F_2\} \models F_1$
	\end{betterlist}
	\fbox{PL Proof system ($N_{PL}$)}
	\begin{betterlist}
		\item proof system for deriving valid PL entailments $\Gamma \models F$
		\item template for giving a proof. Reasoning according to a fixed number of rules. Prove once that every rule is \enquote{correct}. Check a proof $\leadsto$ check if every step is an instance of a rule. Find a proof $\leadsto$ find a sequence of rules
		\item $\mathcal{N}_{PL}$: Proof system for entailments between PL formulas. Proof rules are $(n + 1)$-ary relations over entailments denoted as: $\frac{\Gamma_1 \vDash F_1 \quad \ldots \quad \Gamma_n \vDash F_n}{\Gamma_{n+1} \vDash F_{n+1}}$.  If $\Gamma_i$ entails $F_i$ for all $i \in \{1, \ldots n\}$, then $\Gamma_{n+1}$ entails $F_{n+1}$
		\includegraphics[width=0.7\linewidth]{./figures/proof_rules.png}  (called inference rules)
		\begin{betterlist}
			\item can find a derivation and conclude that the entailment holds
		\end{betterlist}
		\item A \alert{derivation} is a tree whose nodes are labelled by entailments such that the following holds: If a node labelled by entailment $\Gamma_{n+1} \models F_{n+1}$ has children that are labelled by entailments $\Gamma_1 ⊨ F_1 \ldots \Gamma_n ⊨ F_n$, then $\frac{\Gamma_1 \vDash F_1 \quad \ldots \quad \Gamma_n \vDash F_n}{\Gamma_{n+1} \vDash F_{n+1}}$ must be an instance of some rule. \script{44}{Example}. \script{45}{Remarks (f.)}
		\begin{betterlist}
			\item  \script{48}{Example: Construction of a Derivation}, \script{49}{Guide for proving entailments (f.)}
		\end{betterlist}
		\item \alert{Theorem (Soundness of $N_{PL}$):} If a node in a derivation is labelled by $\Gamma \models F$, then the entailment $\Gamma \models F$ holds. \script{47}{Proof}
		\item \alert{Theorem (Completeness of $N_{PL}$):} If the entailment $\Gamma \models F$ holds, then there exists a derivation where the root is labelled by $\Gamma \models F$
	\end{betterlist}
	\fbox{First-Order Logic (FOL)}
	\begin{betterlist}
		\item \script{56}{Examples (f.)}
		\item \underline{syntax:} \script{58}{Vocabulary and Terms}, \script{59}{Formulas}
		\begin{betterlist}
			\item $\forall x:\phi) := \neg(\exists x:\neg\phi)$, abbreviate $\exists x1 .\exists x2 .\phi$ to $\exists x1 , x2 .\phi$ and similarly for $\forall$
			\item \alert{quantifiers:}$\exists$ and $\forall$. \alert{atoms:} $true$, $false$, and $p(t_1, \ldots, t_n)$
			\item \alert{precedence} of quantifiers is lower than the precedence of logical connectives
			\item A \script{60}{model} $M = (\mathcal{D}, \mathcal{I})$ is a pair where $\mathcal{D}$ is a nonempty set that we call \alert{interpretation domain} and $\mathcal{I}$ is a function that we call \alert{interpretation function} and that has the following properties:
			\begin{betterlist}
				\item The domain of $\mathcal{I}$ is $\mathcal{V}_{Const} \cup \mathcal{V}_{Fun} \cup \mathcal{V}_{Pred}$ (all \alert{except for $\mathcal{V}_{Var}$})
				\item $\mathcal{I}$ maps every constant symbol to an element of $\mathcal{D}$
				\item $\mathcal{I}$ maps every $n$-ary function symbol to a function from $\mathcal{D}^n$ to $\mathcal{D}$
				\item $\mathcal{I}$ maps every $n$-ary predicate symbol to an $n$-ary relation over $\mathcal{D}$, i.e., a subset of $\mathcal{D}^n$
			\end{betterlist}
			We call a function $\rho : \mathcal{V}_{Var} \rightarrow \mathcal{D}$ that maps variable symbols to elements of the interpretation domain a \alert{variable assignment}
			\item Let $f : X \rightarrow Y$ be a function whose domain is some set $X$ and whose range is some set $Y$. Let $\tilde x \in X$ and $\tilde y \in Y$, then we use $f \triangleleft \{\tilde x \rightarrow \tilde y\}$ to denote the function that maps all $x \in X\setminus \{\tilde x\}$  to $f (x)$ and that maps $\tilde x$ to $\tilde y$
			\item \underline{evaluation:} \script{61}{of terms} (returns \alert{element of domain}) and \script{62}{of formulas} (returns \alert{truth value})
		\end{betterlist}
		\item we call a formula $\varphi$ \alert{satisfiable} if there exists a model $M$ and a variable assignment $\rho$ such that $[[\varphi]]_{M,\rho} = true$. Otherwise, $\varphi$ is \alert{unsatisfiable}. We call a formula $\varphi$ \alert{valid} if $[[\varphi]]_{M,\rho} = true$ for all models $M$ and for all variable assignments $\rho$
		\begin{betterlist}
			\item $\varphi$ is valid iff $\neg \varphi$ is unsatisfiable
		\end{betterlist}
		\item given a (possibly infinite) set of FOL formulas $\Gamma$ and a FOL formula $\psi$, we say that $\Gamma$ \alert{entails} $\psi$ if for all models $M$ and for all variable assignments $\rho$ we have that if $[[\phi]]_{M,\rho} = true$ holds for all $\phi \in \Gamma$ then also $[[\psi]]_{M,\rho} = true$ holds
		\begin{betterlist}
			\item we use $\models$ to denote this entailment relation and we say that \alert{the entailment $\Gamma \models \psi$ holds} if $\Gamma$ entails $\psi$
		\end{betterlist}
		\item \script{66}{Free Variables, Bound Variables, Closed Formulas}
		\item \script{67}{Substitution}
		\begin{betterlist}
			\item \underline{notation:}
			\begin{betterlist}
				\item given a function $f$, we use $dom(f)$ to denote the domain of $f$. Given a function $f$ that maps variables to terms, we use $vars(f)$ to denote the set that contains $dom(f)$ and all variables of all terms in the range of $f$. I.e., $\displaystyle vars(f) = dom(f) \cup \bigcup_{x\in dom(f)} freevars(f(x))$
				\item if we do not want to specify the substitution function $\sigma$ separately, we write $\varphi[x_1 \mapsto t_1, \ldots, x_n \mapsto t_n ]$ instead of $\varphi\sigma$ if $\sigma$ is the function that maps $x_i$ to $t_i$ for $i \in \{1, \ldots , n\}$.
				\item we sometimes use $\varphi[x]$ to refer to a formula and a variable. We may then use in this context $\varphi[t]$ to denote $\varphi[x \mapsto t]$
			\end{betterlist}
		\end{betterlist}
	\end{betterlist}
	\fbox{FOL Proof system ($N_{FOL}$)}
	\begin{betterlist}
		\item proof system for deriving valid FOL entailments $\Gamma \models \varphi$
		\item \script{70}{$N_{FOL}$} (natural deduction for first order logic):

		\includegraphics[width=0.7\linewidth]{./figures/nfol.png}
		\begin{betterlist}
			\item two of these rules have additional \alert{side conditions} that are written right beneath the rule. A tree is only a \textit{derivation} if all side conditions are satisfied. \script{72}{All rules}
		\end{betterlist}
		\item \underline{derivation:} \script{71}{Example}
		\begin{betterlist}
			\item use derivation (this tree) as a proof
		\end{betterlist}
		\item \script{80}{When use infix notation}
	\end{betterlist}
\end{minipage}
\begin{minipage}[t]{0.2\linewidth}
	\fbox{First-Order Theories}
	\begin{betterlist}
		\item \script{81}{Motivation (pr.)}
		\item \alert{first-order theory T} consists of:
		\begin{betterlist}
			\item a signature $\Sigma$ - set of constant, function, and predicate symbols
			\item a set of axioms $A_T$ - set of closed (no free variables) $\Sigma$-formulae
		\end{betterlist}
		\item a \alert{$\Sigma$-formula} is a formula constructed of constants, functions, and predicate symbols from $\Sigma$, and variables, logical connectives, and quantifiers
		\item \underline{idea:} the symbols of $\Sigma$ are just symbols without prior meaning. The axioms of $T$ provide their meaning
		\item \alert{$T$-model:} a model $M$ is a \alert{$T$ -model}, if $[[\varphi]]_{M,\rho} = true$ for all $\varphi \in A_T$ and for all variable assignments $\rho$
		\item \alert{$T$-valid:} a $\Sigma$-formula $\varphi$ is \alert{valid in theory $T$} (\alert{$T$ -valid}), if for every $T$ -model $M$ and variable assignment $\rho$, it holds that $[[\varphi]]_{M,\rho} = true$
		\item \alert{$T$-satisfiable:} a $\Sigma$-formula $\varphi$ is \alert{satisfiable} in $T$ (\alert{$T$ -satisfiable}), if there is a $T$ -model $M$ and variable assignment $\rho$ such that $[[\varphi]]_{M,\rho} = true$
		\item \alert{$T$-equivalent:} two $\Sigma$-formulae $\varphi_1$ and $\varphi_2$ are \alert{equivalent in $T$} (\alert{$T$ -equivalent}), if $\varphi_1 \leftrightarrow \varphi_2$ is $T$ -valid
		\item \script{90}{\alert{Axiom Schemata}}
	\end{betterlist}
	\fbox{Collection of First-Order Theories and their decidability} \lecturenotes{/home/areo/Documents/Studium/Semester_2_Master/Program_Verification/slides/bonus/06._First_Order_Theories.md} \additionalslides{/home/areo/Documents/Studium/Semester_2_Master/Program_Verification/slides/bonus/06._First_Order_Theories.pdf}
	\begin{betterlist}
		\item \script{89}{Theory of Equality (pr.)}, \script{93}{Theory of Rock-Paper-Scissors (pr.)}
		\item \alert{Decidability}: We call a problem \alert{decidable} if there exists an algorithm that terminates on all instances of the problem and gives a correct yes/no answer.
		\begin{betterlist}
			\item \uline{example undecidable problem:} Halting Problem for Turing machines, \uline{prove decidability:} give an algorithm and prove its correctness, \uline{prove undecidability:} reduction from a known undecidable problem
			\item \alert{Satisfiability} of PL formulas is \alert{decidable}, \alert{Satisfiability} of FOL formulas is \alert{undecidable}
			\item \alert{$T_{E}$-validity} is \alert{undecidable}, For a \alert{quantifier-free formula $T_E$-validity} is \alert{decidable}
			\item \script{100}{Peano Arithmetic $T_{PA}$ (first-order arithmetic) (ff.)}: natural numbers with addition and multiplication
			\begin{betterlist}
				\item \script{101}{Definition of $\le$ etc.}, \script{102}{$EXP[x, n, r]$}
				\item \alert{$T_{PA}$} is \alert{undecidable}, \alert{quantifier-free fragment of $T_{PA}$} is \alert{undecidable}
				\item \script{103}{\alert{Gödel’s first incompleteness theorem}}: \uline{Peano arithmetic $T_{PA}$ does not capture true arithmetic:} There exist closed $\Sigma_{PA}$-formulae representing valid propositions of number theory that are not $T_{PA}$-valid. \uline{The reason:} $T_{PA}$ actually admits nonstandard interpretations. \underline{For decidability:} \alert{no multiplication}
			\end{betterlist}

			\item \script{104}{Presburger Arithmetic $T_{\mathbb{N}}$}: natural numbers with addition
			\begin{betterlist}
				\item \alert{$T_{\mathbb{N}}$-satisfiability} and \alert{$T_{\mathbb{N}}$-validity} are \alert{decidable}
			\end{betterlist}
			\item \script{106}{Theory of Integers $T_{\mathbb{Z}}$ (pr.)}: integers with $+$, $−$, $>$
			\begin{betterlist}
				\item \alert{$T_{\mathbb{Z}}$-satisfiability} and \alert{$T_{\mathbb{Z}}$-validity} are \alert{decidable}
			\end{betterlist}
			\item \script{108}{Theory of Arrays $T^=_A$ (with extensionality)}, \script{109}{Theory of Bit-vectors (f.)}, \script{111}{Theory of Floats}
			\item \script{113}{Overview decidability}
		\end{betterlist}
	\end{betterlist}
	\fbox{SMT-LIB} \lecturenotes{/home/areo/Documents/Studium/Semester_2_Master/Program_Verification/slides/bonus/07._Boogie_and_Boostan.md} \additionalslides{/home/areo/Documents/Studium/Semester_2_Master/Program_Verification/slides/bonus/07._Boogie_and_Boostan.pdf}
	\begin{betterlist}
		\item \script{117}{What it is}, \script{118}{SMT Script}, \script{119}{Theories}, \script{122}{Logics (f.)}
		\item \script{124}{Terms definined in lecture and SMT-LIB (pr.)}, \script{126}{Terms (pr.)}
		\item \script{127}{Links to solvers}
		\item \script{129}{Commands (pr.)}
	\end{betterlist}
	\fbox{Boogie and Boostan Syntax}
	\begin{betterlist}
		\item \script{138}{Boogie and Boogaloo (prr.)}, \script{139}{Examples (f.)}, \script{141}{Options}
		\item \script{142}{Boostan}
		\item \script{146}{Context-free grammar}, \script{147}{Derivation tree}, \script{148}{Derived word}
		\item \script{152}{Grammar for Numbers}, \script{153}{Grammar for Variables}, \script{154}{Grammar for Integer Expressions}, \script{156}{Grammar for Boolean Expressions}, \script{157}{Grammar for Statements}
		\begin{betterlist}
			\item \underline{we call}: A subword that is derived from $X_{var}$ a (program) \alert{variable}, A subword that is derived from $X_{iexpr}$ or $X_{bexpr}$ an \alert{expression}, A subword that is derived from $X_{stmt}$ a (program) \alert{statement}
		\end{betterlist}
	\end{betterlist}
	\fbox{(Boogie and) Boostan Semantics}
	\begin{betterlist}
		\item \color{orange}A \script{159}{\alert{Boostan program}} is a triple $P = (V , \mu , T)$ where,
		\begin{betterlist}
			\item $V$ is a set of (program) variables,
			\item $\mu$  is a map that assigns each variable in V either Z or \{ true, false\}
			\item $T$ is a derivation tree for the start symbol SBoo in the Boostan grammar
		\end{betterlist}
		such that all variables that appear in T are in the set V, and the translation of each expression/type to an SMT term/sort is well-sorted wrt. the map $\mu$\color{black}
		\item \script{161}{Problem with C Semantics (ff.)}
		\item \script{167}{Relational semantics (f.)}
		\item \color{orange}Given a program $P = (V , \mu, \mathcal{T})$, a \script{169}{\alert{program state}} is a map that assigns each variable $v \in V$ a value of the variable’s domain. We use $S_{V, \mu}$ to denote the set of all program states\color{black}
		\begin{betterlist}
			\item \color{orange}Given a program $P = (V, \mu, \mathcal{T})$ and a formula $\varphi$ whose free variables are a subset of $V$, then we will use $\{\varphi\}$ to denote the \script{179}{\alert{set of states}} that are a satisfying assignment for $\varphi$. $\{ \varphi \}  := \{ s \in S_{V ,\mu} \mid [[\varphi ]]_{M,s} = true\}$ (\script{170}{Sets of Program States (first mentioned)})\color{black}
		\end{betterlist}
		\item \script{171}{Semantics of Expressions}
		\begin{betterlist}
			\item \underline{idea:} Assign each expression an SMT formula. Given an expression $expr$, we define the semantics of the expression, denoted $[[expr]]$ as the SMT formula that is denoted by the same string
			\item \script{171}{Exceptions}
			\item \script{179}{Meaning of $\{\varphi\}$ depending on context}, \script{179}{Convention: Omit double brackets} (\script{171}{Convention $expr$ instead of $[[expr]]$} (first mentioned))
		\end{betterlist}
		\item \script{172}{Semantics of the Assignment Statement (f.)}
		\begin{betterlist}
			\item \color{orange}\script{172}{prime} is the function that takes a state $s$ and returns a map where every variable $x$ in the domain of $s$ is replaced by $x'$. E.g., $prime(\{a \mapsto 23, b \mapsto 42\})$ is $\{a' \mapsto 23, b' \mapsto 42\}$\color{black}
		\end{betterlist}

		\item \script{178}{Semantics of the Concatenation of Statements}
		\begin{betterlist}
			\item \script{177}{Relational Composition}
		\end{betterlist}
		\item \script{180}{Semantics of the If-then-else Statement}
		\item \script{183}{Semantics of the While Statement}
		\begin{betterlist}
			\item \script{181}{Reflexive Transitive Closure} and \script{182}{Example}
		\end{betterlist}
		\item \script{184}{Full Example (f.)}
	\end{betterlist}
	\fbox{Hoare Proof System}
	\begin{betterlist}
		\item proof system for deriving valid Hoare triples $\{\varphi\} st \{\psi\}$
		\item \color{orange}a program $P$ \alert{satisfies the precondition-postcondition pair} $(\{\varphi_{pre}\}, \{\varphi_{post}\})$ if the inclusion $post(\{\varphi_{pre}\}, [[st]]) \subseteq \{\varphi_{post}\}$ holds (\script{189}{Precondition-Postcondition Pairs})\color{black}
		\begin{betterlist}
			\item given a binary relation $R$ over the set $X$ and a subset of $Y \subseteq X$, the \alert{postimage of $Y$ under $R$},
			denoted $post(Y , R)$, is the set $\{x \in X \mid \text{ exists } y \in Y \text{ such that } (y, x) \in R\}$. \script{190}{Example}
			\item \script{191}{Full Example}
		\end{betterlist}
		\item given a set of states $\{\varphi\}$, a program statement $st$ and a set of states $\{\psi\}$, we call the triple $\{\varphi\} st \{\psi\}$ a \alert{Hoare triple}
		\item \color{orange}we call a Hoare triple $\{\varphi\} st \{\psi\}$ \alert{valid} if $st$ satisfies the precondition-postcondition pair $(\{\varphi\}, \{\psi\})$. \script{197}{Example}\color{black}
		\item \underline{\script{200}{Rules}:}

		\includegraphics[width=0.7\linewidth]{./figures/hoare_rules.png}
		\begin{betterlist}
			\item \script{202}{Example: Assignment axiom}
			\item \script{203}{Example: Conditional Rule}
			\item \script{204}{Example: While Rule}
			\item \script{205}{Full Example}
		\end{betterlist}
		\item we define a \alert{derivation} as a tree whose nodes are labelled by Hoare triples such that the following holds. If a node that is labelled by a Hoare triple $\{\varphi_{n+1}\} st_{n+1} \{\psi_{n+1}\}$ has children that are labelled by Hoare triples $\{\varphi_1\} st_1 \{\psi_1\} \ldots \{\varphi_n\} st_n \{\psi_n\}$, then the following must be an instance of some rule: $\frac{\{\varphi_1\} st_1 \{\psi_1\} \ldots \{\varphi_n\} st_n \{\psi_n\}}{\{\varphi_{n+1}\} st_{n+1} \{\psi_{n+1}\}}$ (\script{201}{Derivation in context hoare proof system})
		\item \alert{Soundness of the Hoare Proof System:} If there is a derivation whose root is labelled by $\{\varphi\} st \{\psi\}$, then the statement $st$ satisfies the precondition-postcondition pair $(\{\varphi\}, \{\psi\})$
		\begin{betterlist}
			\item we call a rule of the form $\frac{\{\varphi_{1}\} st_{1} \{\psi_{1}\} \ldots \{\varphi_{n}\} st_{n} \{\psi_{n}\}}{\{\varphi_{n+1}\} st_{n+1} \{\psi_{n+1}\}}$ \alert{sound} if the following holds: If for all $i \in\{1, \ldots, n\}$ the Hoare triple ${\varphi_i} st_i {\psi_i}$ is valid, then the Hoare triple ${\varphi_{n+1}} st_{n+1} {\psi_{n+1}}$ is also valid. (\script{209}{Sound rule})
			\item \script{210}{Soundness of the Assignment Axiom}
			\item \script{211}{Soundness of the Composition Rule}
			\item \script{212}{Soundness of the Strengthen Precondition Rule}
			\item \script{213}{Soundness of the Weakening Postcondition Rule}
			\item \script{214}{Soundness of the Conditional Rule}
			\item \script{215}{Soundness of the While Rule (ff.)}
			\item \script{218}{Soundness of the Hoare Proof System (f.)}
		\end{betterlist}
	\end{betterlist}
\end{minipage}
\begin{minipage}[t]{0.2\linewidth}
	\fbox{Boostan Extended Syntax}
	\begin{betterlist}
		\item \script{242}{Arrays}
		\begin{betterlist}
			\item \script{243}{SMT-LIB}
			\item \script{244}{Memory via Arrays}
			\item \script{249}{Grammar}
		\end{betterlist}
		\item \script{255}{Havoc Statement (f.)}
		\begin{betterlist}
			\item \href{https://www.microsoft.com/en-us/research/wp-content/uploads/2016/12/krml178.pdf}{\inlinebox{Section 9.4 of Specification}}
			\item \script{258}{Grammar}
		\end{betterlist}
		\item \script{264}{Assume Statement}
		\begin{betterlist}
			\item \href{https://www.microsoft.com/en-us/research/wp-content/uploads/2016/12/krml178.pdf}{\inlinebox{Section 9.2 of Specification}}
			\item \script{266}{Grammar}
		\end{betterlist}
		\item Assert Statement
		\begin{betterlist}
			\item \script{436}{Grammar}
		\end{betterlist}

	\end{betterlist}
	\fbox{Boostan Extended Semantics}
	\begin{betterlist}
		\item \script{250}{Arrays}
		\item \script{259}{Havoc Statement}
		\item \script{267}{Assume Statement}
	\end{betterlist}
	\fbox{Hoare Proof System Extended}
	\begin{betterlist}
		\item \underline{Rules:}

		\includegraphics[width=0.5\linewidth]{./figures/arrassig.png}

		\includegraphics[width=0.325\linewidth]{./figures/havoc.png}

		\includegraphics[width=0.4\linewidth]{./figures/assu.png}
		\begin{betterlist}
			\item \script{252}{Soundness of the Array Assignment Axiom}
			\item \script{261}{Soundness of the Havoc Axiom}
			\item \script{269}{Soundness of the Assume Axiom}
		\end{betterlist}
	\end{betterlist}
	\fbox{Ultimate Referee}
	\begin{betterlist}
		\item \script{227}{Guide for Finding a Derivation in the Hoare Proof System}
		\item \script{230}{What it is and example (ff.)}
		\item \script{233}{Interactive verification, Deductive verification, Automated verification}
	\end{betterlist}
	\fbox{Control-flow graphs}
	\begin{betterlist}
		\item \color{orange}A \script{279}{\alert{control-flow graph}} is a tuple $G = (Loc, \Delta, \ell_{init}, \ell_{ex})$ where
		\begin{betterlist}
			\item $Loc$ is a finite set whose elements we call \alert{locations},
			\item $\Delta$ is a ternary relation that consists of triples $(\ell , st, \ell ')$ where $\ell$ and $\ell'$  are locations, and $st$ is either
			\begin{betterlist}
				\item an assignment statement,
				\item an array assignment statement,
				\item a havoc statement, or
				\item an assume statement.
			\end{betterlist}
			\item $\ell_{init}$ is a location that we call the \alert{initial location}
			\item $\ell_{ex}$ is a location that we call the \alert{exit location}
		\end{betterlist}\color{black}
		\item Given a program $P = (V , \mu , st)$ we say that a control-flow graph $G$ is a \script{279}{\alert{Control-Flow Graph for a Program}} $P$ if $G$ is a control-flow graph for st (which we define inductively below). \script{280}{Example}
		\begin{betterlist}
			\item \alert{Control-Flow Graph for Simple Statements}:
			\begin{betterlist}
				\item Let $st$ be
				\begin{betterlist}
					\item an assignment statement,
					\item an array assignment statement,
					\item a havoc statement, or
					\item an assume statement,
				\end{betterlist}
				then $G = (Loc, \Delta , \ell_{init}, \ell_{ex})$ such that
				\begin{betterlist}
					\item $Loc = \{ \ell_{init}, \ell_{ex}\}$,
					\item $\Delta = \{ (\ell_{init}, st, \ell_{ex})\}$, and
					\item $\ell_{init} \ne  \ell_{ex}$
				\end{betterlist}
				is a control-flow graph for $st$
			\end{betterlist}
			\item \underline{useful for automated verification:} apply algorithms from graph theory / automata theory
			\item captures only one aspect of a program, it defines the way in which the programmer arranged the statements in the code
			\item focused solely on the program’s data but it is not sufficient to specify the situation in which a program currently is, because the state does not provide information about the next statements that can be executed
			\item \script{281}{Notational Conventions}
			\item all control-flow graphs for a given statement are \alert{isomorphic} to each other
		\end{betterlist}
		\item \script{282}{Sequential Composition}, \script{283}{Illustration}
		\item \script{284}{Conditional Statement}, \script{285}{Illustration}
		\item \script{286}{While Statement}, \script{287}{Illustration}
		\item \color{orange}we call a pair $(\ell, s)$ a \alert{program configuration} of $P$ if $\ell \in Loc$ is a location and $s$ is a state of $P$\color{black}
		\item \color{orange}we call a sequence of program configurations $(\ell_0, s_0), . . . , (\ell_n, s_n)$ an \alert{execution} of $P$ if there exists a sequence of statements (a trace) $st_1 \ldots st_n$ such that for each $i \in \{0, \ldots, n−1\}:$ $(\ell_i, st_{i+1}, \ell_{i+1}) \in \Delta$ and $(s_i, s_{i+1}) \in [[st_{i+1}]]$. \script{292}{Example}\color{black}
		\begin{betterlist}
			\item Executions do not have to start at the initial location and do not have to end at the exit location
		\end{betterlist}
		\item \color{orange}we call the program configuration $(\ell, s)$
		\begin{betterlist}
			\item \alert{initial}, if $\ell= \ell_{init}$ and $s \in\{\varphi_{pre}\}$
			\item an \alert{error configuration} if $\ell= \ell_{ex}$ and $s \not\in \{\varphi_{post}\}$
		\end{betterlist}\color{black}
		\item \color{orange}\alert{Theorem PppSatAndExec:} The program $P = (V, \mu, st)$ satisfies the precondition-postcondition pair $(\varphi_{pre}, \varphi_{post})$ iff there exists no execution $(\ell_0, s_0), \ldots, (\ell_n, s_n)$ such that $(\ell_0, s_0)$ is an initial configuration and $(\ell_n, s_n)$ is an error configuration\color{black}
		\begin{betterlist}
			\item so far we only had one way to formally show that $(\varphi_{pre}, \varphi_{post})$ is not satisfied: compute the binary relation over states for this program to check if every pair satisfies the precondition-postcondition pair. By Theorem PppSatAndExec we now have an alternative within our formal setting: we can give an execution
			\item \script{296}{Example program that shows need for Theorem CorrectIffNoErrorReach}
			\item \underline{Proof via lemma \alert{RelAndExec}:} Let $G = (Loc, \Delta, \ell_{init}, \ell_{ex})$ be a control-flow graph for $st$, then there exists a program execution $(\ell_0, s_0), . . . , (\ell_n, s_n)$ with $\ell_0 = \ell_{init}$ and $\ell_n = \ell_{ex}$, iff $(s_0, s_n) \in [[st]]$
			\begin{betterlist}
				\item Proof by induction over the height of st’s derivation tree. Using the following five lemmas, the proof can be carried out analogously to the soundness proof for the Hoare proof system:
				\begin{betterlist}
					\item \script{303}{Single assignment, array, havoc or assume statement}
					\item \script{304}{Sequential composition of statements}
					\item \script{305}{Conditional statement}
					\item \script{306}{While Statement (ff.)}
				\end{betterlist}
			\end{betterlist}
			\item The theorem Theorem PppSatAndExec follows directly from 1) the lemma Lemma RelAndExec, 2) the definition of an error configuration, and 3) the definition of satisfiability of precondition-postcondition pairs
		\end{betterlist}
		\item \alert{Reachable Program Configuration:} We call a configuration $(\ell, s)$ \alert{reachable} if there exists a program execution $(\ell_0, s_0), . . . , (\ell_n, s_n)$ such that $(\ell_0, s_0)$ is an initial configuration and $(\ell_n, s_n) = (\ell, s)$
		\item \alert{Theorem CorrectIffNoErrorReach:} A program satisfies a given precondition-postcondition pair iff the set of reachable configurations does not contain an error configuration
		\item the \alert{set of reachable configurations $RC$} is the smallest set such that
		\begin{betterlist}
			\item each initial configuration is an element of RC
			\item if $(\ell, s) \in RC$, $(\ell, st, \ell') \in \Delta$ and $(s, s') \in [[st]]$ then $(\ell', s') \in RC$
		\end{betterlist}
		\item \color{orange}the \alert{reachability graph} is a pair $(RC, T)$ such that $((\ell, s), st, (\ell', s')) \in T$ iff $(\ell, st, \ell') \in \Delta$ and $(s, s') \in [[st]]$\color{black}
		\begin{betterlist}
			\item \script{362}{Algorithm}
		\end{betterlist}
		\item \alert{Timestamps:} Each thread maintains a timestamp, We represent a timestamp as a natural number, Each time we process an event we increase the thread’s timestamp, Initially, the timestamp for each thread is $1$
		\begin{betterlist}
			\item \script{111}{Example}
		\end{betterlist}
	\end{betterlist}
\end{minipage}
\begin{minipage}[t]{0.2\linewidth}
	\fbox{Predicate Transformers}
	\begin{betterlist}
		\item main means for analyzing the effect of statements in the control-flow graph-based view on programs
		\item programs with more than one initial state, execute a loop-free program symbolically (i.e., on all inputs in parallel). Set of all states that are reachable after each of the statements. User formulas whose satisfying variable assignments are exactly the reachable sets of states. Define the \alert{strongest post predicate transfomer} which allows to compute these formulas
		\item \color{orange}\alert{Strongest Postcondition:} Given a set of states $S$ and a statement $st$ the strongest postcondition is the post image of $S$ under the relation $[[st]]$, i.e. $sp(S, st) = post(S, [[st]])$
		\begin{betterlist}
			\item \underline{Idea:} Given a set of states $S$ and a statement \verb|st|, the strongest postcondition $sp(S, \verb|st|)$ is the set of states for which the following holds. If there is a state $s \in S$
			\begin{betterlist}
				\item in which we can execute \verb|st|,
				\item in which \verb|st| terminates, and
				\item $s'$ is a successor after executing \verb|st|
			\end{betterlist}
			then $s' \in sp(S, \verb|st|)$\color{black}
			\item \color{orange}\alert{Assignment Statement:} $sp(\{\varphi\}, \verb|x := expr;| )$ is $\{\exists \hat x:\varphi[x \mapsto \hat x] \land x = expr[x \mapsto \hat x]\}$. \script{332}{Proof} and \script{333}{Example}
			\item \alert{Havoc Statement:} $sp(\{\varphi\}, \verb|havoc x;| )$ is $\{\exists x:\varphi\}$. \script{334}{Proof idea}
			\item \alert{Assume Statement:} $sp(\{\varphi\}, \verb|assume expr;| )$ is $\{\varphi \land expr\}$. \script{335}{Proof}
			\item \alert{Sequential Composition:} If $st$ is an sequential composition of the form $st_1st_2$, then $sp(S, st)$ is $sp(sp(S, st_1), st_2)$. \script{336}{Proof}
			\item \alert{Conditional Statement:} $sp(\{\varphi\}, \verb|if (expr) { st1 } else { st2 }|)$ is $sp(sp(S, \verb|assume expr;|), \verb|st1|)\cup sp(sp(S, \verb|assume !expr;|), \verb|st2|)$
			\item In general, we cannot express the strongest post of the \alert{while statement} as a formula
			\begin{betterlist}
				\item If \verb|st| is a while statement of the form \verb|while(expr){st}| then $sp(S, \verb|st|)$ is $\displaystyle \bigcup_{k\in \mathbb{N}} sp(sp^k(S, \verb|assume expr; st|), \verb|assume !expr;| )$
				\begin{betterlist}
					\item \uline{$k$-th iterative application of the strongest post operator:}\\ $s p^k(S, s t)= \begin{cases}S & \text { if } k=0 \\ s p\left(s p^{k-1}(S, s t), s t\right) & \text { if } k>0\end{cases}$
				\end{betterlist}\color{black}
				\item There are \script{340}{examples} in which the strongest post of a while statement can be expressed by a formula
			\end{betterlist}
			\item \script{318}{Example 1} and \script{338}{Example 2}
		\end{betterlist}
		\item \alert{Quantifier Elimination:} Finding an equivalent quanfitier-free formula for a given formula
		\begin{betterlist}
			\item \alert{Destructive Equality Resolution 1:} If the variable $x$ does not occur in the term $t$ then the formula $\exists x:\varphi \land x = t$ and the formula $\varphi[x \mapsto t]$ are equivalent. \script{328}{Example and proof idea}
			\item \alert{Destructive Equality Resolution 2:} If the variable $x$ does not occur in the term $t$ then the formula $\forall x:\varphi \lor x \ne t$ and the formula $\varphi[x\mapsto t]$ are equivalent. \script{329}{Proof idea}
		\end{betterlist}
		\item Let $st$ be a statement, and let $\varphi$, $\psi$ be formulas. The following statements are equivalent:
		\begin{betterlist}
			\item $\{\varphi\} st \{\psi\}$ is a valid Hoare triple
			\item $sp(\{\varphi\}, st) \subseteq \{\psi\}$
			\item $\{\varphi\} \subseteq wp(\{\psi\}, st)$
		\end{betterlist}
	\end{betterlist}
	\fbox{Bounded Model Checking}
	\begin{betterlist}
		\item \color{orange}an \alert{abstract (program) configuration} is a pair $(\ell, \{\varphi\})$ where $\ell$ is a location and $\varphi$ is a formula over the program’s variables\color{black}
		\item \color{orange}an \alert{abstract reachability graph} is a graph $(AC, T)$ where AC is a set of abstract configurations and $T ⊆AC × Stmt × AC$, such that
		\begin{enumerate}
			\item for each edge $((\ell, {\varphi}), st, (\ell', \{\varphi'\})) \in T$, we have $(\ell, st, \ell') \in \Delta$ and $sp(\{\varphi\}, st) \subseteq \{\varphi'\}$,
			\item for each abstract configuration $(\ell, \{\varphi\}) \in AC$ with $\varphi\not\equiv false$ and $(\ell, st, \ell') \in ∆$, there exists an abstract configuration $(\ell', \{\varphi'\}) \in AC$ such that $((\ell, \{\varphi\}), st, (\ell', \{\varphi'\})) \in T$,
			\item there exists $(\ell_{init}, \{\varphi_{init}\}) \in AC$ with $\{\varphi_{pre}\} \subseteq \{\varphi_{init}\}$, and
			\item for each abstract configuration $(\ell, \{\varphi\}) \in AC$ there is a path from $(\ell_{init}, \{\varphi_{init}\})$ to $(\ell, \{\varphi\})$, using edges in $T$
		\end{enumerate}\color{black}
		\begin{betterlist}
			\item \color{orange}we call an abstract reachability graph for G a \alert{safety proof} if is does not contain an abstract error configuration\color{black}
			\begin{betterlist}
				\item \script{372}{Example}
			\end{betterlist}
		\end{betterlist}
		\item \color{orange}a \alert{precise abstract reachability graph} is an abstract reachability graph $(AC, T)$ such that for each edge $((\ell, \{\varphi\}), st, (\ell', \{\varphi'\}))$ the equality $sp(\{\varphi\}, st) = \{\varphi'\}$ holds, and $\{\varphi_{init}\} = \{\varphi_{pre}\}$\color{black}
		\begin{betterlist}
			\item a precise abstract reachability graph for a given control-flow graph is unique up to the formulas that represent the set of states at each location
			\item \script{354}{Example: Implementation of the GCD (pr.)}. None of the three tests shows a violation of the postcondition. If one starts to build the precise abstract reachability graph, one sees after a few iterations that there is an abstract program configuration whose set of states is not a subset of the postcondition
			\item \script{363}{Algorithm}
			\begin{betterlist}
				\item \script{364}{Modifications}
			\end{betterlist}
		\end{betterlist}
		\item \color{orange}Let $(\varphi_{pre}, \varphi_{post})$ be a precondition-postcondition pair. We call an abstract configuration $(\ell, \{\varphi\})$ an \alert{abstract error configuration} if $\ell$ is the exit location and the inclusion $\{\varphi\} \subseteq \{\varphi_{post}\}$ does not hold. \script{355}{Example}\color{black}
		\item \underline{Lemma:} The set of reachable configurations contains an error configuration \alert{iff} the precise abstract reachability graph for $G$ contains an abstract error configuration
		\begin{betterlist}
			\item $G$ is a control-flow graph for $P$
		\end{betterlist}
		\item \underline{Theorem:} Let $(\varphi_{pre}, \varphi_{post})$ be a precondition-postcondition pair. The program $P$ satisfies $(\varphi_{pre}, \varphi_{post})$ iff the precise abstract reachability graph for $G$ does not contain an abstract error configuration
	\end{betterlist}
	\fbox{Abstract Interpretation}
	\begin{betterlist}
		\item given a set $X$, a partial order is a binary relation $\sqsubseteq$ that is
		\begin{betterlist}
			\item reflexive (for any $x \in X$, $x \sqsubseteq x$ holds),
			\item antisymmetric, (if $x \sqsubseteq y$ and $y \sqsubseteq x$ then $x = y$) and
			\item transitive (if $x \sqsubseteq y$ and $y \sqsubseteq z$ then $x \sqsubseteq z$)
			\item \script{381}{Examples}
		\end{betterlist}
		\item Let $X$ be a set, $\sqsubseteq$ some partial order over $X$ and $M \subseteq X$ be a subset
		\begin{betterlist}
			\item we call $x \in X$ a \alert{lower bound} for $M$ if $x \sqsubseteq m$ for all $m \in M$
			\item we call a lower bound $y$ the \alert{greatest lower bound} for $M$ if for each lower bound $x$ of / for? $M$ the inequality $x \sqsubseteq y$ holds
			\begin{betterlist}
				\item we use $\sqcap M$ to denote the \alert{greatest lower bound}. If $M = \{x, y\}$ we may also write $x \sqcap y$
			\end{betterlist}
			\item we call $x \in X$ an \alert{upper bound} for $M$ if $m \sqsubseteq x$ for all $m \in M$
			\item we call an upper bound $y$ the \alert{least upper bound} for $M$ if for each upper bound $x$ of / for? $M$ the inequality $y \sqsubseteq x$ holds
			\begin{betterlist}
				\item we use $\sqcup M$ to denote the \alert{least upper bound}. If $M = \{x, y\}$ we may also write $x \sqcup y$
			\end{betterlist}
		\end{betterlist}
		\item a \alert{complete lattice} is a tuple (L, \sqsubseteq ) such that
		\begin{betterlist}
			\item $L$ is a set,
			\item $\sqsubseteq $ is a \alert{partial order} over $L$,
			\item every subset $M$ of $L$ has a \alert{greatest lower bound} $\sqcap M$ w.r.t. $\sqsubseteq$
			\item every subset $M$ of $L$ has a \alert{least upper bound} $\sqcup M$ w.r.t. $\sqsubseteq$
			\item \script{383}{Examples}
		\end{betterlist}
		\item \alert{Monotonicity:} Given partially ordered sets $(X, \sqsubseteq_X)$ and $(Y, \sqsubseteq_Y)$, we call a function $f:X\rightarrow Y$ \alert{monotone} if for all $x_1, x_2 \in X$ the inequality $x_1 \sqsubseteq_X x_2$ implies $f(x_1) \sqsubseteq_Y f(x_2)$
		\begin{betterlist}
			\item \script{385}{Examples}
		\end{betterlist}
		\item \color{orange}\alert{Galois connection:} Let $(A, \sqsubseteq_A)$ and $(B, \sqsubseteq_B)$ be partially ordered sets, and let $F : A \rightarrow B$ and $G : B \rightarrow A$ be functions. The pair $(F, G)$ is a Galois connection for $(A, \sqsubseteq_A)$ and $(B, \sqsubseteq_B)$ if for all $a \in A$ and $b \in B$ it holds that $F(a) \sqsubseteq_B b$ iff $a \sqsubseteq_A G(b)$\color{black}
		\item \color{orange}\alert{GaloisProp:} If $(F, G)$ is a \alert{Galois connection} for $(A, \sqsubseteq A)$ and $(B, \sqsubseteq B)$, then:
		\begin{betterlist}
			\item $F$ and $G$ are \alert{monotone},
			\item $a \sqsubseteq_A G(F(a))$ holds for all $a \in A$, and
			\item $F(G(b)) \sqsubseteq_B b$ holds for all $b \in B$
			\item \script{394}{Proof}
		\end{betterlist}\color{black}
		\item \color{orange}an \alert{abstract domain} is a tuple $(\mathbb{A}, \sqsubseteq, \gamma, \alpha)$, such that
		\begin{betterlist}
			\item $(\mathbb{A}, \sqsubseteq)$ is a complete lattice
			\item $(\alpha, \gamma)$ is a Galois connection for $(\mathbb{A}, \sqsubseteq)$ and $(2^{S_{V ,\mu}}, \subseteq)$
			\item \underline{Sidenotes:}
			\begin{betterlist}
				\item we call elements of $\mathbb{A}$ \alert{abstract states}, $\gamma$ the \alert{concretization function}, and $\alpha$ the \alert{abstraction function}
				\item an abstract state $s^\# \in \mathbb{A}$ represents the set of concrete states $\gamma(s^\#)$
				\item for a set $S \subseteq S_{V,\mu}$, the abstract state $\alpha(S)$ is the abstraction of $S$
				\item the relation $\sqsubseteq$ orders abstract states from \enquote{less abstract} to \enquote{more abstract}
				\item \underline{properties:}
				\begin{betterlist}
					\item by Lemma GaloisProp, $\gamma$ is monotone. This means that $s^\#_1 \sqsubseteq s^\#_2$ implies $\gamma(s^\#_1) \subseteq \gamma(s^\#_2)$
					\item by Lemma GaloisProp, $\alpha$ is monotone. This means that $S_1 \subseteq S_2$ implies $\alpha(S_1) \sqsubseteq \alpha(S_2)$
					\item by condition $2$ of Lemma GaloisProp, we have $S \subseteq \gamma(\alpha(S))$
					\item by condition $3$ of Lemma GaloisProp, we have $\alpha(\gamma(s^\#)) \sqsubseteq s^\#$
				\end{betterlist}
			\end{betterlist}
			\item \script{389}{Examples (ff.)}
		\end{betterlist}\color{black}
		\item \color{violet}An \alert{abstract post operator} $post^\#$ for an abstract domain $(\mathbb{A}, \sqsubseteq, \gamma, \alpha)$ is a monotone function that takes an abstract state $s^\# \in \mathbb{A}$ and a simple statement $st$ and returns a new abstract state, such that the following holds: $sp(\gamma(s^\#), st) = post(\gamma(s^\#), [[st]]) \subseteq \gamma(post^\#(s^\#, st))$\color{black}
		\begin{betterlist}
			\item \script{392}{Illustration}
			\item \script{393}{Example}
		\end{betterlist}
		\item \color{orange}\alert{Value abstraction (Towards Non-relational Domains):} A value abstraction for a set of values $\mathbb{V}$ is a tuple $(A_{\mathbb{V}}, \sqsubset_{\mathbb{V}}, \gamma_{\mathbb{V}}, \alpha_{\mathbb{V}})$ such that:
		\begin{betterlist}
			\item $(A_{\mathbb{V}}, \sqsubseteq_{\mathbb{V}})$ is a complete lattice
			\item $(\alpha_{\mathbb{V}}, \gamma_{\mathbb{V}})$ is a Galois connection for $(A_{\mathbb{V}}, \sqsubseteq_{\mathbb{V}})$ and $(2^{\mathbb{V}}, \subseteq)$
		\end{betterlist}\color{black}
		\item \script{396}{Sign abstraction}
		\begin{betterlist}
			\item \script{401}{Abstract Evaluation}
			\item sign abstraction satisfies ACC
		\end{betterlist}
		\item \script{398}{Explicit-Value Domain}
		\begin{betterlist}
			\item explicit-value abstraction satisfies ACC
		\end{betterlist}
	\end{betterlist}
\end{minipage}
\begin{minipage}[t]{0.2\linewidth}
	\begin{betterlist}
		\item \script{399}{Interval Domain}
		\begin{betterlist}
			\item \script{402}{Abstract Evaluation}
			\item interval abstraction does not satisfy ACC
			\item \color{orange}A \alert{widening operator} for an abstract domain $(\mathbb{A}_S, \sqsubseteq, \alpha, \gamma)$ is a binary operator $\triangledown$ on abstract states such that
			\begin{betterlist}
				\item for all $s^\#_1, s^\#_2 \in \mathbb{A}_S$, we have $\gamma(s^\#_1) \cup \gamma(s^\#_2) \subseteq \gamma(s^\#_1 \triangledown s^\#_2)$, and
				\item for any sequence $(s^\#_i)_{i\in \mathbb{N}}$ of abstract states, the sequence $(\tilde s^\#_i)_{i\in \mathbb{N}}$ with $\tilde s^\#_0 = s^\#_0$ and $\tilde s^\#_{i+1} = \tilde s^\#_i \triangledown s^\#_i$ stabilizes; i.e., there exists $n$ such that $\tilde s^\#_m = \tilde s^\#_n$ for all $m \ge n$\color{black}
			\end{betterlist}
    \item \color{orange}Kleene iteration with $F_{\triangledown}$ always terminates. The result is an abstract annotation:
			\begin{betterlist}
      \item $F_{\triangledown}: (Loc \rightarrow \mathbb{A}_S) \rightarrow (Loc \rightarrow \mathbb{A}_S)$ with $F_{\triangledown}(g) = \{\ell_{init} \mapsto g(\ell_{init}) \triangledown(\alpha(\{\varphi_{pre}\}) \sqcup \bigsqcup \{post^\#(g(\ell'), st) \mid (\ell', st, \ell_{init}) \in \Delta\})\}\cup \{\ell\mapsto g(\ell) \triangledown \bigsqcup\{post^\#(g(\ell'), st) \mid (\ell', st, \ell) \in \Delta\} \mid \ell \in Loc \setminus \{\ell_{init}\}\}$\color{black}
			\end{betterlist}
		\end{betterlist}
		\item \color{orange}\alert{Non-relational Domain:} A value abstraction $(A_{\mathbb{Z}}, \sqsubseteq_{\mathbb{Z}}, \gamma_{\mathbb{Z}}, \alpha_{\mathbb{Z}})$ for $\mathbb{Z}$ induces the \alert{non-relational abstract domain} $(\mathbb{A}, \sqsubseteq, \gamma, \alpha)$ with
		\begin{betterlist}
			\item $\mathbb{A} = V \rightarrow A_{\mathbb{Z}}$
			\item $s^\#_1 \sqsubseteq s^\#_2$ iff for all $x \in V$ it holds that $s^\#_1(x) \sqsubseteq_{\mathbb{Z}} s^\#_2(x)$
			\item $\gamma(s^\#) = \{s \in S_{V ,\mu} | \text{ for all } x \in V, s(x) \in \gamma_{\mathbb{Z}}(s^\#(x))\}$
			\item $\alpha(S) = \{x \mapsto \alpha_{\mathbb{Z}}(\{s(x) | s \in S\}) \mid x \in V\}$
			\item \script{397}{Example}
			\item the following rules define an abstract post operator for the non-relational domain induced by a value abstraction $(A_{\mathbb{Z}}, \sqsubseteq_{\mathbb{Z}}, \gamma_{\mathbb{Z}}, \alpha_{\mathbb{Z}})$:
			\begin{betterlist}
				\item $post^\#(s^\#, \verb|x:=expr|) := s^\#\{x \mapsto eval^\#(expr, s^\#)\} \sqsupseteq \alpha(sp(\gamma(s^\#), \verb|x:=expr|))$
				\item $post^\#(s^\#, \verb|havoc x|) := s^\#\{x \mapsto \top\} = \alpha(sp(\gamma(s^\#), \verb|havoc x|))$
				\item $post^\#(s^\#, \verb|assume expr|) := \alpha(\gamma(s^\#) \cap \{expr\}) = \alpha(sp(\gamma(s^\#), \verb|assume expr|))$
			\end{betterlist}
			where $\top= \bigsqcup_{\sqsubseteq_{\mathbb{Z}}} A_{\mathbb{Z}}$ is the greatest element of $A_{\mathbb{Z}}$. \script{405}{Proof}
		\end{betterlist}\color{black}
		\item \color{orange}an \alert{abstract evaluation function} for a value abstraction $(A_{\mathbb{Z}}, \sqsubset_{\mathbb{Z}}, \gamma_{\mathbb{Z}}, \alpha_{\mathbb{Z}})$ is a monotone function $eval^\#$ that takes an (integer) expression $expr$ and an abstract state $s^\#: V \rightarrow A_{\mathbb{Z}}$ and returns an element of $A_{\mathbb{Z}}$ such that
		\begin{betterlist}
			\item if $s \in \gamma(s^\#)$ and $[[expr]]_{M,\rho} = v$ for $\rho = s$ then $v \in \gamma_{\mathbb{Z}}(eval^\#(expr, s^\#))$
		\end{betterlist}\color{black}
		\item \color{orange}For a CFG $(Loc, \Delta, \ell_{init}, \ell_{ex})$, an \alert{abstract annotation} is a function $f: Loc \rightarrow \mathbb{A}_S$ which satisfies $f(\ell_{init}) \sqsupseteq \alpha(\{\varphi_{pre}\}) \sqcup \bigsqcup \{post^\#(f(\ell'), st) \mid (\ell′, st, \ell_{init}) \in \Delta\}$ and for all $\ell \in Loc \setminus \{\ell_{init}\}$, $f(\ell) \sqsupseteq \bigsqcup \{post^\#(f(\ell'), st) \mid (\ell', st, \ell) \in \Delta\}$\color{black}
		\begin{betterlist}
			\item Let $G = (Loc, \Delta, \ell_{init}, \ell_{ex})$ be a control-flow graph, and let $f$ be an abstract annotation for $G$. Assume that for every $\ell\in Loc$ there exists a formula $\varphi_{\ell}$ such that $\gamma(f(\ell)) = \{\varphi_{\ell}\}$. Then the graph $(AC, T)$ with $AC = \{(\ell, \{\varphi_{\ell}\}) \mid \ell \in Loc\}$ and $T = \{((\ell, \{\varphi_{\ell}\}), st, (\ell', \{\varphi_{\ell'}\})) \mid (\ell, st, \ell') \in \Delta\}$ is an \alert{abstract reachability graph}. \script{411}{Proof (f.)}
      \item \color{orange}An abstract annotation is a fixpoint of the monotone function $F_\#  : (Loc \rightarrow \mathbb{A}_S) \rightarrow (Loc \rightarrow \mathbb{A}_S)$ with\\$F^\# (g) = \left\{\ell_{init} \mapsto g(\ell_{init}) \sqcup \alpha(\{\varphi_{pre}\}) \sqcup \bigsqcup \{post^\#(g(\ell'), st) \mid (\ell', st, \ell_{init}) \in \Delta \}\right\}$\\$\cup  \left\{\ell \mapsto g(\ell) \sqcup  \bigsqcup \{post^\#(g(\ell'), st) \mid (\ell', st, \ell) \in \Delta \} | \ell \in Loc \setminus \{ \ell init\}\right\}$\color{black}
		\end{betterlist}
		\item given a set $X$ and a function $f:X \rightarrow X$ we call an element $x \in X$ a \alert{fixpoint} of $f$ if $f(x) = x$. \script{418}{Examples}
		\item given a set $X$ and a partial order $\sqsubseteq$ and a function $f:X \rightarrow X$, we call an element $x$ the \alert{least fixpoint} of $f$ if $x$ is a fixpoint of $f$ and for all fixpoints $y$ of $f$ the inclusion $x \sqsubseteq y$ holds. \script{419}{Examples}
		\begin{betterlist}
			\item \color{orange}\alert{Knaster-Tarski Fixpoint Theorem}: Let $(X, \sqsubseteq)$ be a complete lattice. If $f:X \rightarrow X$ is monotone then $f$ has a least fixpoint and this fixpoint is $\bigsqcap \{x \mid f(x) \sqsubseteq x\}$. \script{420}{Proof}\color{black}
			\item \script{421}{Abstract Annotations as (Least) Fixpoints}
		\end{betterlist}
  \item \color{orange}\underline{Kleene Chains:} Let $F : X \rightarrow X$ be a monotone function in a complete lattice $(X, \sqsubseteq)$, and let $\bot = \bigsqcap X$ be the least element of $X$\color{black}
		\begin{betterlist}
    \item \color{orange}it holds that $\bot\sqsubseteq F(\bot) \sqsubseteq \ldots \sqsubseteq F^n(\bot) \sqsubseteq F^{n+1}(\bot) \sqsubseteq \ldots$\color{black}
			\item \color{orange}\alert{Ascending Chain Condition (ACC)}: $(X, \sqsubseteq)$ satisfies the \alert{ascending chain condition} if for every infinite ascending chain $x_1 \sqsubseteq x_2 \sqsubseteq \ldots$ there exists an $k \in \mathbb{N}$ such that $x_m = x_k$ for all $m \ge k$\color{black}
			\item \color{orange}\alert{ACC-FP}: If $(X, \sqsubseteq)$ satisfies the ACC, then $\bigsqcup\{F^n(\bot) \mid n \in  \mathbb{N}\}$ is a fixpoint of $F$ and can be computed in finite time. \script{424}{Proof}\color{black}
			\item \color{orange}\alert{Kleene Fixpoint Theorem}: If $F$ is continuous (i.e. $F(\bigsqcup M) = \bigsqcup \{F(m) \mid m \in M\}$ for every set $M$), then $\bigsqcup\{F^n(\bot) \mid n \in \mathbb{N}\}$ is the least fixpoint of $F$\color{black}
			\item \script{426}{Example (f.)}
		\end{betterlist}
		\item If $(Y, \sqsubseteq_Y)$ is a complete lattice, and $X$ is any set, then $(X\rightarrow Y, \sqsubseteq)$ is also a complete lattice, where $X \rightarrow Y$ is the set of all functions from $X \rightarrow Y$, and $f \sqsubseteq g$ iff for all $x \in X$, we have $f(x) \sqsubseteq_Y g(x)$. \script{429}{Proof}
		\item If a complete lattice $(Y , \sqsubseteq_Y)$ satisfies the ACC, then for any finite set $X$, the complete lattice $(X \rightarrow Y , \sqsubseteq)$ also satisfies the ACC
	\end{betterlist}
	\fbox{Predicate Abstraction}
	\begin{betterlist}
		\item Way to design custom domain
		\item \color{orange}Let $B$ a finite set of formulas over program variables. The \alert{predicate abstraction for $B$} is the abstract domain $(\mathbb{A}_B, \sqsubseteq, \gamma_B, \alpha_B)$ where
		\begin{betterlist}
			\item the abstract states are the subsets of $B$: $\mathbb{A}_B = 2^B$,
			\item the order $\sqsubseteq$ is subset inclusion $\subseteq$,
			\item the concretization is $\gamma_B(X) = \{\bigwedge X\}$,
			\item and the abstraction is $\alpha_B(S) = \{\varphi \in B \mid S \subseteq \{\varphi\}\}$
		\end{betterlist}\color{black}
		\item \color{violet}The following defines an \alert{abstract post operator} for predicate abstraction for $B$: $post^\#_B(X, st) = \left\{\varphi \in B \mid sp(\{\bigwedge X\}, st) \subseteq \{\varphi\}\right\} = \left\{\varphi \in B \mid post(\{\bigwedge X\}, [[st]]) \subseteq \{\varphi\}\right\}$\color{black}
		\item \color{orange}Given a finite set of formulas $B$ we define the \script{452}{\alert{abstract strongest post}} operator as follows: $sp^\#_B(S, st) = \{\bigwedge \{\varphi \in B \mid sp(S, st) \subseteq \{\varphi\}\}\}$ or $sp^\#_B(\{\bigwedge X\}, st) = \{\bigwedge \{\varphi \in B \mid sp(\{\bigwedge X\}, st) \subseteq \{\varphi\}\}\} = \{\bigwedge \{\varphi \in B \mid post(\{\bigwedge X\}, [[st]]) \subseteq \{\varphi\}\}\}$\color{black}
		\begin{betterlist}
			\item $sp^\#_B(\{ \psi \} , st) = \{\bigwedge \{\varphi \in B \mid sp(\{ \psi \}, st) \subseteq \{ \varphi \}\}\}$
		\end{betterlist}
  \item \color{orange}We call an abstract reachability graph $(AC, T)$ \alert{precise for $B$} if for each edge $((\ell, \{\varphi\}), st, (\ell', \{\varphi'\})) \in T$ the equality $sp^\#_B(\{\varphi\}, st) = \{\varphi'\}$ holds\color{black}
	\end{betterlist}
	\fbox{Infeasability Proofs}
	\begin{betterlist}
		\item \color{orange}A \alert{control-flow graph with error locations} is a tuple $G = (Loc, \Delta, \ell_{init}, \ell_{ex}, Loc_{err})$ where
		\begin{betterlist}
			\item $(Loc, \Delta, \ell_{init}, \ell_{ex})$ is a control-flow graph and
			\item $Loc_{err} \subseteq Loc$ is a subset of locations that we call \alert{error locations}
		\end{betterlist}\color{black}
		\item Given a program $P = (V, \mu, st)$ we define the \alert{control-flow graph with error locations for $P$} analogously to the control-flow graph for $P$. We always take the union of error locations for sub-statements, and define the control-flow graph for an assert statement below
		\begin{betterlist}
			\item \script{438}{Example}
		\end{betterlist}
		\item \color{orange}We call a program configuration $(\ell, s)$ an \alert{error configuration} if $\ell \in Loc_{err}$\color{black}
    \item \color{orange}An abstract configuration $(\ell, \{\varphi\})$ is an \alert{abstract error configuration} if $\ell \in Loc_{err}$ and $\{\varphi\}\ne \emptyset = \{false\}$\color{black}
		\item \color{orange}We call a sequence of statements a \alert{trace}\color{black}
		\begin{betterlist}
			\item We call a trace $\pi$ \alert{feasible} if there is some execution for $\pi$
		\end{betterlist}
		\item \color{orange}Given a trace $\pi = st_1, \ldots, st_n$, we call a \alert{sequence of formulas} $\varphi_0, . . . , \varphi_n$ \alert{inductive for $\pi$} if $sp(\{\varphi_i\}, st_{i+1}) \subseteq \{\varphi_{i+1}\}$ for all $i \in \{0, \ldots, n−1\}$\color{black} %(Inductive sequence of formulas)
		\item If there exists a sequence of formulas $\varphi_0, \ldots , \varphi_n$ that is inductive for $\pi$ such that $\varphi_0$ is $true$ and $\varphi_n$ is $false$, then $\pi$ is infeasible
		\item \color{orange}We call a sequence of formulas $\varphi_0, \ldots , \varphi_n$ a \alert{proof of infeasibility} if the sequence is inductive for $\pi$, $\varphi_0$ is $true$, and $\varphi_n$ is $false$\color{black}
		\item We define the \alert{abstraction of a statement} $abstract(st)$ as follows:

		$abstract(st) = \begin{cases}
				\verb|assume true| & \text{if st is of the form } \verb|assume |\psi \\
				\verb|havoc x|     & \text{if st is of the form } \verb|x:=e|        \\
				\verb|havoc a|     & \text{if st is of the form } \verb|a[k]:=v|     \\
				\verb|havoc x|     & \text{if st is of the form } \verb|havoc x|
			\end{cases}$
		\item We call a trace $\pi^\# = st^\#_1 \ldots st^\#_n$ an \alert{abstraction of a trace} $\pi = st_1, \ldots, st_n$ if each $st^\#_i$ is either the statement $st_i$ or the abstraction $abstract(st_i)$
		\begin{betterlist}
			\item If $\pi^\#$ is an abstraction of $\pi$ and $\varphi_0, \ldots , \varphi_n$ is a proof of infeasibility for $\pi^\#$, then $\varphi_0, \ldots , \varphi_n$ is a proof of infeasibility for $\pi$
		\end{betterlist}
		\item For $i = 0, \ldots, n$, let $\sigma_i$ be the substitution such that for any $x \in V$, we have $\sigma_i(x) = x_k$ iff there are exactly $k$ statements of the form \verb|x:=expr|, \verb|x[k]:=v| or \verb|havoc x| in the prefix trace $st_1 \ldots st_i$.

		\color{orange}We define the \alert{static single-assignment form (SSA)} as the set of formulas $SSA(\pi) := \{\psi_1, \ldots, \psi_n\}$, where

		$\psi_i =
			\begin{cases}
				expr\;\sigma_i                                    & \text{if } st_i \text{ is } \verb|assume expr| \\
				\sigma_i(x) = (expr\;\sigma_{i−1})                & \text{if } st_i \text{ is } \verb|x:=expr|     \\
				\sigma_i(a) = (a⟨k \triangleleft v⟩) \sigma_{i−1} & \text{if } st_i \text{ is } \verb|a[k]:=v|     \\
				true                                              & \text{if } st_i \text{ is } \verb|havoc x|
			\end{cases}$
		\begin{betterlist}
			\item $\bigwedge SSA(\pi )$ is unsatisfiable iff $\pi$ is infeasible
		\end{betterlist}\color{black}
		\item \color{orange}Given a finite set of formulas $\mathbb{F}$ where $\bigwedge \mathbb{F}$ is unsatisfiable, we call a subset $X \subseteq \mathbb{F}$ an \alert{unsatisfiable core} if $\bigwedge X$ is also unsatisfiable\color{black}
		\begin{betterlist}
			\item An unsatisfiable core $X$ is \alert{minimal} if no strict subset of $X$ is an unsatisfiable core
		\end{betterlist}
		\item Let $\pi = st_1\ldots st_n$ be an infeasible trace, with $SSA(\pi ) = \{ \psi_1,\ldots , \psi_n\}$ as on the previous slide. Let $X$ be an unsatisfiable core of $SSA(\pi )$, and let $\pi^\# = st^\#_1 \ldots st^\#_n$ such that $st^\#_i = st_i$ if $\psi_i \in X$, and $st^\#_i = abstract(st_i)$ otherwise. Then the trace $\pi^\#$ is infeasible
	\end{betterlist}
	\fbox{CEGAR}
	\begin{betterlist}
		\item \color{orange}Given an abstract reachability graph $(AC, T)$, we call a sequence of statements $st_1,\ldots , st_n$ an \alert{error trace in $(AC, T)$} if there exists a sequence of abstract configurations $(\ell_0, \{ \varphi_0\} ),\ldots , (\ell_n, \{ \varphi_n\})$ such that
		\begin{betterlist}
			\item $(\ell_0, \{ \varphi_0\} )$ is the initial abstract configuration $(\ell_{init}, \{ true\} )$,
			\item $( (\ell_i, \{ \varphi_i\} ), st_{i+1}, (\ell_{i+1}, \{ \varphi_{i+1}\} ) ) \in T$ for $i \in \{ 0,\ldots , n −1\}$, and
			\item $(\ell_n, \{ \varphi_n\} )$ is an abstract error configuration
		\end{betterlist}\color{black}
		\item Let $\pi$  be a trace. If $\varphi_0,\ldots , \varphi_n$ is an infeasibility proof for $\pi$  and $B \supseteq \{ \varphi_0,\ldots \varphi_n\}$  then $\pi$  is not an error trace in an abstract reachability graph that is precise for $B$. \script{487}{Proof}
		\item \alert{Progress property:} In the CEGAR algorithm, if $\pi$ is the error trace that is analyzed in iteration $i$, then $\pi$ will not be an error trace of the abstract reachability graph in further iterations
	\end{betterlist}
\end{minipage}

\newpage

\begin{minipage}[t]{0.2\linewidth}
	\fbox{Trace Abstraction}
	\begin{betterlist}
		\item a \alert{nondeterministic finite automaton (NFA)} is a tuple $A = (Q, \sum , \Delta , Q_{init}, F)$ consisting of a finite set of states $Q$, a finite alphabet $\sum$, a transition relation $\Delta \subseteq Q × \sum  × Q$, a set of initial states $Q_{init} \subseteq Q$, and a set of accepting states $F \subseteq Q$.
		\begin{betterlist}
			\item a \alert{run} for a word $w = a_1\ldots a_n \in \sum^{*}$ in an NFA $\mathcal{A}$ is a sequence of states $q_0q_1\ldots q_n$ such that $q_0 \in Q_{init}$ and $(q_{i−1}, a_{i}, q_{i}) \in \Delta$ for all $i \in \{1,\ldots , n\}$
			\begin{betterlist}
				\item the run is \alert{accepting} if it ends in an accepting state $q_n \in F$
			\end{betterlist}
			\item a word $w \in \sum ^*$ is \alert{accepted} by $\mathcal{A}$ if there exists an accepting run for $w$ in $\mathcal{A}$
			\item we write $\mathcal{L}(A)$ to denote the \alert{language of $\mathcal{A}$}, i.e., the set of all accepted words
		\end{betterlist}
		\item Let P be a program with assert statements, and let $G = (Loc, \Delta , \ell_{init}, \ell_{ex}, Loc_{err})$ be a CFG with error locations for $P$. \color{orange}The \alert{program automaton} for $P$ is the NFA $\mathcal{A}_P = (Loc, \sum , \Delta , \{ \ell_{init}\} , Loc_{err})$ where $\sum$ is the set of all statements $st$ such that $(\ell, st, \ell') \in \Delta$ for some locations $\ell, \ell'$\color{black}
		\begin{betterlist}
			\item $P$ satisfies all assert statements iff every word in $\mathcal{L}(\mathcal{A}_P)$ is infeasible
		\end{betterlist}
		\item \color{orange}a \alert{Floyd-Hoare annotation} for an automaton $\mathcal{A}$ is a mapping $\beta$ that assigns each state $q$ a formula $\beta(q)$ such that for every edge $\beta (q)q\, stmt\, q'\beta(q')$ the Hoare triple $\{\beta(q)\} stmt \{\beta(q′)\}$ is valid\color{black}
		\item \color{violet}given an automaton $\mathcal{A}$, if there is a Floyd-Hoare annotation such that
		\begin{betterlist}
			\item every initial state is labeled with true and
			\item every accepting state is labeled with false
		\end{betterlist}
		then every accepted trace of $\mathcal{A}$ is infeasible\color{black}
		\item \color{orange}we call an automaton $A = (Q, \sum , \Delta , Q_{init}, F)$ a \alert{Floyd-Hoare automaton} if there exists a Floyd-Hoare annotation $\beta  : Q \rightarrow Fm(V)$ such that
		\begin{betterlist}
			\item $\beta(q) = true$ for all $q \in Q_{init}$ and
			\item $\beta(q) = false$ for all $q \in F$
		\end{betterlist}\color{black}
		\item \underline{Lemma:} Every trace that is accepted by a Floyd-Hoare automaton is infeasible
		\item If there are Floyd-Hoare automata $\mathcal{A}_{1}, \ldots, \mathcal{A}_{n}$ such that the inclusion $L(\mathcal{A}_P) \subseteq L(\mathcal{A}_{1}) \cup . . . \cup L(\mathcal{A}_{n})$ holds then the program $P$ is safe
	\end{betterlist}
	\fbox{Constraint-based Invariant Synthesis}
	\begin{betterlist}
		\item \color{violet}given a program $P$, if there is a Floyd-Hoare annotation of the program automaton $\mathcal{A}_P$ such that
		\begin{betterlist}
			\item every initial state is labeled with true and
			\item every accepting state (i.e., error location) is labeled with false
		\end{betterlist}
		then $P$ is safe\color{black}
		\begin{betterlist}
			\item there exist formulas $\varphi_{\ell_1},\ldots , \varphi_{\ell_n}$ such that
			\begin{betterlist}
				\item $\varphi_{\ell_{init}}$ is true
				\item for each $(\ell , st, \ell ' ) \in \Delta$ : $sp(\{ \varphi_{\ell} \} , st) \subseteq \{ \varphi_{\ell'}\}$
				\item for each $\ell \in Loc_{err} : \varphi_{\ell}$ is false
			\end{betterlist}
			\item there exist sets of states $S_{\ell_1},\ldots , S_{\ell_n}$ such that
			\begin{betterlist}
				\item $S_{\ell_{init}}$ is $S_{V,\mu}$
				\item for each $(\ell, st, \ell') \in \Delta$ : for all $s, s' \in S_{V,µ}$ : $s \in S_{\ell}$ and $(s, s') \in [[st]]$ implies $s' \in S_{\ell'}$
				\item for each $\ell \in Loc_{err}$ : $S_{\ell}$ is $\emptyset$
			\end{betterlist}
			\item there exist $p{\ell_1},\ldots , p{\ell_n}$ such that
			\begin{betterlist}
				\item $\forall\vec{v}. p_{\ell_{init}}(\vec{v}) \leftrightarrow true$
				\item for each $(\ell, st, \ell') \in \Delta : \forall\vec{v}.\forall\vec{v'}.p_{\ell}(\vec{v}) \land \tau_{st}(\vec{v},\vec{v'}) \rightarrow p_{\ell'}(\vec{v}')$
				\item for each $\ell \in Loc_{err} : \forall\vec{v}. p_{\ell}(\vec{v}) \leftrightarrow false$
			\end{betterlist}
			\item there exist $a_{\ell_1},\ldots, a_{\ell_n}, b_{\ell_1},\ldots, b_{\ell_n}$ such that
			\begin{betterlist}
				\item $\forall x. a_{\ell_{init}} \cdot  x + b_{\ell_{init}} \geq 0 \leftrightarrow true$
				\item for each $(\ell, st, \ell') \in \Delta$ : $\forall x, x' . a_{\ell} \cdot  x + b_{\ell} \geq 0 \land \tau_{st}(x, x') \rightarrow a_{\ell'} \cdot x' + b_{\ell'} \geq 0$
				\item for each $\ell \in Loc_{err} : \forall x. a_{\ell} \cdot  x + b_{\ell} \geq 0 \leftrightarrow false$
				\item special case where the program has only one variable. The extension to multiple variables is straightforward
			\end{betterlist}
		\end{betterlist}
		\item \alert{Obstacle 1:} The relation $[[st]]$ that defines the meaning of a statement st is not given as a formula
		\begin{betterlist}
			\item define the transition formula which is a formula that denotes the relation $[[st]]$ for a given statement $st$. Such a formula does not always exist (difficult to prove) and is not unique. For every simple statement there exists a transition formula. Since a control-flow graph contains only simple statements we overcame Obstacle 1
		\end{betterlist}
		\item \alert{Obstacle 2:} The condition quantifies over states, sets of states and both sorts are related via the 'is element' relation. This is usually impossible in first-order logic and can only be done in second-order logic
		\begin{betterlist}
			\item Using the two obserservations below, we rephrase the set conditions from above as SMT formulas by the conditions below them. In order to improve legibility we use $\vec{v}$ to denote the list of all program variables. We call these formulas constraints
			\begin{enumerate}
				\item The quantification of set variables is existential and the outermost quantification in the orange box. We can always drop the outermost existential quantification (we introduce a Skolem constant) by replacing the quantified variables by other symbols and obtain an equisatisfiable formula
				\item If quantification is not required, we can use a predicate symbol to represent a set. E.g., over the integers, the set of even numbers is a (resp. the only) satisfying assignment for the predicate symbol $p$ in the following formula. $\forall x.p(x) \leftrightarrow \exists y.x = 2 \cdot y$
			\end{enumerate}
			\item We note that the constraints do not encode the existence of a Floyd-Hoare annotation but something weaker: for a Floyd-Hoare annotation we require additionally that the solutions for sets of states can be represented as a FOL formula
		\end{betterlist}
		\item \color{orange}\alert{Transition Formula:}  We call a formula $\tau$ over primed and unprimed program variables a \alert{transition formula} for $st$ if the relation $[[st]]$ coincides with the following relation. $\{(s_1, s_2) | [[\tau]]_{M,\rho} \text{ is true and } \rho = s_1 \cup prime(s_2)\}$. \script{524}{Transition formulas for statements from lecture}\color{black}
		\item \underline{Problem:} No SMT-sovler is able to provide a response for the check-sat command. The constraints are already too complicated for small and simple control flow graphs. Thus have to find a simpler problem for which our approach works
		\begin{betterlist}
			\item Do not check if some Floyd-Hoare annotation exists, check only if some Floyd-Hoare annotation of a specific form exists
			\item Replace each $p\ell(\vec{v})$ by a linear inequality whose variables are the variables of the program and whose coefficients are the unknowns for which we want to find a solution. E.g. replace the predicate symbol $p_{\ell}(x, y)$ by $a_{\ell} \cdot  x + b_{\ell} \cdot  y + c_{\ell} \geq 0$
			\item $\oplus$ The SMT solver does not have to find a solution for predicate symbols but only for first-order variables $a_{\ell}$, $b_{\ell}$, $c_{\ell}$
			\item $\ominus$ We can only find a Floyd-Hoare annotation $\beta$ if for each $\ell \in Loc$ the formula $\beta (\ell)$ is a linear inequality
		\end{betterlist}
		\item \underline{Problem:} No SMT-solver is able to provide a response for the check-sat command. The constraints are already too complicated for small and simple control flow graphs
		\begin{betterlist}
			\item \underline{constraints that are difficult to solve:}
			\begin{enumerate}
				\item Quantifier alternation. Since we are searching for a satisfying assignment of a non-closed formula, the formula is implicitly existentially quantified and we have to solve a problem that involves quantifier alternation.
				\item Nonlinear arithmetic (i.e., multiplication of variables)
			\end{enumerate}
			\item \underline{can use a brilliant idea:}
			\begin{betterlist}
				\item can write (many) transition formulas as conjunction of linear inequalities, and abbreviate. \script{533}{Example}
				such conjunctions using matrix notation
				\item \color{orange}\script{534}{\alert{Lemma Farkas}}: If $\exists\vec{x} . A \cdot \vec{x} \leq\vec{b}$ is satisfiable, then $\forall\vec{x} . (A \cdot \vec{x} \leq\vec{b} \rightarrow\vec{c}^T\cdot \vec{x} \leq \delta)$ is equivalent to $\exists\vec{\lambda} . ( \vec{\lambda} \geq 0 \land\vec{\lambda}^T\cdot A =\vec{c}^T\land\vec{\lambda}^T\cdot \vec{b} \leq \delta)$\color{black}
				\begin{betterlist}
					\item use this lemma to transform formulas into equivalent formulas that are simpler for SMT solvers as they do not have quantifier alternation: $\exists\vec{\lambda}.(\vec{\lambda} \geq 0 \land\vec{\lambda}^T\cdot  A =\vec{c}^⊺\land\vec{\lambda}^T\cdot \vec{b} \leq \delta )$ is satisfiable iff $(\vec{\lambda}  \geq 0 \land\vec{\lambda}^T\cdot A =\vec{c}^T\land\vec{\lambda}^T\cdot \vec{b} \leq \delta)$ is satisfiable
					\item \script{535}{Steps}
					% \item extension to use a boolean combination of linear inequalities. For Farkas’ Lemma we need a form that is very similar to a conjunctive normal form and that hence the size of the final formula grows exponentially in the size of this Boolean combination of linear inequalities
				\end{betterlist}
			\end{betterlist}
			\item \script{537}{Example}. We use $\vec{\lambda}=\left[\begin{array}{c}L_{41}\\\ldots\\L_{45}\end{array}\right]$, where the first index (4) indicates from which constraint the constant stems, and the second index indicates the position in the vector
		\end{betterlist}
	\end{betterlist}
	\fbox{Termination Analysis}
	\begin{betterlist}
		\item \script{546}{Questions} and \script{547}{Answers}
		\item We call an infinite sequence of program configurations $(\ell_0, s_0), (\ell_1, s_1)\ldots$ an \alert{infinite execution} of $P$ if there exists an infinite sequence of statements $st_1, st_2,\ldots$ such that for each $i \in \mathbb{N}$:
		\begin{betterlist}
			\item $(\ell_i, st_{i+1}, \ell_{i+1}) \in \Delta$ and
			\item $(s_i, s_{i+1}) \in [[st_{i+1}]]$
		\end{betterlist}
		\item We call $P$ \alert{terminating} if $P$ does not have an infinite execution that starts in an initial configuration
		\item Let $X$ be a set. We call a binary relation $R \subseteq X × X$ \alert{well-founded} if there is no infinite sequence $x_1, x_2,\ldots$ such that $(x_i, x_{i+1}) \in R$ for all $i \in \mathbb{N}$
		\item \color{orange}Let $P = (V, \mu, st_P)$ be a program that contains a while loop \verb|while(expr){ st }|. Let $W$ be a set, and $R \subseteq W × W$ a well-founded relation. We call a function $f : S_{V,\mu} \rightarrow W a$ \alert{ranking function}  for the loop if for each pair of states $(s, s') \in [[\verb|assume expr; st|]]$ the relation $(f(s), f(s')) \in R$ holds. \script{551}{Example}. \script{550}{Informal definition and loop variant}\color{black}
		\begin{betterlist}
			\item \alert{RankTerminate:} Let $P$ be a program. If every while loop of $P$ has a ranking function then $P$ is terminating. \script{553}{Proof}
		\end{betterlist}
		\item \script{554}{More questions}
    \item \color{orange}do not use $(\mathbb{N}, >)$ but $(\mathbb{Z}, >_{\mathbb{N}})$ where we define $>_{\mathbb{N}}$ as follows. $x >_{\mathbb{N}} y$ iff $x > y$ and $x \in \mathbb{N}$. \script{555}{Reason}\color{black}
		\item \script{552}{Every loop that has a ranking function terminating}, \script{556}{Check if a function f is a ranking function}, \script{557}{4 assumptions, lexicographic ranking function}, \script{558}{Ranking function is only decreasing for reachable states}, in order to prove termination of the program above, we also have to take the reachable states into account
		\item \alert{Loop Entry:} Given a while loop \verb|while(expr){ st }| and a control-flow graph $G = (Loc, \Delta , \ell_{init}, \ell_{ex})$ for this while loop, we call $\ell_{init}$ the \alert{entry location} of the while loop
		\item Let $P = (V, \mu, st_P)$ be a program that contains a while loop \verb|while(expr){ st }|  with entry location $\ell$. Let $\beta$ be a Floyd-Hoare annotation of $\mathcal{A}_P$. Let $W$ be a set, and $R \subseteq W × W$ a well-founded relation. We call a function $f : S_{V,\mu} \rightarrow W$ a \alert{ranking function} if for each pair of states $(s, s') \in [[\verb|assume expr; st|]]$ with $s \in \{ \beta(\ell )\}$ the relation $(f(s), f(s')) \in R$ holds
		\begin{betterlist}
			\item Let $P$ be a program and $\beta$ be a Floyd-Hoare annotation for $P$. If every while loop of $P$ has a ranking function for $\beta$ then $P$ is terminating
			\begin{betterlist}
				\item Floyd-Hoare annotation denotes a superset of the reachable states at each location
			\end{betterlist}
		\end{betterlist}
		\item \underline{Idea of the approach of the Terminator tool:} Iteratively collect ranking functions until termination of all loops is shown. \script{574}{Example}. \script{582}{Büchi Automizer}
		\begin{enumerate}
			\item Start with the empty set of ranking functions
			\item Pick an ultimately periodic trace for which termination is not yet shown (if termination is not yet proven)
			\item Compute a ranking function for this trace and add it to our collection (if the trace does not have in infinite execution)
			\item Check if the collection of ranking functions is sufficient to prove termination and continue with the second step
		\end{enumerate}
		\item \script{583}{Prove nontermination}, \script{584}{Safety or termination more difficult}
	\end{betterlist}
\end{minipage}
\begin{minipage}[t]{0.2\linewidth}
	\fbox{Concurrent Programs}
	\begin{betterlist}
		\item \script{587}{Concurrent Programs}, Number interleaving of 2 threads: $\dfrac{(m+n)!}{m!\cdot n!} $ (\script{588}{Illustration})
		\item \color{orange}a \alert{ concurrent Boostan program}  is a triple $(V , \mu , \mathcal{T})$ where
		\begin{betterlist}
			\item $V$ is a set of program variables,
			\item $\mu$ is a map that assigns each variable a domain,
			\item $\mathcal{T}$ is a finite set of threads, i.e., a set of derivation trees $T$ such that $(V , \mu , T)$ is a (sequential) Boostan program
		\end{betterlist}\color{black}
		\item \color{orange}\alert{Concurrent Program CFG:} Let $P = (V , \mu , \mathcal{T} )$ be a concurrent program, with $\mathcal{T} = \{ T_1,\ldots, T_n\}$. Let $(Loc_i, \Delta_i, \ell_{init,i}, \ell_{ex,i})$ be a CFG for $(V, \mu , T_i)$ for $i = 1, \ldots, n$

		Then $(Loc, \Delta, \ell_{init}, \ell_{ex})$ is a CFG for $P$, where
		\begin{betterlist}
			\item $Loc = Loc_1 \times \ldots \times Loc_n$,
			\item $((\ell_1,\ldots , \ell_n), st, (\ell'_1,\ldots , \ell'_n)) \in \Delta$ iff $(\ell_i, st, \ell'_i) \in \Delta_i$ for some $i$, and $\ell_j = \ell'_j$ for all $j \ne i$,
			\item $\ell_{init} = (\ell_{init,1},\ldots , \ell_{init,n})$,
			\item and $\ell_{ex} = (\ell_{ex,1},\ldots , \ell_{ex,n})$
		\end{betterlist}\color{black}
		\item \script{593}{Partial Order Reduction Illustration}
		\begin{betterlist}
			\item \alert{Commutativity:} We say that two statements $st1$, $st2$ \alert{commute} if $[[st_1 st_2]] = [[st_2 st_1]]$ holds
			\item \alert{Equivalence:} We say that two traces $\pi_1, \pi_2$ are \alert{equivalent}, denoted $\pi_1 \sim \pi_2$, if $\pi_2$ can be derived from $\pi_1$ by (repeatedly) swapping adjacent commuting statements
			\begin{betterlist}
				\item $\sim$ is indeed reflexive (do not swap any statements), transitive (concatenate sequences of swaps) and symmetric (reverse swaps)
			\end{betterlist}
			\item A \alert{reduction} of a program $P$ is an automaton $\mathcal{A}_R$ such that $\mathcal{L}(\mathcal{A}_R) \subseteq \mathcal{L}(\mathcal{A}_P)$, and for every trace $\pi_1 \in \mathcal{L}(\mathcal{A}_P)$ there exists a trace $\pi_2 \in \mathcal{L}(\mathcal{A}_R)$ with $\pi_1 \sim \pi_2$
			\item \alert{Soundness of Partial Order Reduction:} If $\mathcal{A}_R$ is a reduction of $P$, and every trace $\pi \in \mathcal{L}(\mathcal{A}_R)$ is correct, then $P$ is safe
		\end{betterlist}
		\item \script{595}{Example for Reduction of Program Automaton}
	\end{betterlist}
	\fbox{Neat little details}
	\begin{betterlist}
		\item Although \alert{predicate transformers} technically manipulate sets of states, they do so through the medium of predicates (logical formulas). The term \enquote{predicate transformer} reflects the fact that these functions take predicates as input and produce new predicates as output
		\item $M \models \{\text{theory formulas}\}$
		\item bei $M = (D,\{p \mapsto \overset{.}{=}\})$, $\overset{.}{=} {=} \{(x, y)\in \mathbb{N} \mid x = y\}$, $[[\forall x: p(x, x)]]_{M, \rho}$, $[[p(x, x)]]_{M, \rho} = [[x]]_{M, \rho} \overset{.}{=} [[x]]_{M, \rho}$, forall $v\in D$ it's the case that $[[x]]_{M, \rho\triangleleft\{x \mapsto v\}} \overset{.}{=} [[x]]_{M, \rho\triangleleft\{x \mapsto v\}} = v \overset{.}{=} v = true$
		\item basis on propositional and first order logic
    \item Terminator unpassend
		\begin{betterlist}
			\item Valid $\rightarrow$ Satisfiable (but not vice versa)
			\item Unsatisfiable $\rightarrow$ Falsifiable (but not vice versa)
			\item Valid $\leftrightarrow$ Not Falsifiable
			\item Satisfiable $\leftrightarrow$ Not Unsatisfiable
		\end{betterlist}
		\item \underline{Good loop invariant:}
		\begin{enumerate}
			\item Identify the goal: What is the loop trying to achieve? The loop invariant should help you prove that the loop is working towards this goal.
			Break down the problem: Understand the preconditions (what’s true before the loop starts) and the postconditions (what needs to be true after the loop ends)
			\item A good loop invariant often represents partial progress toward the final solution. It should capture the idea that each iteration of the loop brings you closer to solving the problem. Example: If the goal is to sort an array, a possible invariant might be that the first k elements are already sorted
			\item Consider what should be true at the very start of the loop (when no iterations have occurred). This is often a simpler version of the invariant
			\item Look at the loop's control variables and how they change with each iteration. The loop invariant often involves these variables
			\item The loop invariant should be strong enough that, when the loop terminates, it implies the postcondition (the desired outcome of the loop). Example: If you want to find the maximum in an array, a good invariant might be that the variable max holds the maximum of all elements processed so far
			\item Test the loop with small examples and see what properties remain true after each iteration. This can help you discover the invariant.
			\item Ensure that the invariant is preserved by the loop body. This means that if the invariant holds before an iteration, it should still hold after the iteration. Example: For a loop that reverses an array, an invariant could be that all elements swapped so far are in their correct reversed positions.
			\item Often, a loop invariant expresses a relationship between variables, like array indices or counters. Consider how variables relate to each other as the loop progresses Example: In an algorithm to find the GCD using the Euclidean method, a possible invariant is that gcd(a, b) = gcd(a, b \% a).
			\item Ensure that the invariant holds for edge cases, like when the loop starts with empty inputs or when the loop runs zero times. A strong invariant should still hold in these cases.
			\item Finding a good loop invariant is often an iterative process. You may need to refine your invariant as you analyze the loop more deeply or as you encounter edge cases
		\end{enumerate}
		\item \underline{Two heuristics that work quite well:}
		\begin{betterlist}
			\item start with what you have (pre-conditions), and weaken until you have an inductive invariant. In order to get an intuition how to weaken, apply one or several forward loop iterations and see what ceases to be true in the formula you have.
			\item start with what you want (post-conditions) and strengthen until you have an inductive invariant. To get the intuition how to strengthen, apply one or several loop iterations backwards and see what needs to be added so that the post-condition can be deduced
		\end{betterlist}
		\item \underline{Where to Find the Loop Invariant in CFG:}
		\begin{betterlist}
			\item At the Entry Node (Loop Condition Check):
			\begin{betterlist}
				\item The loop invariant is asserted at the entry node, where the loop condition is evaluated
				\item This is because the loop invariant should hold before the first iteration of the loop (initialization phase) and also before each subsequent iteration of the loop
			\end{betterlist}
			\item Before Each Iteration:
			\begin{betterlist}
				\item After every iteration of the loop body, control flows back to the entry node (condition check). At this point, the loop invariant should be checked (implicitly or explicitly) to ensure it still holds
			\end{betterlist}
		\end{betterlist}
		\item \underline{Why loop invariant:} Loops can introduce a lot of complexity into a program because they execute a block of code multiple times. The state of the program changes with each iteration, making it difficult to reason about the final outcome. Why Invariants Help: A loop invariant provides a property that remains true before and after each iteration. This consistent truth simplifies reasoning about the loop's behavior, allowing you to break down the verification process into manageable steps
    \item wie in der Übungsaufgaben, Erfahrungen... lange gedacht, dass... lange gebraucht, anstrengende Aufgabe
    \item Fragen zurück stellen, wollen auch wisssen warum non-relational z.B.
    \item sagen stopen sobald zu ausführlich
    \item the Hoare proof system allows us to give a correctness proof if we guess “good” loop invariants. ARGs allow us to give a correctness proof if we guess “good” abstract configurations
    \item unlike the non-relational abstract domains discussed in the last section, it can express relations between different variables. For example, $B$ may contain the formula $x \le y$, for two integer variables $x, y$
    \item it is easy to see that, since B is finite, the predicate abstraction for B satisfies the ACC.
    \item ARG from the predicate abstraction which, unlike the ARG defined by abstract interpretation, does not necessarily have the same structure as the CFG
    \item the benefit of this ARG is that we are not restricted to a single abstract configuration per location: Different executions that reach the same location may reach different abstract configurations. Intuitively, this allows us to associate a location with a \enquote{disjunction} of abstract states: When an execution reaches the location, the program state must match one of the abstract states in abstract configurations with this location
    \item using the given algorithm, we can algorithmically construct the abstract reachability graph that is precise for a given set of formulas B. As there are only finitely many possible conjunctions of formulas in B, the algorithm will always terminate
    \item however, as we have seen on the example, it is still important that we choose a suitable set of formulas B in order to get a safety proof. The next two sections present a method for choosing B that has turned out to be quite successful in practice
    \item CEGAR:
    \begin{betterlist}
      \item stands for CounterExample-Guided Abstraction Refinement
    \end{betterlist}
	\end{betterlist}
\end{minipage}
\begin{minipage}[t]{0.2\linewidth}
\end{minipage}
\begin{minipage}[t]{0.2\linewidth}
\end{minipage}
\begin{minipage}[t]{0.2\linewidth}
\end{minipage}

\end{document}
